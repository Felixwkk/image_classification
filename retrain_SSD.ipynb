{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "retrain SSD.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO6/qnHnmNFIy9KmX2rmuZr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Felixwkk/image_classification/blob/master/retrain_SSD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-KxSH3IZsIs",
        "colab_type": "text"
      },
      "source": [
        "Download the files  from GITHUB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFi7ED_ZPDaH",
        "colab_type": "code",
        "outputId": "d9be2c2c-f8de-4bcc-fc08-5bd39ccb4943",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "! git clone https://github.com/tensorflow/models.git\n",
        "#!git clone https://github.com/hardikvasa/google-images-download.git\n",
        "! git clone https://github.com/Joeclinton1/google-images-download.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 41, done.\u001b[K\n",
            "remote: Counting objects:   2% (1/41)\u001b[K\rremote: Counting objects:   4% (2/41)\u001b[K\rremote: Counting objects:   7% (3/41)\u001b[K\rremote: Counting objects:   9% (4/41)\u001b[K\rremote: Counting objects:  12% (5/41)\u001b[K\rremote: Counting objects:  14% (6/41)\u001b[K\rremote: Counting objects:  17% (7/41)\u001b[K\rremote: Counting objects:  19% (8/41)\u001b[K\rremote: Counting objects:  21% (9/41)\u001b[K\rremote: Counting objects:  24% (10/41)\u001b[K\rremote: Counting objects:  26% (11/41)\u001b[K\rremote: Counting objects:  29% (12/41)\u001b[K\rremote: Counting objects:  31% (13/41)\u001b[K\rremote: Counting objects:  34% (14/41)\u001b[K\rremote: Counting objects:  36% (15/41)\u001b[K\rremote: Counting objects:  39% (16/41)\u001b[K\rremote: Counting objects:  41% (17/41)\u001b[K\rremote: Counting objects:  43% (18/41)\u001b[K\rremote: Counting objects:  46% (19/41)\u001b[K\rremote: Counting objects:  48% (20/41)\u001b[K\rremote: Counting objects:  51% (21/41)\u001b[K\rremote: Counting objects:  53% (22/41)\u001b[K\rremote: Counting objects:  56% (23/41)\u001b[K\rremote: Counting objects:  58% (24/41)\u001b[K\rremote: Counting objects:  60% (25/41)\u001b[K\rremote: Counting objects:  63% (26/41)\u001b[K\rremote: Counting objects:  65% (27/41)\u001b[K\rremote: Counting objects:  68% (28/41)\u001b[K\rremote: Counting objects:  70% (29/41)\u001b[K\rremote: Counting objects:  73% (30/41)\u001b[K\rremote: Counting objects:  75% (31/41)\u001b[K\rremote: Counting objects:  78% (32/41)\u001b[K\rremote: Counting objects:  80% (33/41)\u001b[K\rremote: Counting objects:  82% (34/41)\u001b[K\rremote: Counting objects:  85% (35/41)\u001b[K\rremote: Counting objects:  87% (36/41)\u001b[K\rremote: Counting objects:  90% (37/41)\u001b[K\rremote: Counting objects:  92% (38/41)\u001b[K\rremote: Counting objects:  95% (39/41)\u001b[K\rremote: Counting objects:  97% (40/41)\u001b[K\rremote: Counting objects: 100% (41/41)\u001b[K\rremote: Counting objects: 100% (41/41), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 34385 (delta 7), reused 10 (delta 3), pack-reused 34344\u001b[K\n",
            "Receiving objects: 100% (34385/34385), 512.47 MiB | 34.05 MiB/s, done.\n",
            "Resolving deltas: 100% (22172/22172), done.\n",
            "Checking out files: 100% (2497/2497), done.\n",
            "Cloning into 'google-images-download'...\n",
            "remote: Enumerating objects: 4, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 625 (delta 0), reused 3 (delta 0), pack-reused 621\u001b[K\n",
            "Receiving objects: 100% (625/625), 275.83 KiB | 1.13 MiB/s, done.\n",
            "Resolving deltas: 100% (362/362), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yo8Yv_XWZ3SZ",
        "colab_type": "text"
      },
      "source": [
        "Prepare the google image download to support python 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaRgRUS6fdRu",
        "colab_type": "code",
        "outputId": "e6c60c3e-9054-492c-bafc-e05ecfc1738a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "%cd /content/google-images-download\n",
        "! wget https://files.pythonhosted.org/packages/ed/9c/9030520bf6ff0b4c98988448a93c04fcbd5b13cd9520074d8ed53569ccfe/selenium-3.141.0.tar.gz"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/google-images-download\n",
            "--2020-05-03 00:13:03--  https://files.pythonhosted.org/packages/ed/9c/9030520bf6ff0b4c98988448a93c04fcbd5b13cd9520074d8ed53569ccfe/selenium-3.141.0.tar.gz\n",
            "Resolving files.pythonhosted.org (files.pythonhosted.org)... 151.101.1.63, 151.101.65.63, 151.101.129.63, ...\n",
            "Connecting to files.pythonhosted.org (files.pythonhosted.org)|151.101.1.63|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 854669 (835K) [binary/octet-stream]\n",
            "Saving to: ‘selenium-3.141.0.tar.gz’\n",
            "\n",
            "selenium-3.141.0.ta 100%[===================>] 834.64K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2020-05-03 00:13:03 (98.8 MB/s) - ‘selenium-3.141.0.tar.gz’ saved [854669/854669]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3jtFPkWflYj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar xf  /content/google-images-download/selenium-3.141.0.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3p0_-2L6f-NF",
        "colab_type": "code",
        "outputId": "bd750f41-46ef-47ae-c8f3-a4c5291bda53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%cd /content/google-images-download/selenium-3.141.0\n",
        "!python3 setup.py install"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/google-images-download/selenium-3.141.0\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "writing selenium.egg-info/PKG-INFO\n",
            "writing dependency_links to selenium.egg-info/dependency_links.txt\n",
            "writing requirements to selenium.egg-info/requires.txt\n",
            "writing top-level names to selenium.egg-info/top_level.txt\n",
            "reading manifest file 'selenium.egg-info/SOURCES.txt'\n",
            "reading manifest template 'MANIFEST.in'\n",
            "warning: no files found matching 'selenium/selenium.py'\n",
            "writing manifest file 'selenium.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/selenium\n",
            "copying selenium/__init__.py -> build/lib/selenium\n",
            "creating build/lib/selenium/common\n",
            "copying selenium/common/__init__.py -> build/lib/selenium/common\n",
            "copying selenium/common/exceptions.py -> build/lib/selenium/common\n",
            "creating build/lib/selenium/webdriver\n",
            "copying selenium/webdriver/__init__.py -> build/lib/selenium/webdriver\n",
            "creating build/lib/selenium/webdriver/android\n",
            "copying selenium/webdriver/android/__init__.py -> build/lib/selenium/webdriver/android\n",
            "copying selenium/webdriver/android/webdriver.py -> build/lib/selenium/webdriver/android\n",
            "creating build/lib/selenium/webdriver/chrome\n",
            "copying selenium/webdriver/chrome/options.py -> build/lib/selenium/webdriver/chrome\n",
            "copying selenium/webdriver/chrome/__init__.py -> build/lib/selenium/webdriver/chrome\n",
            "copying selenium/webdriver/chrome/remote_connection.py -> build/lib/selenium/webdriver/chrome\n",
            "copying selenium/webdriver/chrome/service.py -> build/lib/selenium/webdriver/chrome\n",
            "copying selenium/webdriver/chrome/webdriver.py -> build/lib/selenium/webdriver/chrome\n",
            "creating build/lib/selenium/webdriver/common\n",
            "copying selenium/webdriver/common/keys.py -> build/lib/selenium/webdriver/common\n",
            "copying selenium/webdriver/common/utils.py -> build/lib/selenium/webdriver/common\n",
            "copying selenium/webdriver/common/__init__.py -> build/lib/selenium/webdriver/common\n",
            "copying selenium/webdriver/common/touch_actions.py -> build/lib/selenium/webdriver/common\n",
            "copying selenium/webdriver/common/alert.py -> build/lib/selenium/webdriver/common\n",
            "copying selenium/webdriver/common/proxy.py -> build/lib/selenium/webdriver/common\n",
            "copying selenium/webdriver/common/service.py -> build/lib/selenium/webdriver/common\n",
            "copying selenium/webdriver/common/by.py -> build/lib/selenium/webdriver/common\n",
            "copying selenium/webdriver/common/action_chains.py -> build/lib/selenium/webdriver/common\n",
            "copying selenium/webdriver/common/desired_capabilities.py -> build/lib/selenium/webdriver/common\n",
            "creating build/lib/selenium/webdriver/common/html5\n",
            "copying selenium/webdriver/common/html5/__init__.py -> build/lib/selenium/webdriver/common/html5\n",
            "copying selenium/webdriver/common/html5/application_cache.py -> build/lib/selenium/webdriver/common/html5\n",
            "creating build/lib/selenium/webdriver/support\n",
            "copying selenium/webdriver/support/events.py -> build/lib/selenium/webdriver/support\n",
            "copying selenium/webdriver/support/__init__.py -> build/lib/selenium/webdriver/support\n",
            "copying selenium/webdriver/support/event_firing_webdriver.py -> build/lib/selenium/webdriver/support\n",
            "copying selenium/webdriver/support/ui.py -> build/lib/selenium/webdriver/support\n",
            "copying selenium/webdriver/support/wait.py -> build/lib/selenium/webdriver/support\n",
            "copying selenium/webdriver/support/select.py -> build/lib/selenium/webdriver/support\n",
            "copying selenium/webdriver/support/color.py -> build/lib/selenium/webdriver/support\n",
            "copying selenium/webdriver/support/abstract_event_listener.py -> build/lib/selenium/webdriver/support\n",
            "copying selenium/webdriver/support/expected_conditions.py -> build/lib/selenium/webdriver/support\n",
            "creating build/lib/selenium/webdriver/firefox\n",
            "copying selenium/webdriver/firefox/options.py -> build/lib/selenium/webdriver/firefox\n",
            "copying selenium/webdriver/firefox/__init__.py -> build/lib/selenium/webdriver/firefox\n",
            "copying selenium/webdriver/firefox/extension_connection.py -> build/lib/selenium/webdriver/firefox\n",
            "copying selenium/webdriver/firefox/remote_connection.py -> build/lib/selenium/webdriver/firefox\n",
            "copying selenium/webdriver/firefox/firefox_binary.py -> build/lib/selenium/webdriver/firefox\n",
            "copying selenium/webdriver/firefox/webelement.py -> build/lib/selenium/webdriver/firefox\n",
            "copying selenium/webdriver/firefox/service.py -> build/lib/selenium/webdriver/firefox\n",
            "copying selenium/webdriver/firefox/firefox_profile.py -> build/lib/selenium/webdriver/firefox\n",
            "copying selenium/webdriver/firefox/webdriver.py -> build/lib/selenium/webdriver/firefox\n",
            "creating build/lib/selenium/webdriver/ie\n",
            "copying selenium/webdriver/ie/options.py -> build/lib/selenium/webdriver/ie\n",
            "copying selenium/webdriver/ie/__init__.py -> build/lib/selenium/webdriver/ie\n",
            "copying selenium/webdriver/ie/service.py -> build/lib/selenium/webdriver/ie\n",
            "copying selenium/webdriver/ie/webdriver.py -> build/lib/selenium/webdriver/ie\n",
            "creating build/lib/selenium/webdriver/edge\n",
            "copying selenium/webdriver/edge/options.py -> build/lib/selenium/webdriver/edge\n",
            "copying selenium/webdriver/edge/__init__.py -> build/lib/selenium/webdriver/edge\n",
            "copying selenium/webdriver/edge/service.py -> build/lib/selenium/webdriver/edge\n",
            "copying selenium/webdriver/edge/webdriver.py -> build/lib/selenium/webdriver/edge\n",
            "creating build/lib/selenium/webdriver/opera\n",
            "copying selenium/webdriver/opera/options.py -> build/lib/selenium/webdriver/opera\n",
            "copying selenium/webdriver/opera/__init__.py -> build/lib/selenium/webdriver/opera\n",
            "copying selenium/webdriver/opera/webdriver.py -> build/lib/selenium/webdriver/opera\n",
            "creating build/lib/selenium/webdriver/phantomjs\n",
            "copying selenium/webdriver/phantomjs/__init__.py -> build/lib/selenium/webdriver/phantomjs\n",
            "copying selenium/webdriver/phantomjs/service.py -> build/lib/selenium/webdriver/phantomjs\n",
            "copying selenium/webdriver/phantomjs/webdriver.py -> build/lib/selenium/webdriver/phantomjs\n",
            "creating build/lib/selenium/webdriver/remote\n",
            "copying selenium/webdriver/remote/errorhandler.py -> build/lib/selenium/webdriver/remote\n",
            "copying selenium/webdriver/remote/utils.py -> build/lib/selenium/webdriver/remote\n",
            "copying selenium/webdriver/remote/mobile.py -> build/lib/selenium/webdriver/remote\n",
            "copying selenium/webdriver/remote/__init__.py -> build/lib/selenium/webdriver/remote\n",
            "copying selenium/webdriver/remote/switch_to.py -> build/lib/selenium/webdriver/remote\n",
            "copying selenium/webdriver/remote/remote_connection.py -> build/lib/selenium/webdriver/remote\n",
            "copying selenium/webdriver/remote/webelement.py -> build/lib/selenium/webdriver/remote\n",
            "copying selenium/webdriver/remote/file_detector.py -> build/lib/selenium/webdriver/remote\n",
            "copying selenium/webdriver/remote/command.py -> build/lib/selenium/webdriver/remote\n",
            "copying selenium/webdriver/remote/webdriver.py -> build/lib/selenium/webdriver/remote\n",
            "creating build/lib/selenium/webdriver/blackberry\n",
            "copying selenium/webdriver/blackberry/__init__.py -> build/lib/selenium/webdriver/blackberry\n",
            "copying selenium/webdriver/blackberry/webdriver.py -> build/lib/selenium/webdriver/blackberry\n",
            "creating build/lib/selenium/webdriver/safari\n",
            "copying selenium/webdriver/safari/__init__.py -> build/lib/selenium/webdriver/safari\n",
            "copying selenium/webdriver/safari/permissions.py -> build/lib/selenium/webdriver/safari\n",
            "copying selenium/webdriver/safari/remote_connection.py -> build/lib/selenium/webdriver/safari\n",
            "copying selenium/webdriver/safari/service.py -> build/lib/selenium/webdriver/safari\n",
            "copying selenium/webdriver/safari/webdriver.py -> build/lib/selenium/webdriver/safari\n",
            "creating build/lib/selenium/webdriver/webkitgtk\n",
            "copying selenium/webdriver/webkitgtk/__init__.py -> build/lib/selenium/webdriver/webkitgtk\n",
            "copying selenium/webdriver/webkitgtk/options.py -> build/lib/selenium/webdriver/webkitgtk\n",
            "copying selenium/webdriver/webkitgtk/service.py -> build/lib/selenium/webdriver/webkitgtk\n",
            "copying selenium/webdriver/webkitgtk/webdriver.py -> build/lib/selenium/webdriver/webkitgtk\n",
            "creating build/lib/selenium/webdriver/common/actions\n",
            "copying selenium/webdriver/common/actions/__init__.py -> build/lib/selenium/webdriver/common/actions\n",
            "copying selenium/webdriver/common/actions/action_builder.py -> build/lib/selenium/webdriver/common/actions\n",
            "copying selenium/webdriver/common/actions/input_device.py -> build/lib/selenium/webdriver/common/actions\n",
            "copying selenium/webdriver/common/actions/interaction.py -> build/lib/selenium/webdriver/common/actions\n",
            "copying selenium/webdriver/common/actions/key_actions.py -> build/lib/selenium/webdriver/common/actions\n",
            "copying selenium/webdriver/common/actions/key_input.py -> build/lib/selenium/webdriver/common/actions\n",
            "copying selenium/webdriver/common/actions/mouse_button.py -> build/lib/selenium/webdriver/common/actions\n",
            "copying selenium/webdriver/common/actions/pointer_actions.py -> build/lib/selenium/webdriver/common/actions\n",
            "copying selenium/webdriver/common/actions/pointer_input.py -> build/lib/selenium/webdriver/common/actions\n",
            "copying selenium/webdriver/firefox/webdriver.xpi -> build/lib/selenium/webdriver/firefox\n",
            "copying selenium/webdriver/firefox/webdriver_prefs.json -> build/lib/selenium/webdriver/firefox\n",
            "creating build/lib/selenium/webdriver/firefox/amd64\n",
            "copying selenium/webdriver/firefox/amd64/x_ignore_nofocus.so -> build/lib/selenium/webdriver/firefox/amd64\n",
            "creating build/lib/selenium/webdriver/firefox/x86\n",
            "copying selenium/webdriver/firefox/x86/x_ignore_nofocus.so -> build/lib/selenium/webdriver/firefox/x86\n",
            "copying selenium/webdriver/remote/getAttribute.js -> build/lib/selenium/webdriver/remote\n",
            "copying selenium/webdriver/remote/isDisplayed.js -> build/lib/selenium/webdriver/remote\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/selenium\n",
            "copying build/lib/selenium/__init__.py -> build/bdist.linux-x86_64/egg/selenium\n",
            "creating build/bdist.linux-x86_64/egg/selenium/common\n",
            "copying build/lib/selenium/common/__init__.py -> build/bdist.linux-x86_64/egg/selenium/common\n",
            "copying build/lib/selenium/common/exceptions.py -> build/bdist.linux-x86_64/egg/selenium/common\n",
            "creating build/bdist.linux-x86_64/egg/selenium/webdriver\n",
            "creating build/bdist.linux-x86_64/egg/selenium/webdriver/support\n",
            "copying build/lib/selenium/webdriver/support/events.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/support\n",
            "copying build/lib/selenium/webdriver/support/__init__.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/support\n",
            "copying build/lib/selenium/webdriver/support/event_firing_webdriver.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/support\n",
            "copying build/lib/selenium/webdriver/support/ui.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/support\n",
            "copying build/lib/selenium/webdriver/support/wait.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/support\n",
            "copying build/lib/selenium/webdriver/support/select.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/support\n",
            "copying build/lib/selenium/webdriver/support/color.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/support\n",
            "copying build/lib/selenium/webdriver/support/abstract_event_listener.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/support\n",
            "copying build/lib/selenium/webdriver/support/expected_conditions.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/support\n",
            "creating build/bdist.linux-x86_64/egg/selenium/webdriver/remote\n",
            "copying build/lib/selenium/webdriver/remote/errorhandler.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/remote\n",
            "copying build/lib/selenium/webdriver/remote/utils.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/remote\n",
            "copying build/lib/selenium/webdriver/remote/mobile.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/remote\n",
            "copying build/lib/selenium/webdriver/remote/__init__.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/remote\n",
            "copying build/lib/selenium/webdriver/remote/switch_to.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/remote\n",
            "copying build/lib/selenium/webdriver/remote/remote_connection.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/remote\n",
            "copying build/lib/selenium/webdriver/remote/getAttribute.js -> build/bdist.linux-x86_64/egg/selenium/webdriver/remote\n",
            "copying build/lib/selenium/webdriver/remote/webelement.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/remote\n",
            "copying build/lib/selenium/webdriver/remote/isDisplayed.js -> build/bdist.linux-x86_64/egg/selenium/webdriver/remote\n",
            "copying build/lib/selenium/webdriver/remote/file_detector.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/remote\n",
            "copying build/lib/selenium/webdriver/remote/command.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/remote\n",
            "copying build/lib/selenium/webdriver/remote/webdriver.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/remote\n",
            "creating build/bdist.linux-x86_64/egg/selenium/webdriver/webkitgtk\n",
            "copying build/lib/selenium/webdriver/webkitgtk/options.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/webkitgtk\n",
            "copying build/lib/selenium/webdriver/webkitgtk/__init__.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/webkitgtk\n",
            "copying build/lib/selenium/webdriver/webkitgtk/service.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/webkitgtk\n",
            "copying build/lib/selenium/webdriver/webkitgtk/webdriver.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/webkitgtk\n",
            "copying build/lib/selenium/webdriver/__init__.py -> build/bdist.linux-x86_64/egg/selenium/webdriver\n",
            "creating build/bdist.linux-x86_64/egg/selenium/webdriver/android\n",
            "copying build/lib/selenium/webdriver/android/__init__.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/android\n",
            "copying build/lib/selenium/webdriver/android/webdriver.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/android\n",
            "creating build/bdist.linux-x86_64/egg/selenium/webdriver/common\n",
            "copying build/lib/selenium/webdriver/common/keys.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/common\n",
            "copying build/lib/selenium/webdriver/common/utils.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/common\n",
            "copying build/lib/selenium/webdriver/common/__init__.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/common\n",
            "copying build/lib/selenium/webdriver/common/touch_actions.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/common\n",
            "copying build/lib/selenium/webdriver/common/alert.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/common\n",
            "creating build/bdist.linux-x86_64/egg/selenium/webdriver/common/actions\n",
            "copying build/lib/selenium/webdriver/common/actions/mouse_button.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/common/actions\n",
            "copying build/lib/selenium/webdriver/common/actions/pointer_actions.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/common/actions\n",
            "copying build/lib/selenium/webdriver/common/actions/pointer_input.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/common/actions\n",
            "copying build/lib/selenium/webdriver/common/actions/__init__.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/common/actions\n",
            "copying build/lib/selenium/webdriver/common/actions/input_device.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/common/actions\n",
            "copying build/lib/selenium/webdriver/common/actions/key_actions.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/common/actions\n",
            "copying build/lib/selenium/webdriver/common/actions/key_input.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/common/actions\n",
            "copying build/lib/selenium/webdriver/common/actions/action_builder.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/common/actions\n",
            "copying build/lib/selenium/webdriver/common/actions/interaction.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/common/actions\n",
            "copying build/lib/selenium/webdriver/common/proxy.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/common\n",
            "creating build/bdist.linux-x86_64/egg/selenium/webdriver/common/html5\n",
            "copying build/lib/selenium/webdriver/common/html5/__init__.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/common/html5\n",
            "copying build/lib/selenium/webdriver/common/html5/application_cache.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/common/html5\n",
            "copying build/lib/selenium/webdriver/common/service.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/common\n",
            "copying build/lib/selenium/webdriver/common/by.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/common\n",
            "copying build/lib/selenium/webdriver/common/action_chains.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/common\n",
            "copying build/lib/selenium/webdriver/common/desired_capabilities.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/common\n",
            "creating build/bdist.linux-x86_64/egg/selenium/webdriver/blackberry\n",
            "copying build/lib/selenium/webdriver/blackberry/__init__.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/blackberry\n",
            "copying build/lib/selenium/webdriver/blackberry/webdriver.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/blackberry\n",
            "creating build/bdist.linux-x86_64/egg/selenium/webdriver/ie\n",
            "copying build/lib/selenium/webdriver/ie/options.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/ie\n",
            "copying build/lib/selenium/webdriver/ie/__init__.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/ie\n",
            "copying build/lib/selenium/webdriver/ie/service.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/ie\n",
            "copying build/lib/selenium/webdriver/ie/webdriver.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/ie\n",
            "creating build/bdist.linux-x86_64/egg/selenium/webdriver/edge\n",
            "copying build/lib/selenium/webdriver/edge/options.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/edge\n",
            "copying build/lib/selenium/webdriver/edge/__init__.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/edge\n",
            "copying build/lib/selenium/webdriver/edge/service.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/edge\n",
            "copying build/lib/selenium/webdriver/edge/webdriver.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/edge\n",
            "creating build/bdist.linux-x86_64/egg/selenium/webdriver/chrome\n",
            "copying build/lib/selenium/webdriver/chrome/options.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/chrome\n",
            "copying build/lib/selenium/webdriver/chrome/__init__.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/chrome\n",
            "copying build/lib/selenium/webdriver/chrome/remote_connection.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/chrome\n",
            "copying build/lib/selenium/webdriver/chrome/service.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/chrome\n",
            "copying build/lib/selenium/webdriver/chrome/webdriver.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/chrome\n",
            "creating build/bdist.linux-x86_64/egg/selenium/webdriver/safari\n",
            "copying build/lib/selenium/webdriver/safari/__init__.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/safari\n",
            "copying build/lib/selenium/webdriver/safari/remote_connection.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/safari\n",
            "copying build/lib/selenium/webdriver/safari/service.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/safari\n",
            "copying build/lib/selenium/webdriver/safari/permissions.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/safari\n",
            "copying build/lib/selenium/webdriver/safari/webdriver.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/safari\n",
            "creating build/bdist.linux-x86_64/egg/selenium/webdriver/firefox\n",
            "copying build/lib/selenium/webdriver/firefox/options.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/firefox\n",
            "copying build/lib/selenium/webdriver/firefox/__init__.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/firefox\n",
            "copying build/lib/selenium/webdriver/firefox/extension_connection.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/firefox\n",
            "copying build/lib/selenium/webdriver/firefox/remote_connection.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/firefox\n",
            "copying build/lib/selenium/webdriver/firefox/webdriver_prefs.json -> build/bdist.linux-x86_64/egg/selenium/webdriver/firefox\n",
            "copying build/lib/selenium/webdriver/firefox/firefox_binary.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/firefox\n",
            "copying build/lib/selenium/webdriver/firefox/webelement.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/firefox\n",
            "copying build/lib/selenium/webdriver/firefox/service.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/firefox\n",
            "copying build/lib/selenium/webdriver/firefox/firefox_profile.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/firefox\n",
            "copying build/lib/selenium/webdriver/firefox/webdriver.xpi -> build/bdist.linux-x86_64/egg/selenium/webdriver/firefox\n",
            "creating build/bdist.linux-x86_64/egg/selenium/webdriver/firefox/amd64\n",
            "copying build/lib/selenium/webdriver/firefox/amd64/x_ignore_nofocus.so -> build/bdist.linux-x86_64/egg/selenium/webdriver/firefox/amd64\n",
            "creating build/bdist.linux-x86_64/egg/selenium/webdriver/firefox/x86\n",
            "copying build/lib/selenium/webdriver/firefox/x86/x_ignore_nofocus.so -> build/bdist.linux-x86_64/egg/selenium/webdriver/firefox/x86\n",
            "copying build/lib/selenium/webdriver/firefox/webdriver.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/firefox\n",
            "creating build/bdist.linux-x86_64/egg/selenium/webdriver/phantomjs\n",
            "copying build/lib/selenium/webdriver/phantomjs/__init__.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/phantomjs\n",
            "copying build/lib/selenium/webdriver/phantomjs/service.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/phantomjs\n",
            "copying build/lib/selenium/webdriver/phantomjs/webdriver.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/phantomjs\n",
            "creating build/bdist.linux-x86_64/egg/selenium/webdriver/opera\n",
            "copying build/lib/selenium/webdriver/opera/options.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/opera\n",
            "copying build/lib/selenium/webdriver/opera/__init__.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/opera\n",
            "copying build/lib/selenium/webdriver/opera/webdriver.py -> build/bdist.linux-x86_64/egg/selenium/webdriver/opera\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/common/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/common/exceptions.py to exceptions.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/support/events.py to events.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/support/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/support/event_firing_webdriver.py to event_firing_webdriver.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/support/ui.py to ui.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/support/wait.py to wait.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/support/select.py to select.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/support/color.py to color.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/support/abstract_event_listener.py to abstract_event_listener.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/support/expected_conditions.py to expected_conditions.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/remote/errorhandler.py to errorhandler.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/remote/utils.py to utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/remote/mobile.py to mobile.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/remote/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/remote/switch_to.py to switch_to.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/remote/remote_connection.py to remote_connection.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/remote/webelement.py to webelement.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/remote/file_detector.py to file_detector.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/remote/command.py to command.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/remote/webdriver.py to webdriver.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/webkitgtk/options.py to options.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/webkitgtk/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/webkitgtk/service.py to service.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/webkitgtk/webdriver.py to webdriver.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/android/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/android/webdriver.py to webdriver.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/common/keys.py to keys.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/common/utils.py to utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/common/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/common/touch_actions.py to touch_actions.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/common/alert.py to alert.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/common/actions/mouse_button.py to mouse_button.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/common/actions/pointer_actions.py to pointer_actions.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/common/actions/pointer_input.py to pointer_input.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/common/actions/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/common/actions/input_device.py to input_device.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/common/actions/key_actions.py to key_actions.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/common/actions/key_input.py to key_input.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/common/actions/action_builder.py to action_builder.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/common/actions/interaction.py to interaction.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/common/proxy.py to proxy.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/common/html5/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/common/html5/application_cache.py to application_cache.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/common/service.py to service.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/common/by.py to by.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/common/action_chains.py to action_chains.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/common/desired_capabilities.py to desired_capabilities.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/blackberry/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/blackberry/webdriver.py to webdriver.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/ie/options.py to options.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/ie/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/ie/service.py to service.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/ie/webdriver.py to webdriver.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/edge/options.py to options.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/edge/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/edge/service.py to service.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/edge/webdriver.py to webdriver.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/chrome/options.py to options.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/chrome/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/chrome/remote_connection.py to remote_connection.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/chrome/service.py to service.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/chrome/webdriver.py to webdriver.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/safari/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/safari/remote_connection.py to remote_connection.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/safari/service.py to service.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/safari/permissions.py to permissions.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/safari/webdriver.py to webdriver.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/firefox/options.py to options.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/firefox/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/firefox/extension_connection.py to extension_connection.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/firefox/remote_connection.py to remote_connection.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/firefox/firefox_binary.py to firefox_binary.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/firefox/webelement.py to webelement.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/firefox/service.py to service.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/firefox/firefox_profile.py to firefox_profile.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/firefox/webdriver.py to webdriver.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/phantomjs/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/phantomjs/service.py to service.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/phantomjs/webdriver.py to webdriver.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/opera/options.py to options.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/opera/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/selenium/webdriver/opera/webdriver.py to webdriver.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying selenium.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying selenium.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying selenium.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying selenium.egg-info/not-zip-safe -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying selenium.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying selenium.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "creating dist\n",
            "creating 'dist/selenium-3.141.0-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing selenium-3.141.0-py3.6.egg\n",
            "creating /usr/local/lib/python3.6/dist-packages/selenium-3.141.0-py3.6.egg\n",
            "Extracting selenium-3.141.0-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding selenium 3.141.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/selenium-3.141.0-py3.6.egg\n",
            "Processing dependencies for selenium==3.141.0\n",
            "Searching for urllib3==1.24.3\n",
            "Best match: urllib3 1.24.3\n",
            "Adding urllib3 1.24.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Finished processing dependencies for selenium==3.141.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ox2rvV8JaD33",
        "colab_type": "text"
      },
      "source": [
        "Setting the environment to support the files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYh8Qbc-AoXg",
        "colab_type": "code",
        "outputId": "aa0a4679-104f-4c0b-a6c0-6b6d97433641",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "%cd /content/models/research/\n",
        "! protoc object_detection/protos/*.proto --python_out=.\n",
        "! export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim\n",
        "%set_env PYTHONPATH=/content/models/research/object_detection/\n",
        "%set_env PYTHONPATH=/content/models/research/\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n",
            "env: PYTHONPATH=/content/models/research/object_detection/\n",
            "env: PYTHONPATH=/content/models/research/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdN2mdQ-yqYv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.append('/content/models/research/object_detection/')\n",
        "sys.path.append('/content/models/research/')\n",
        "sys.path.append(\"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/slim\")\n",
        "sys.path.append('/content/google-images-download/')\n",
        "sys.path.append('content/google-images-download/selenium-3.141.0/')\n",
        "os.environ['PYTHONPATH']=os.environ['PYTHONPATH']+':/content/models/research/slim'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbYWAjDBaKCQ",
        "colab_type": "text"
      },
      "source": [
        "Use Tensorflow GPU to train faster than CPU. Seems that only this version works with Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8roA9G7o75JN",
        "colab_type": "code",
        "outputId": "8cc2e38c-b184-4830-c2d3-b5d66f3434f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        }
      },
      "source": [
        "!pip install tensorflow-gpu==1.15.2\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==1.15.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/ca/58e40e5077fa2a92004f398d705a288e958434f123938f4ce75ffe25b64b/tensorflow_gpu-1.15.2-cp36-cp36m-manylinux2010_x86_64.whl (411.0MB)\n",
            "\u001b[K     |████████████████████████████████| 411.0MB 44kB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.28.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.12.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (3.10.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.0.8)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (0.34.2)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 40.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.18.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (0.2.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.12.0)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 50.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (0.8.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (0.9.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (3.2.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.15.2) (46.1.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15.2) (2.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (3.2.1)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=7474127bd3eb216dc5814b28084ee1e2cfa5d3fb4973baf696c111f10012f188\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow 2.2.0rc3 has requirement gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.2.0rc3 has requirement tensorboard<2.3.0,>=2.2.0, but you'll have tensorboard 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.2.0rc3 has requirement tensorflow-estimator<2.3.0,>=2.2.0rc0, but you'll have tensorflow-estimator 1.15.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.10.0rc0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gast, tensorboard, tensorflow-estimator, tensorflow-gpu\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorboard 2.2.1\n",
            "    Uninstalling tensorboard-2.2.1:\n",
            "      Successfully uninstalled tensorboard-2.2.1\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "Successfully installed gast-0.2.2 tensorboard-1.15.0 tensorflow-estimator-1.15.1 tensorflow-gpu-1.15.2\n",
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UohBNMbhaVU7",
        "colab_type": "text"
      },
      "source": [
        "Test the code is working with the environment setup."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCQfgRKmPgGl",
        "colab_type": "code",
        "outputId": "7fa74e90-3012-4d09-99bd-efe21860d7cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        }
      },
      "source": [
        "%cd /content/models/research\n",
        "! python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "Running tests under Python 3.6.9: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTest.test_create_experimental_model\n",
            "[       OK ] ModelBuilderTest.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_rfcn_model_from_config\n",
            "[       OK ] ModelBuilderTest.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTest.test_create_ssd_fpn_model_from_config\n",
            "[       OK ] ModelBuilderTest.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTest.test_create_ssd_models_from_config\n",
            "[       OK ] ModelBuilderTest.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update\n",
            "[       OK ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold\n",
            "[       OK ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_model_config_proto\n",
            "[       OK ] ModelBuilderTest.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_second_stage_batch_size\n",
            "[       OK ] ModelBuilderTest.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTest.test_session\n",
            "[  SKIPPED ] ModelBuilderTest.test_session\n",
            "[ RUN      ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor\n",
            "[       OK ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTest.test_unknown_meta_architecture\n",
            "[       OK ] ModelBuilderTest.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTest.test_unknown_ssd_feature_extractor\n",
            "[       OK ] ModelBuilderTest.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 17 tests in 0.167s\n",
            "\n",
            "OK (skipped=1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVHB7-5VafTU",
        "colab_type": "text"
      },
      "source": [
        "Create directories for retraining the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zj4GUBg2R7rO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "os.mkdir('/content/models/annotations')\n",
        "os.mkdir('/content/models/images')\n",
        "os.mkdir('/content/models/checkpoints')\n",
        "os.mkdir('/content/models/tf_record')\n",
        "#os.mkdir('/content/models/reasearch')\n",
        "os.mkdir('/content/models/annotations/xmls')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tKPK1ED48XZ",
        "colab_type": "text"
      },
      "source": [
        "Download CHromedriver "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GK1HXxzDw54",
        "colab_type": "code",
        "outputId": "4baf8b5c-d3b7-40c6-a6b4-b52fddcf158e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "%cd /content/google-images-download\n",
        "! wget https://chromedriver.storage.googleapis.com/81.0.4044.69/chromedriver_mac64.zip"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/google-images-download\n",
            "--2020-05-03 00:14:39--  https://chromedriver.storage.googleapis.com/81.0.4044.69/chromedriver_mac64.zip\n",
            "Resolving chromedriver.storage.googleapis.com (chromedriver.storage.googleapis.com)... 172.217.14.80, 2607:f8b0:4007:803::2010\n",
            "Connecting to chromedriver.storage.googleapis.com (chromedriver.storage.googleapis.com)|172.217.14.80|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7019279 (6.7M) [application/zip]\n",
            "Saving to: ‘chromedriver_mac64.zip’\n",
            "\n",
            "chromedriver_mac64. 100%[===================>]   6.69M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2020-05-03 00:14:39 (135 MB/s) - ‘chromedriver_mac64.zip’ saved [7019279/7019279]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGbjmiwFEJx4",
        "colab_type": "code",
        "outputId": "f272b9a2-13f6-4057-a589-5bcb87b01c9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\n",
        "!unzip chromedriver_mac64.zip"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  chromedriver_mac64.zip\n",
            "  inflating: chromedriver            \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hi7m9Cr85BQ6",
        "colab_type": "text"
      },
      "source": [
        "download images from google search if images are not in google drive.\n",
        "Image count is 70. Can be changed up to 200.\n",
        "'Corgi' is used to train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQKD4n78UnY1",
        "colab_type": "code",
        "outputId": "f0a800dd-7da1-4196-eac2-036bee82677d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "sys.path.append('/content/google_images_download')\n",
        "%set_env PYTHONPATH=/content/google_images_download/\n",
        "\n",
        "from google_images_download import google_images_download   #importing the library\n",
        "\n",
        "response = google_images_download.googleimagesdownload()   #class instantiation\n",
        "image_count = 100\n",
        "arguments = {\"keywords\":\"corgi\",\"limit\":image_count,\"print_urls\":True}   #creating list of arguments\n",
        "paths = response.download(arguments)   #passing the arguments to the function\n",
        "print(paths)   #printing absolute paths of the downloaded images"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: PYTHONPATH=/content/google_images_download/\n",
            "\n",
            "Item no.: 1 --> Item name = corgi\n",
            "Evaluating...\n",
            "Starting Download...\n",
            "Image URL: https://s3.amazonaws.com/cdn-origin-etr.akc.org/wp-content/uploads/2017/11/25201637/day_2_dec_14_085.jpg\n",
            "Completed Image ====> 1.day_2_dec_14_085.jpg\n",
            "Image URL: https://upload.wikimedia.org/wikipedia/commons/f/fb/Welchcorgipembroke.JPG\n",
            "Invalid or missing image format. Skipping...\n",
            "Image URL: https://upload.wikimedia.org/wikipedia/commons/2/2b/WelshCorgi.jpeg\n",
            "Completed Image ====> 2.WelshCorgi.jpeg\n",
            "Image URL: https://cdn1-www.dogtime.com/assets/uploads/gallery/pembroke-welsh-corgi-dog-breed-pictures/prance-8.jpg\n",
            "Completed Image ====> 3.prance-8.jpg\n",
            "Image URL: https://s3.amazonaws.com/cdn-origin-etr.akc.org/wp-content/uploads/2017/11/29172137/Pembroke-Welsh-Corgi-puppy.jpg\n",
            "Completed Image ====> 4.Pembroke-Welsh-Corgi-puppy.jpg\n",
            "Image URL: https://images-na.ssl-images-amazon.com/images/I/715VUc4IDCL.jpg\n",
            "Completed Image ====> 5.715VUc4IDCL.jpg\n",
            "Image URL: https://cdn1-www.dogtime.com/assets/uploads/2011/01/file_23192_pembroke-welsh-corgi-460x290.jpg\n",
            "Completed Image ====> 6.file_23192_pembroke-welsh-corgi-460x290.jpg\n",
            "Image URL: https://www.thesprucepets.com/thmb/Mn97CATmMX-N5qkl1aHC0ZbWhu8=/960x0/filters:no_upscale():max_bytes(150000):strip_icc()/19933184_104417643500613_5541725731421159424_n-5ba0548546e0fb0050edecc0.jpg\n",
            "Completed Image ====> 7.19933184_104417643500613_5541725731421159424_n-5ba0548546e0fb0050edecc0.jpg\n",
            "Image URL: https://cmkt-image-prd.freetls.fastly.net/0.1.0/ps/7537916/910/1299/m2/fpnw/wm1/z4qlovxhgjcsupdej1qfq1mhmre5lxj9nsfymaxawgbkurwt9pttwpiyw1nqbrjy-.jpg?1578167361&s=e895efae1fbce28a4d65cb25a001f5cd\n",
            "Invalid or missing image format. Skipping...\n",
            "Image URL: https://images.radio.com/aiu-media/GettyImages1061822700-eb517cd2-387f-4448-ab1b-759627ede846.jpg?width=800\n",
            "Invalid or missing image format. Skipping...\n",
            "Image URL: https://images-na.ssl-images-amazon.com/images/I/718vecXok%2BL.jpg\n",
            "Completed Image ====> 8.718vecXok%2BL.jpg\n",
            "Image URL: https://www.rover.com/blog/wp-content/uploads/2019/01/6342530545_45ec8696c8_b-960x540.jpg\n",
            "Completed Image ====> 9.6342530545_45ec8696c8_b-960x540.jpg\n",
            "Image URL: https://photos.puppyspot.com/2/listing/629262/photo/5443948_large-resize.jpg\n",
            "Completed Image ====> 10.5443948_large-resize.jpg\n",
            "Image URL: https://www.loveyourdog.com/wp-content/uploads/2019/10/Best-Corgi-Harness-900x500.jpg\n",
            "Completed Image ====> 11.Best-Corgi-Harness-900x500.jpg\n",
            "Image URL: https://animals.net/wp-content/uploads/2018/07/Pembroke-Welsh-Corgi-3-650x425.jpg\n",
            "Completed Image ====> 12.Pembroke-Welsh-Corgi-3-650x425.jpg\n",
            "Image URL: https://lookaside.fbsbx.com/lookaside/crawler/media/?media_id=2629535270442379\n",
            "Invalid or missing image format. Skipping...\n",
            "Image URL: https://d1941uuft27pfg.cloudfront.net/breed-uploads/2018/08/pembroke-welsh-corgi-card-small.jpg?bust=1535568082\n",
            "Invalid or missing image format. Skipping...\n",
            "Image URL: https://www.thesprucepets.com/thmb/svw9xgcobToAwVEmK-WhFYPNZfM=/1500x1000/filters:fill(auto,1)/breed_profile_corgi_1117986_hero_917-6ed2ed41b6e641bb98221b13a1d83a86.jpg\n",
            "Completed Image ====> 13.breed_profile_corgi_1117986_hero_917-6ed2ed41b6e641bb98221b13a1d83a86.jpg\n",
            "Image URL: https://dqzrr9k4bjpzk.cloudfront.net/images/18976117/1200340866.jpg\n",
            "Completed Image ====> 14.1200340866.jpg\n",
            "Image URL: https://s3.amazonaws.com/cdn-origin-etr.akc.org/wp-content/uploads/2019/02/19131712/NomNomNow_Pembroke_Welsh_Corgis.jpeg\n",
            "Completed Image ====> 15.NomNomNow_Pembroke_Welsh_Corgis.jpeg\n",
            "Image URL: https://vetstreet.brightspotcdn.com/dims4/default/79f1bd2/2147483647/crop/0x0%2B0%2B0/resize/645x380/quality/90/?url=https%3A%2F%2Fvetstreet-brightspot.s3.amazonaws.com%2F83%2F9e8de0a7f411e0a0d50050568d634f%2Ffile%2FPembroke-Welsh-Corgi-3-645mk62711.jpg\n",
            "Completed Image ====> 16.?url=https%3A%2F%2Fvetstreet-brightspot.s3.amazonaws.com%2F83%2F9e8de0a7f411e0a0d50050568d634f%2Ffile%2FPembroke-Welsh-Corgi-3-645mk62711.jpg\n",
            "Image URL: https://photos.puppyspot.com/5/listing/629245/photo/5438671_large-resize.jpg\n",
            "Completed Image ====> 17.5438671_large-resize.jpg\n",
            "Image URL: https://indulgeyourpet.com/wp-content/uploads/Pembroke-Welsh-Corgi.png\n",
            "Completed Image ====> 18.Pembroke-Welsh-Corgi.png\n",
            "Image URL: https://i0.wp.com/www.wagpets.com/wp-content/uploads/2020/04/the-pembroke-welsh-corgi-an-energetic-and-eager-t.jpeg?fit=1172%2C754&ssl=1\n",
            "Invalid or missing image format. Skipping...\n",
            "Image URL: https://www.handicappedpets.com/wp-content/uploads/2018/09/corgi-wc-main.jpg\n",
            "Completed Image ====> 19.corgi-wc-main.jpg\n",
            "Image URL: http://cdn.akc.org/content/hero/corgis_harvey_hero.jpg\n",
            "Completed Image ====> 20.corgis_harvey_hero.jpg\n",
            "Image URL: https://www.rover.com/blog/wp-content/uploads/2018/11/running-corgi-puppy.jpg\n",
            "Completed Image ====> 21.running-corgi-puppy.jpg\n",
            "Image URL: https://i.pinimg.com/736x/2a/e9/a4/2ae9a40b4363e74554dcae603cd8356d.jpg\n",
            "Completed Image ====> 22.2ae9a40b4363e74554dcae603cd8356d.jpg\n",
            "Image URL: https://images-na.ssl-images-amazon.com/images/I/7101JLFc5tL.jpg\n",
            "Completed Image ====> 23.7101JLFc5tL.jpg\n",
            "Image URL: https://d2oe4uttdfvoiw.cloudfront.net/pictures/breeds/hLubW742T5S8PyESpRdW/500x500-16_Pembroke-Welsh%20Corgi-1542813595505.png\n",
            "Completed Image ====> 24.500x500-16_Pembroke-Welsh%20Corgi-1542813595505.png\n",
            "Image URL: https://cdn11.bigcommerce.com/s-g1all5e/images/stencil/1280x1280/products/974/3755/1144__62770.1536857804.JPG?c=2&imbypass=on\n",
            "Invalid or missing image format. Skipping...\n",
            "Image URL: https://thenypost.files.wordpress.com/2013/11/corgi.jpg?quality=80&strip=all&w=618&h=410&crop=1\n",
            "Invalid or missing image format. Skipping...\n",
            "Image URL: https://www.rover.com/blog/wp-content/uploads/2014/07/corgi-dog-smiling.jpg\n",
            "Completed Image ====> 25.corgi-dog-smiling.jpg\n",
            "Image URL: https://images2.minutemediacdn.com/image/upload/c_crop,h_1415,w_2103,x_8,y_0/v1554738239/shape/mentalfloss/63484-istock-533859316.jpg?itok=6yuSJ39P\n",
            "Invalid or missing image format. Skipping...\n",
            "Image URL: https://animals.net/wp-content/uploads/2018/07/Cardigan-Corgi-5-650x425.jpg\n",
            "Completed Image ====> 26.Cardigan-Corgi-5-650x425.jpg\n",
            "Image URL: https://thenypost.files.wordpress.com/2019/10/corgi-05.jpeg?quality=80&strip=all\n",
            "Invalid or missing image format. Skipping...\n",
            "Image URL: https://s3.amazonaws.com/cdn-origin-etr.akc.org/wp-content/uploads/2017/11/04202304/Cardigan-Welsh-Corgi-on-White-111-400x267.jpg\n",
            "Completed Image ====> 27.Cardigan-Welsh-Corgi-on-White-111-400x267.jpg\n",
            "Image URL: https://www.thesprucepets.com/thmb/46A_mR1SQxiDNJ6MgZT-9cQwDQ8=/1500x1000/filters:fill(auto,1)/GettyImages-506513232-ddf4848f66de48c1b0b9a82ace2dddce.jpg\n",
            "Completed Image ====> 28.GettyImages-506513232-ddf4848f66de48c1b0b9a82ace2dddce.jpg\n",
            "Image URL: https://www.petlandsarasota.com/wp-content/uploads/2017/05/corgi-puppies-300x186.jpg\n",
            "Completed Image ====> 29.corgi-puppies-300x186.jpg\n",
            "Image URL: https://www.holidogtimes.com/wp-content/uploads/2017/12/corgi-raisons-fi.png\n",
            "Completed Image ====> 30.corgi-raisons-fi.png\n",
            "Image URL: https://i.insider.com/528127d66bb3f7c12136f884?width=1100&format=jpeg&auto=webp\n",
            "Invalid or missing image format. Skipping...\n",
            "Image URL: https://static.boredpanda.com/blog/wp-content/uploads/2020/03/corgis-22-5e5d2542f2ef9__700.jpg\n",
            "Completed Image ====> 31.corgis-22-5e5d2542f2ef9__700.jpg\n",
            "Image URL: https://www.loveyourdog.com/wp-content/uploads/2019/07/Cardigan-Welsh-Corgi-vs-Pembroke-Welsh-Corgi-900x500.jpg\n",
            "Completed Image ====> 32.Cardigan-Welsh-Corgi-vs-Pembroke-Welsh-Corgi-900x500.jpg\n",
            "Image URL: https://cdn11.bigcommerce.com/s-oe2q4reh/images/stencil/2048x2048/products/797/1319/Welsh_Corgi_Puppy__22550.1568515983.jpg?c=2\n",
            "Invalid or missing image format. Skipping...\n",
            "Image URL: https://i.insider.com/5acbd14afacba849008b45cf?width=1100&format=jpeg&auto=webp\n",
            "Invalid or missing image format. Skipping...\n",
            "Image URL: https://lookaside.fbsbx.com/lookaside/crawler/media/?media_id=193261104069820\n",
            "Invalid or missing image format. Skipping...\n",
            "Image URL: https://i1.wp.com/bestlifeonline.com/wp-content/uploads/2018/06/sherlock-the-corgi.jpg?resize=640%2C360&ssl=1\n",
            "Invalid or missing image format. Skipping...\n",
            "Image URL: https://i.pinimg.com/originals/37/54/d6/3754d6fbdcbc1b553f6a22124f566320.png\n",
            "Completed Image ====> 33.3754d6fbdcbc1b553f6a22124f566320.png\n",
            "Image URL: https://cdn1-www.dogtime.com/assets/uploads/2020/01/golden-retriever-corgi-mixed-dog-breed-pictures-1.jpg\n",
            "Completed Image ====> 34.golden-retriever-corgi-mixed-dog-breed-pictures-1.jpg\n",
            "Image URL: https://i.barkpost.com/wp-content/uploads/2019/06/corgi-by-the-beach-again.jpg?q=70&fit=crop&crop=entropy&w=808&h=500\n",
            "Invalid or missing image format. Skipping...\n",
            "Image URL: https://ih1.redbubble.net/image.439646371.5865/fpp,small,lustre,wall_texture,product,750x1000.u3.jpg\n",
            "Completed Image ====> 35.fpp,small,lustre,wall_texture,product,750x1000.u3.jpg\n",
            "Image URL: https://ca-times.brightspotcdn.com/dims4/default/c04b493/2147483647/strip/true/crop/2644x1911+0+0/resize/1486x1074!/quality/90/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F20%2Fcb%2Ff86ac1dc495cb5a86a13d5b0edc2%2F500219-me-city-beat-homeless-foster-corgi-jja-0001.JPG\n",
            "Invalid or missing image format. Skipping...\n",
            "Image URL: https://thenypost.files.wordpress.com/2019/03/corgi1.jpg?quality=80&strip=all\n",
            "Invalid or missing image format. Skipping...\n",
            "Image URL: https://thehappypuppysite.com/wp-content/uploads/2018/05/Pembroke-Welsh-Corgi-HP-long.jpg\n",
            "Completed Image ====> 36.Pembroke-Welsh-Corgi-HP-long.jpg\n",
            "Image URL: https://douglascuddletoy.com/wp-content/uploads/2019/01/2419.jpg\n",
            "URLError on an image...trying next one... Error: <urlopen error _ssl.c:835: The handshake operation timed out>\n",
            "Image URL: https://i.ytimg.com/vi/5DKhjLZLiio/maxresdefault.jpg\n",
            "Completed Image ====> 37.maxresdefault.jpg\n",
            "Image URL: https://kaethe-wohlfahrt.com/out/pictures/master/product/1/753413.png\n",
            "Completed Image ====> 38.753413.png\n",
            "Image URL: https://www.keystonepuppies.com/wp-content/uploads/2018/10/Welsh-Corgi-Category-1024x707.jpg\n",
            "Completed Image ====> 39.Welsh-Corgi-Category-1024x707.jpg\n",
            "Image URL: https://lookaside.fbsbx.com/lookaside/crawler/media/?media_id=10156701897133356\n",
            "Invalid or missing image format. Skipping...\n",
            "Image URL: https://imagesvc.meredithcorp.io/v3/mm/image?url=https%3A%2F%2Fstatic.onecms.io%2Fwp-content%2Fuploads%2Fsites%2F37%2F2017%2F05%2F15215238%2F102997431.jpg&q=85\n",
            "Invalid or missing image format. Skipping...\n",
            "Image URL: https://previews.123rf.com/images/reamonn/reamonn1803/reamonn180300010/98110296-pembroke-welsh-corgi-puppy-outdoors-in-winter.jpg\n",
            "Completed Image ====> 40.98110296-pembroke-welsh-corgi-puppy-outdoors-in-winter.jpg\n",
            "Image URL: https://cdn.orvis.com/images/DBS_CarWelCor_1280.jpg\n",
            "Completed Image ====> 41.DBS_CarWelCor_1280.jpg\n",
            "Image URL: http://dogell.com/uploads/breed/thumb_pembroke-welsh-corgi.jpg\n",
            "Completed Image ====> 42.thumb_pembroke-welsh-corgi.jpg\n",
            "Image URL: https://petsnurturing.com/wp-content/uploads/2019/10/Pembroke-Welsh-Corgi3-e1571970227649.jpg\n",
            "Completed Image ====> 43.Pembroke-Welsh-Corgi3-e1571970227649.jpg\n",
            "Image URL: https://i.etsystatic.com/13844389/r/il/6aa2f1/1861897922/il_570xN.1861897922_tkfs.jpg\n",
            "Completed Image ====> 44.il_570xN.1861897922_tkfs.jpg\n",
            "Image URL: https://previews.123rf.com/images/photodeti/photodeti1805/photodeti180500409/101213186-happy-brown-pembroke-welsh-corgi-puppy-looking-at-camera-isolated-on-white-background-.jpg\n",
            "Completed Image ====> 45.101213186-happy-brown-pembroke-welsh-corgi-puppy-looking-at-camera-isolated-on-white-background-.jpg\n",
            "Image URL: https://i.ytimg.com/vi/sjydlB7bFQE/maxresdefault.jpg\n",
            "Completed Image ====> 46.maxresdefault.jpg\n",
            "Image URL: https://bloximages.newyork1.vip.townnews.com/purdueexponent.org/content/tncms/assets/v3/editorial/c/83/c833edec-edfa-11e9-a2f9-33bcd410677f/5da38d90c6dd0.image.jpg?resize=1200%2C800\n",
            "Invalid or missing image format. Skipping...\n",
            "Image URL: https://www.loveyourdog.com/wp-content/uploads/2019/09/Pitbull-Corgi-Mix-900x500.jpg\n",
            "Completed Image ====> 47.Pitbull-Corgi-Mix-900x500.jpg\n",
            "Image URL: https://cdn.orvis.com/images/DBS_PemWelCor_1280.jpg\n",
            "Completed Image ====> 48.DBS_PemWelCor_1280.jpg\n",
            "Image URL: https://images.unsplash.com/photo-1526137966266-60618b40bcd4?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&w=1000&q=80\n",
            "Invalid or missing image format. Skipping...\n",
            "Image URL: https://www.sidewalkdog.com/wp-content/uploads/2020/02/47326531_262339401121041_7183643058112561152_o.jpg\n",
            "Completed Image ====> 49.47326531_262339401121041_7183643058112561152_o.jpg\n",
            "Image URL: https://images-na.ssl-images-amazon.com/images/I/61RmpE6ycvL._AC_SY355_.jpg\n",
            "Completed Image ====> 50.61RmpE6ycvL._AC_SY355_.jpg\n",
            "Image URL: https://kbimages1-a.akamaihd.net/6a2bae5b-20b6-44f0-b695-05c7f1d439a2/1200/1200/False/a-beginners-guide-to-pembroke-welsh-corgis.jpg\n",
            "Completed Image ====> 51.a-beginners-guide-to-pembroke-welsh-corgis.jpg\n",
            "Image URL: https://i.ytimg.com/vi/RlMSovrWhn8/maxresdefault.jpg\n",
            "Completed Image ====> 52.maxresdefault.jpg\n",
            "Image URL: https://creativelyuncorked.com/wp-content/uploads/Corgi-Butt.jpg\n",
            "Completed Image ====> 53.Corgi-Butt.jpg\n",
            "Image URL: https://gfp-2a3tnpzj.stackpathdns.com/wp-content/uploads/2016/07/Pembroke-Welsh-Corgi-2-1600x700.jpg\n",
            "Completed Image ====> 54.Pembroke-Welsh-Corgi-2-1600x700.jpg\n",
            "Image URL: https://cheappuppiesforsalenearme.com/wp-content/uploads/2019/11/Pembroke-Welsh-Corgi.jpg\n",
            "Completed Image ====> 55.Pembroke-Welsh-Corgi.jpg\n",
            "Image URL: https://media.nextechclassifieds.com/img/listings/vl/vlsheets/listing_pic_1715247_1572496527.jpeg\n",
            "Completed Image ====> 56.listing_pic_1715247_1572496527.jpeg\n",
            "Image URL: https://cdn11.bigcommerce.com/s-n8fmp/images/stencil/1280x1280/products/8658/14331/Capture__79759.1555962682.JPG?c=2\n",
            "Invalid or missing image format. Skipping...\n",
            "Image URL: https://images.fineartamerica.com/images/artworkimages/mediumlarge/1/corgi-golfers-pembroke-welsh-corgi-lyn-cook.jpg\n",
            "Completed Image ====> 57.corgi-golfers-pembroke-welsh-corgi-lyn-cook.jpg\n",
            "Image URL: https://i.etsystatic.com/6635261/r/il/6c4be8/1425779896/il_570xN.1425779896_7jba.jpg\n",
            "Completed Image ====> 58.il_570xN.1425779896_7jba.jpg\n",
            "Image URL: https://www.carsonvet.com/sites/default/files/styles/large/adaptive-image/public/pembroke-welsh-corgi-dog-breed-info_0.jpg?itok=UZ9ePBvk\n",
            "Invalid or missing image format. Skipping...\n",
            "Image URL: https://media.nextechclassifieds.com/img/listings/ho/horseypal/listing_pic_1333696_1577209221.jpeg\n",
            "Completed Image ====> 59.listing_pic_1333696_1577209221.jpeg\n",
            "Image URL: https://i.pinimg.com/originals/4f/d5/b3/4fd5b335809133575bac1dffdd272bb8.jpg\n",
            "Completed Image ====> 60.4fd5b335809133575bac1dffdd272bb8.jpg\n",
            "Image URL: https://cdn.shortpixel.ai/spai/w_977+q_lossless+ret_img+to_webp/https://www.k9ofmine.com/wp-content/uploads/2017/03/corgi-mixed-breeds-1150x700.jpg\n",
            "Completed Image ====> 61.corgi-mixed-breeds-1150x700.jpg\n",
            "Image URL: https://cdn.vox-cdn.com/thumbor/woPLRIC0T-ra6cxxq6CDAbI4Guw=/0x0:3482x2511/1200x675/filters:focal(1792x904:2348x1460)/cdn.vox-cdn.com/uploads/chorus_image/image/65122848/GettyImages_1146389509.0.jpg\n",
            "Completed Image ====> 62.GettyImages_1146389509.0.jpg\n",
            "Image URL: https://t1.ea.ltmcdn.com/en/razas/0/5/5/img_550_pembroke-welsh-corgi_0_600.jpg\n",
            "Completed Image ====> 63.img_550_pembroke-welsh-corgi_0_600.jpg\n",
            "Image URL: https://previews.123rf.com/images/reamonn/reamonn1711/reamonn171100005/90112065-pembroke-welsh-corgi-puppy.jpg\n",
            "Completed Image ====> 64.90112065-pembroke-welsh-corgi-puppy.jpg\n",
            "Image URL: https://s3.envato.com/files/274284817/up_03__00009.jpg\n",
            "Completed Image ====> 65.up_03__00009.jpg\n",
            "Image URL: https://ih1.redbubble.net/image.474852050.1683/flat,750x1000,075,f.u2.jpg\n",
            "Completed Image ====> 66.flat,750x1000,075,f.u2.jpg\n",
            "Image URL: https://dogstruggles.com/wp-content/uploads/2018/09/best_food_for_corgi_puppy_dogstruggles.jpg\n",
            "Completed Image ====> 67.best_food_for_corgi_puppy_dogstruggles.jpg\n",
            "Image URL: https://www.thesprucepets.com/thmb/3dF7d-nxYqKk2zs5X0HFLn8ki3w=/960x0/filters:no_upscale():max_bytes(150000):strip_icc()/40926432_560505141051912_3896594467564281999_n-5ba052bac9e77c0050e669bb.jpg\n",
            "Completed Image ====> 68.40926432_560505141051912_3896594467564281999_n-5ba052bac9e77c0050e669bb.jpg\n",
            "Image URL: https://cmkt-image-prd.freetls.fastly.net/0.1.0/ps/7604279/910/607/m2/fpnw/wm1/jdr0vaarsuxoz2dndzut4obvd992uiwdrjzrxacbukqhgpasymdadqilszoj4g0n-.jpg?1579233355&s=7ec16557248ce3811172902d5fb4b2ba\n",
            "Invalid or missing image format. Skipping...\n",
            "Image URL: https://slimages.macysassets.com/is/image/MCY/products/1/optimized/16173961_fpx.tif?op_sharpen=1&wid=500&hei=613&fit=fit,1&$filtersm$\n",
            "Invalid or missing image format. Skipping...\n",
            "Image URL: https://photos.puppyspot.com/6/listing/624026/photo/5242327_medium.jpg\n",
            "Completed Image ====> 69.5242327_medium.jpg\n",
            "Image URL: https://www.rover.com/blog/wp-content/uploads/2019/10/corgi-4267251_1280.jpg\n",
            "Completed Image ====> 70.corgi-4267251_1280.jpg\n",
            "Image URL: https://cdn.drmartypets.com/wp-content/uploads/2018/10/AdobeStock_178852279.jpeg\n",
            "Completed Image ====> 71.AdobeStock_178852279.jpeg\n",
            "Image URL: https://lookaside.fbsbx.com/lookaside/crawler/media/?media_id=1014691848919705\n",
            "Invalid or missing image format. Skipping...\n",
            "Image URL: https://www.shoutfactory.com/s3_images/images/19741/div_96/documents/d96c17r19741/CorgiXmas_DVD_Cover_72dpi.jpg\n",
            "Completed Image ====> 72.CorgiXmas_DVD_Cover_72dpi.jpg\n",
            "\n",
            "\n",
            "Unfortunately all 100 could not be downloaded because some images were not downloadable. 72 is all we got for this search filter!\n",
            "\n",
            "Errors: 28\n",
            "\n",
            "({'corgi': ['/content/google-images-download/downloads/corgi/1.day_2_dec_14_085.jpg', '/content/google-images-download/downloads/corgi/2.WelshCorgi.jpeg', '/content/google-images-download/downloads/corgi/3.prance-8.jpg', '/content/google-images-download/downloads/corgi/4.Pembroke-Welsh-Corgi-puppy.jpg', '/content/google-images-download/downloads/corgi/5.715VUc4IDCL.jpg', '/content/google-images-download/downloads/corgi/6.file_23192_pembroke-welsh-corgi-460x290.jpg', '/content/google-images-download/downloads/corgi/7.19933184_104417643500613_5541725731421159424_n-5ba0548546e0fb0050edecc0.jpg', '/content/google-images-download/downloads/corgi/8.718vecXok%2BL.jpg', '/content/google-images-download/downloads/corgi/9.6342530545_45ec8696c8_b-960x540.jpg', '/content/google-images-download/downloads/corgi/10.5443948_large-resize.jpg', '/content/google-images-download/downloads/corgi/11.Best-Corgi-Harness-900x500.jpg', '/content/google-images-download/downloads/corgi/12.Pembroke-Welsh-Corgi-3-650x425.jpg', '/content/google-images-download/downloads/corgi/13.breed_profile_corgi_1117986_hero_917-6ed2ed41b6e641bb98221b13a1d83a86.jpg', '/content/google-images-download/downloads/corgi/14.1200340866.jpg', '/content/google-images-download/downloads/corgi/15.NomNomNow_Pembroke_Welsh_Corgis.jpeg', '/content/google-images-download/downloads/corgi/16.?url=https%3A%2F%2Fvetstreet-brightspot.s3.amazonaws.com%2F83%2F9e8de0a7f411e0a0d50050568d634f%2Ffile%2FPembroke-Welsh-Corgi-3-645mk62711.jpg', '/content/google-images-download/downloads/corgi/17.5438671_large-resize.jpg', '/content/google-images-download/downloads/corgi/18.Pembroke-Welsh-Corgi.png', '/content/google-images-download/downloads/corgi/19.corgi-wc-main.jpg', '/content/google-images-download/downloads/corgi/20.corgis_harvey_hero.jpg', '/content/google-images-download/downloads/corgi/21.running-corgi-puppy.jpg', '/content/google-images-download/downloads/corgi/22.2ae9a40b4363e74554dcae603cd8356d.jpg', '/content/google-images-download/downloads/corgi/23.7101JLFc5tL.jpg', '/content/google-images-download/downloads/corgi/24.500x500-16_Pembroke-Welsh%20Corgi-1542813595505.png', '/content/google-images-download/downloads/corgi/25.corgi-dog-smiling.jpg', '/content/google-images-download/downloads/corgi/26.Cardigan-Corgi-5-650x425.jpg', '/content/google-images-download/downloads/corgi/27.Cardigan-Welsh-Corgi-on-White-111-400x267.jpg', '/content/google-images-download/downloads/corgi/28.GettyImages-506513232-ddf4848f66de48c1b0b9a82ace2dddce.jpg', '/content/google-images-download/downloads/corgi/29.corgi-puppies-300x186.jpg', '/content/google-images-download/downloads/corgi/30.corgi-raisons-fi.png', '/content/google-images-download/downloads/corgi/31.corgis-22-5e5d2542f2ef9__700.jpg', '/content/google-images-download/downloads/corgi/32.Cardigan-Welsh-Corgi-vs-Pembroke-Welsh-Corgi-900x500.jpg', '/content/google-images-download/downloads/corgi/33.3754d6fbdcbc1b553f6a22124f566320.png', '/content/google-images-download/downloads/corgi/34.golden-retriever-corgi-mixed-dog-breed-pictures-1.jpg', '/content/google-images-download/downloads/corgi/35.fpp,small,lustre,wall_texture,product,750x1000.u3.jpg', '/content/google-images-download/downloads/corgi/36.Pembroke-Welsh-Corgi-HP-long.jpg', '/content/google-images-download/downloads/corgi/37.maxresdefault.jpg', '/content/google-images-download/downloads/corgi/38.753413.png', '/content/google-images-download/downloads/corgi/39.Welsh-Corgi-Category-1024x707.jpg', '/content/google-images-download/downloads/corgi/40.98110296-pembroke-welsh-corgi-puppy-outdoors-in-winter.jpg', '/content/google-images-download/downloads/corgi/41.DBS_CarWelCor_1280.jpg', '/content/google-images-download/downloads/corgi/42.thumb_pembroke-welsh-corgi.jpg', '/content/google-images-download/downloads/corgi/43.Pembroke-Welsh-Corgi3-e1571970227649.jpg', '/content/google-images-download/downloads/corgi/44.il_570xN.1861897922_tkfs.jpg', '/content/google-images-download/downloads/corgi/45.101213186-happy-brown-pembroke-welsh-corgi-puppy-looking-at-camera-isolated-on-white-background-.jpg', '/content/google-images-download/downloads/corgi/46.maxresdefault.jpg', '/content/google-images-download/downloads/corgi/47.Pitbull-Corgi-Mix-900x500.jpg', '/content/google-images-download/downloads/corgi/48.DBS_PemWelCor_1280.jpg', '/content/google-images-download/downloads/corgi/49.47326531_262339401121041_7183643058112561152_o.jpg', '/content/google-images-download/downloads/corgi/50.61RmpE6ycvL._AC_SY355_.jpg', '/content/google-images-download/downloads/corgi/51.a-beginners-guide-to-pembroke-welsh-corgis.jpg', '/content/google-images-download/downloads/corgi/52.maxresdefault.jpg', '/content/google-images-download/downloads/corgi/53.Corgi-Butt.jpg', '/content/google-images-download/downloads/corgi/54.Pembroke-Welsh-Corgi-2-1600x700.jpg', '/content/google-images-download/downloads/corgi/55.Pembroke-Welsh-Corgi.jpg', '/content/google-images-download/downloads/corgi/56.listing_pic_1715247_1572496527.jpeg', '/content/google-images-download/downloads/corgi/57.corgi-golfers-pembroke-welsh-corgi-lyn-cook.jpg', '/content/google-images-download/downloads/corgi/58.il_570xN.1425779896_7jba.jpg', '/content/google-images-download/downloads/corgi/59.listing_pic_1333696_1577209221.jpeg', '/content/google-images-download/downloads/corgi/60.4fd5b335809133575bac1dffdd272bb8.jpg', '/content/google-images-download/downloads/corgi/61.corgi-mixed-breeds-1150x700.jpg', '/content/google-images-download/downloads/corgi/62.GettyImages_1146389509.0.jpg', '/content/google-images-download/downloads/corgi/63.img_550_pembroke-welsh-corgi_0_600.jpg', '/content/google-images-download/downloads/corgi/64.90112065-pembroke-welsh-corgi-puppy.jpg', '/content/google-images-download/downloads/corgi/65.up_03__00009.jpg', '/content/google-images-download/downloads/corgi/66.flat,750x1000,075,f.u2.jpg', '/content/google-images-download/downloads/corgi/67.best_food_for_corgi_puppy_dogstruggles.jpg', '/content/google-images-download/downloads/corgi/68.40926432_560505141051912_3896594467564281999_n-5ba052bac9e77c0050e669bb.jpg', '/content/google-images-download/downloads/corgi/69.5242327_medium.jpg', '/content/google-images-download/downloads/corgi/70.corgi-4267251_1280.jpg', '/content/google-images-download/downloads/corgi/71.AdobeStock_178852279.jpeg', '/content/google-images-download/downloads/corgi/72.CorgiXmas_DVD_Cover_72dpi.jpg']}, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92ROzEJTPpDK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# rename files to be numeric filename for training the model\n",
        "path = '/content/google-images-download/downloads/corgi/'\n",
        "counter = 1\n",
        "for f in os.listdir(path):\n",
        "    suffix = f.split('.')[-1]\n",
        "    if suffix == 'jpg' or suffix == 'png':\n",
        "        new = '{}.{}'.format(str(counter), suffix)\n",
        "        os.rename(path +f, path + new)\n",
        "        counter = int(counter) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcdvAucjclWQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# upload images from Colab to Google Drive for storage\n",
        "from shutil import copyfile\n",
        "for x in os.listdir('/content/google-images-download/downloads/corgi'):\n",
        "  copyfile('/content/google-images-download/downloads/corgi/'+x, '/content/drive/My Drive/Colab Notebooks/image_retrainssd/images/'+x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Xt-d9V5azBs",
        "colab_type": "text"
      },
      "source": [
        "Setup the link with Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0cDpjlT41jI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# copy images from google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4rfHpWBBE10",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_count=140"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Y4E5IUA8Df8",
        "colab_type": "text"
      },
      "source": [
        "transfer image files to google drive for storage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqT0H-x85euG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from shutil import copyfile\n",
        "# copy image files from google drive to ./models/images\n",
        "for x in os.listdir('/content/drive/My Drive/Colab Notebooks/image_retrainssd/images'):\n",
        " copyfile('/content/drive/My Drive/Colab Notebooks/image_retrainssd/images/'+x , '/content/models/images/'+x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWmqizYJbcua",
        "colab_type": "text"
      },
      "source": [
        "Creaing the label_map.pbtxt file to identify 'corgi' image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DpxAG3CdDqY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f= open(\"/content/models/annotations/label_map.pbtxt\",\"w+\")\n",
        "#f= open(\"/content/models/research/object_detection/data/label_map.pbtxt\",\"w+\")\n",
        "f.write(\"item { \\r\\n id: 1 \\r\\n name: 'corgi' }\")\n",
        "f.close() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBfFjnQYblIW",
        "colab_type": "text"
      },
      "source": [
        "Creating the trainval.txt to list the number of images to be trained. Image_count contained the number of image files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZR2NVRmzePQ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f= open(\"/content/models/annotations/trainval.txt\",\"w+\")\n",
        "for i in range(image_count):\n",
        "     f.write(\"%d\\r\\n\" % (i+1))\n",
        "f.close() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6J2-e3sHb0dP",
        "colab_type": "text"
      },
      "source": [
        "Download the correct create_tf_record.py file for creating the train and val files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irwe4l2I9ruC",
        "colab_type": "code",
        "outputId": "89c12ca1-9763-4a06-b095-5202d7c7a6e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "os.chdir('/content/models/research/object_detection/dataset_tools')\n",
        "! wget https://raw.githubusercontent.com/thatbrguy/Pedestrian-Detection/master/create_tf_record.py\n",
        "#%mv /content/models/research/object_detection/dataset_tools/create_pet_tf_record.py.1 create_tf_record.py"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-03 00:25:01--  https://raw.githubusercontent.com/thatbrguy/Pedestrian-Detection/master/create_tf_record.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6823 (6.7K) [text/plain]\n",
            "Saving to: ‘create_tf_record.py’\n",
            "\n",
            "\rcreate_tf_record.py   0%[                    ]       0  --.-KB/s               \rcreate_tf_record.py 100%[===================>]   6.66K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-05-03 00:25:02 (86.5 MB/s) - ‘create_tf_record.py’ saved [6823/6823]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oj4wRfZ-SSHn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# setup the path here the google drive storage directory\n",
        "\n",
        "image_path = '/content/drive/My Drive/Colab Notebooks/image_retrainssd/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O-pD1nOcPqh",
        "colab_type": "text"
      },
      "source": [
        "copy files from the google download directory to the training model directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTJEUFiXd5Vq",
        "colab_type": "code",
        "outputId": "292b9639-60c6-458d-c1cb-f1a7f4531d4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/google-images-download/downloads/corgi/\n",
        "\n",
        "for x in os.listdir('/content/google-images-download/downloads/corgi'):\n",
        "  os.rename(x, '/content/models/images/'+x)\n",
        "  "
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/google-images-download/downloads/corgi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcCUShiMcfCR",
        "colab_type": "text"
      },
      "source": [
        "Download the XML created using IMagelbl from google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-T_glfeh0tY9",
        "colab_type": "code",
        "outputId": "cf0c7d38-803c-4f96-ed2d-a4b7b8a6914e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\n",
        "%cd /content/drive/My Drive/Colab Notebooks/image_retrainssd/xml\n",
        "for x in os.listdir('/content/drive/My Drive/Colab Notebooks/image_retrainssd/xml'):\n",
        "  if x.split('.')[-1] == 'xml':\n",
        "    copyfile(x, '/content/models/annotations/xmls/'+x)\n",
        "\n",
        "%cd /content"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/image_retrainssd/xml\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fk6j_lYec8a-",
        "colab_type": "text"
      },
      "source": [
        "XML files contain incorrect paths need to replace them with the right paths in the colab here by replacing the paths in the file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UBpCByz4UmF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for x in os.listdir('/content/models/annotations/xmls'):\n",
        "  if x.split('.')[-1] == 'xml':\n",
        "    fin = open('/content/models/annotations/xmls/'+x, 'rt')\n",
        "    data = fin.read()\n",
        "    data = data.replace('/Users/admin/Downloads/', '/content/models/images/')\n",
        "    fin.close()\n",
        "\n",
        "    fin = open('/content/models/annotations/xmls/'+x, 'wt')\n",
        "    fin.write(data)\n",
        "    fin.close()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ed5UAHUSdK-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#renaming file extension in the xml files  from jpg to png to support the script"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5LzoeupWIa8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for x in os.listdir('/content/models/annotations/xmls'):\n",
        "  if x.split('.')[-1] == 'xml':\n",
        "    fin = open('/content/models/annotations/xmls/'+x, 'rt')\n",
        "    data = fin.read()\n",
        "    data = data.replace('jpg', 'png')\n",
        "    fin.close()\n",
        "\n",
        "    fin = open('/content/models/annotations/xmls/'+x, 'wt')\n",
        "    fin.write(data)\n",
        "    fin.close()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2Q5V8HueG8K",
        "colab_type": "text"
      },
      "source": [
        "copy the images from jpg to png"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgjFipzcA0lM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.mkdir('/content/models/annotations/trimaps')\n",
        "for  x in os.listdir('/content/models/images'):\n",
        "  copyfile('/content/models/images/'+x, '/content/models/annotations/trimaps/'+x.split('.')[0]+'.png')\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILCxzHDMH1Q4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for x in os.listdir('/content/models/images'):\n",
        "  if x.split('.')[-1] == 'jpg':\n",
        "    copyfile('/content/models/images/'+x , '/content/models/images/'+x.split('.')[0]+'.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwWYtpeUeezl",
        "colab_type": "text"
      },
      "source": [
        "create the relevant  files to prepare for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pxHFhs1dgX2",
        "colab_type": "code",
        "outputId": "e7ab9971-757f-4177-91eb-4bf3965c8011",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        }
      },
      "source": [
        "# From the models directory\n",
        "import os\n",
        "os.chdir('/content/models')\n",
        "sys.path.append('/content/models/research/object_detection')\n",
        "#sys.path.append('/content/models/annotations')\n",
        "!export PYTHONPATH='$PYTHONPATH:/content/models/annotations'\n",
        "%set_env PYTHONPATH=/content/models/research:/content/models:/content/models/research/object_detection\n",
        "!PATH=”$PATH:/content/models”\n",
        "!python research/object_detection/dataset_tools/create_tf_record.py  --label_map_path=/content/models/annotations/label_map.pbtxt --output_dir=/content/models/tf_record --data_dir=/content/models "
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: PYTHONPATH=/content/models/research:/content/models:/content/models/research/object_detection\n",
            "WARNING:tensorflow:From research/object_detection/dataset_tools/create_tf_record.py:178: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/label_map_util.py:138: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0503 01:25:06.112476 139938190534528 module_wrapper.py:139] From /content/models/research/object_detection/utils/label_map_util.py:138: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "I0503 01:25:06.113358 139938190534528 create_tf_record.py:153] Reading from Pet dataset.\n",
            "I0503 01:25:06.113993 139938190534528 create_tf_record.py:168] 133 training and 7 validation examples.\n",
            "WARNING:tensorflow:From research/object_detection/dataset_tools/create_tf_record.py:131: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W0503 01:25:06.114135 139938190534528 module_wrapper.py:139] From research/object_detection/dataset_tools/create_tf_record.py:131: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "I0503 01:25:06.114547 139938190534528 create_tf_record.py:134] On image 0 of 133\n",
            "/content/models/research/object_detection/utils/dataset_util.py:79: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
            "  if not xml:\n",
            "Traceback (most recent call last):\n",
            "  File \"research/object_detection/dataset_tools/create_tf_record.py\", line 178, in <module>\n",
            "    tf.app.run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"research/object_detection/dataset_tools/create_tf_record.py\", line 173, in main\n",
            "    image_dir, train_examples)\n",
            "  File \"research/object_detection/dataset_tools/create_tf_record.py\", line 145, in create_tf_record\n",
            "    tf_example = dict_to_tf_example(data, label_map_dict, image_dir)\n",
            "  File \"research/object_detection/dataset_tools/create_tf_record.py\", line 62, in dict_to_tf_example\n",
            "    encoded_jpg = fid.read()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/lib/io/file_io.py\", line 122, in read\n",
            "    self._preread_check()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/lib/io/file_io.py\", line 84, in _preread_check\n",
            "    compat.as_bytes(self.__name), 1024 * 512)\n",
            "tensorflow.python.framework.errors_impl.NotFoundError: images/151.png; No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QEsFNzgev-h",
        "colab_type": "text"
      },
      "source": [
        "downlod the ssd_mobilenet zip file from google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGnYWk3lw4O4",
        "colab_type": "code",
        "outputId": "a2da5afe-05d2-4150-ce53-45a0c8b8259c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "copyfile('/content/drive/My Drive/Colab Notebooks/image_retrainssd/ssd_mobilenet_v2_coco.config', '/content/models/ssd_mobilenet_v2_coco.config')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/models/ssd_mobilenet_v2_coco.config'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Tfbp8lPe3Tn",
        "colab_type": "text"
      },
      "source": [
        "Create the directories for the train and val records generated from the above command"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyNSjYvi9FTv",
        "colab_type": "code",
        "outputId": "812a967b-669f-4f8a-d6c6-8462bd0f6dd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%cd /content/models\n",
        "%mv /content/models/train.record /content/models/tf_record\n",
        "%mv /content/models/val.record /content/models/tf_record"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "mv: cannot stat '/content/models/val.record': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-viTSCBa9S1G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lIQDbMXfcAK",
        "colab_type": "text"
      },
      "source": [
        "download the tar file for ssd_mobilenet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtnrdZ6heRbt",
        "colab_type": "code",
        "outputId": "e21d673a-3b64-404c-9ffc-5edbd8f6884a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "%cd /content\n",
        "! wget http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_coco_2018_03_29.tar.gz"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "--2020-05-03 00:27:26--  http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_coco_2018_03_29.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 172.217.14.112, 2607:f8b0:4007:80c::2010\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|172.217.14.112|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 187925923 (179M) [application/x-tar]\n",
            "Saving to: ‘ssd_mobilenet_v2_coco_2018_03_29.tar.gz’\n",
            "\n",
            "ssd_mobilenet_v2_co 100%[===================>] 179.22M   141MB/s    in 1.3s    \n",
            "\n",
            "2020-05-03 00:27:27 (141 MB/s) - ‘ssd_mobilenet_v2_coco_2018_03_29.tar.gz’ saved [187925923/187925923]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7w9wGDrJmng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! tar -xf ssd_mobilenet_v2_coco_2018_03_29.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJYSzci8fsPs",
        "colab_type": "text"
      },
      "source": [
        "Move the files to the correct directories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVswuU7AJ5W_",
        "colab_type": "code",
        "outputId": "ab94745d-9794-40d7-919b-89810249d111",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/ssd_mobilenet_v2_coco_2018_03_29\n",
        "%mv model.ckpt.meta /content/models/checkpoints/\n",
        "%mv model.ckpt.index /content/models/checkpoints/\n",
        "%mv model.ckpt.data-00000-of-00001 /content/models/checkpoints/"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ssd_mobilenet_v2_coco_2018_03_29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRx8tdG2flh4",
        "colab_type": "text"
      },
      "source": [
        "Create directories for train and eval"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZygEQP55OgxK",
        "colab_type": "code",
        "outputId": "53a2242b-4064-4bce-d41e-bc7b844c78f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Change into the models directory\n",
        "%cd /content/models\n",
        "# Make directory for storing training progress\n",
        "%mkdir train\n",
        "# Make directory for storing validation results\n",
        "%mkdir eval\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUkPOce6fzcD",
        "colab_type": "text"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYfZPn4mVIL0",
        "colab_type": "code",
        "outputId": "3ad7dbab-3a3a-4dc0-ab05-0a08849e6817",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%cd /content/models\n",
        "%set_env PYTHONPATH=$PYTHONPATH:/content/models/research/slim:/content/models/research\n",
        "# Begin training\n",
        "! python research/object_detection/legacy/train.py \\\n",
        "    --logtostderr \\\n",
        "    --train_dir=train \\\n",
        "    --pipeline_config_path=ssd_mobilenet_v2_coco.config"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "env: PYTHONPATH=$PYTHONPATH:/content/models/research/slim:/content/models/research\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From research/object_detection/legacy/train.py:56: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "WARNING:tensorflow:From research/object_detection/legacy/train.py:56: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "WARNING:tensorflow:From research/object_detection/legacy/train.py:185: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/absl/app.py:250: main (from __main__) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use object_detection/model_main.py.\n",
            "W0503 01:26:28.505170 140519389960064 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/absl/app.py:250: main (from __main__) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use object_detection/model_main.py.\n",
            "WARNING:tensorflow:From research/object_detection/legacy/train.py:91: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W0503 01:26:28.505403 140519389960064 module_wrapper.py:139] From research/object_detection/legacy/train.py:91: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/config_util.py:102: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0503 01:26:28.505681 140519389960064 module_wrapper.py:139] From /content/models/research/object_detection/utils/config_util.py:102: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From research/object_detection/legacy/train.py:96: The name tf.gfile.Copy is deprecated. Please use tf.io.gfile.copy instead.\n",
            "\n",
            "W0503 01:26:28.508918 140519389960064 module_wrapper.py:139] From research/object_detection/legacy/train.py:96: The name tf.gfile.Copy is deprecated. Please use tf.io.gfile.copy instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/legacy/trainer.py:267: create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.create_global_step\n",
            "W0503 01:26:28.512194 140519389960064 deprecation.py:323] From /content/models/research/object_detection/legacy/trainer.py:267: create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.create_global_step\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "W0503 01:26:28.515794 140519389960064 module_wrapper.py:139] From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:197: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n",
            "\n",
            "W0503 01:26:28.516017 140519389960064 module_wrapper.py:139] From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:197: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:64: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "W0503 01:26:28.527036 140519389960064 module_wrapper.py:139] From /content/models/research/object_detection/builders/dataset_builder.py:64: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:71: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
            "\n",
            "W0503 01:26:28.527473 140519389960064 module_wrapper.py:139] From /content/models/research/object_detection/builders/dataset_builder.py:71: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
            "\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0503 01:26:28.527591 140519389960064 dataset_builder.py:72] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "W0503 01:26:28.534264 140519389960064 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W0503 01:26:28.534415 140519389960064 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:155: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0503 01:26:28.556291 140519389960064 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:155: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:43: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
            "W0503 01:26:29.105633 140519389960064 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:43: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:44: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "W0503 01:26:29.113073 140519389960064 module_wrapper.py:139] From /content/models/research/object_detection/builders/dataset_builder.py:44: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:44: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "W0503 01:26:29.113273 140519389960064 module_wrapper.py:139] From /content/models/research/object_detection/builders/dataset_builder.py:44: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/preprocessor.py:627: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0503 01:26:29.117261 140519389960064 module_wrapper.py:139] From /content/models/research/object_detection/core/preprocessor.py:627: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/preprocessor.py:197: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0503 01:26:29.162535 140519389960064 deprecation.py:323] From /content/models/research/object_detection/core/preprocessor.py:197: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/box_list_ops.py:206: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0503 01:26:29.172669 140519389960064 deprecation.py:323] From /content/models/research/object_detection/core/box_list_ops.py:206: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/batcher.py:101: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n",
            "W0503 01:26:29.805033 140519389960064 deprecation.py:323] From /content/models/research/object_detection/core/batcher.py:101: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:752: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "W0503 01:26:29.808441 140519389960064 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:752: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:752: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "W0503 01:26:29.809583 140519389960064 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:752: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/prefetcher.py:51: The name tf.PaddingFIFOQueue is deprecated. Please use tf.queue.PaddingFIFOQueue instead.\n",
            "\n",
            "W0503 01:26:29.814458 140519389960064 module_wrapper.py:139] From /content/models/research/object_detection/core/prefetcher.py:51: The name tf.PaddingFIFOQueue is deprecated. Please use tf.queue.PaddingFIFOQueue instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/prefetcher.py:58: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "W0503 01:26:29.817626 140519389960064 module_wrapper.py:139] From /content/models/research/object_detection/core/prefetcher.py:58: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/legacy/trainer.py:286: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "W0503 01:26:29.820449 140519389960064 module_wrapper.py:139] From /content/models/research/object_detection/legacy/trainer.py:286: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/slim/deployment/model_deploy.py:192: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0503 01:26:29.820828 140519389960064 module_wrapper.py:139] From /content/models/research/slim/deployment/model_deploy.py:192: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/slim/deployment/model_deploy.py:192: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "W0503 01:26:29.820980 140519389960064 module_wrapper.py:139] From /content/models/research/slim/deployment/model_deploy.py:192: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/preprocessor.py:2937: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "W0503 01:26:30.567734 140519389960064 module_wrapper.py:139] From /content/models/research/object_detection/core/preprocessor.py:2937: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0503 01:26:30.819815 140519389960064 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "W0503 01:26:33.200754 140519389960064 module_wrapper.py:139] From /content/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W0503 01:26:33.210503 140519389960064 module_wrapper.py:139] From /content/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0503 01:26:33.210680 140519389960064 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0503 01:26:33.239907 140519389960064 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0503 01:26:33.267534 140519389960064 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0503 01:26:33.295410 140519389960064 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0503 01:26:33.323475 140519389960064 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0503 01:26:33.351297 140519389960064 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/box_coders/faster_rcnn_box_coder.py:82: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0503 01:26:33.503398 140519389960064 module_wrapper.py:139] From /content/models/research/object_detection/box_coders/faster_rcnn_box_coder.py:82: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/losses.py:79: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n",
            "\n",
            "W0503 01:26:37.030639 140519389960064 module_wrapper.py:139] From /content/models/research/object_detection/core/losses.py:79: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/losses.py:177: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n",
            "\n",
            "W0503 01:26:37.031791 140519389960064 module_wrapper.py:139] From /content/models/research/object_detection/core/losses.py:177: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/losses.py:183: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n",
            "\n",
            "W0503 01:26:37.032917 140519389960064 module_wrapper.py:139] From /content/models/research/object_detection/core/losses.py:183: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/legacy/trainer.py:209: The name tf.losses.add_loss is deprecated. Please use tf.compat.v1.losses.add_loss instead.\n",
            "\n",
            "W0503 01:26:37.556569 140519389960064 module_wrapper.py:139] From /content/models/research/object_detection/legacy/trainer.py:209: The name tf.losses.add_loss is deprecated. Please use tf.compat.v1.losses.add_loss instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/optimizer_builder.py:157: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "W0503 01:26:37.557401 140519389960064 module_wrapper.py:139] From /content/models/research/object_detection/builders/optimizer_builder.py:157: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/learning_schedules.py:66: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
            "\n",
            "W0503 01:26:37.557675 140519389960064 module_wrapper.py:139] From /content/models/research/object_detection/utils/learning_schedules.py:66: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/optimizer_builder.py:47: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
            "\n",
            "W0503 01:26:37.565936 140519389960064 module_wrapper.py:139] From /content/models/research/object_detection/builders/optimizer_builder.py:47: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/legacy/trainer.py:323: The name tf.check_numerics is deprecated. Please use tf.debugging.check_numerics instead.\n",
            "\n",
            "W0503 01:26:39.600289 140519389960064 module_wrapper.py:139] From /content/models/research/object_detection/legacy/trainer.py:323: The name tf.check_numerics is deprecated. Please use tf.debugging.check_numerics instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0503 01:26:39.603096 140519389960064 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W0503 01:26:41.221761 140519389960064 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/legacy/trainer.py:354: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
            "\n",
            "W0503 01:26:44.796015 140519389960064 module_wrapper.py:139] From /content/models/research/object_detection/legacy/trainer.py:354: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/legacy/trainer.py:356: The name tf.losses.get_losses is deprecated. Please use tf.compat.v1.losses.get_losses instead.\n",
            "\n",
            "W0503 01:26:45.061787 140519389960064 module_wrapper.py:139] From /content/models/research/object_detection/legacy/trainer.py:356: The name tf.losses.get_losses is deprecated. Please use tf.compat.v1.losses.get_losses instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/legacy/trainer.py:360: The name tf.losses.get_total_loss is deprecated. Please use tf.compat.v1.losses.get_total_loss instead.\n",
            "\n",
            "W0503 01:26:45.064287 140519389960064 module_wrapper.py:139] From /content/models/research/object_detection/legacy/trainer.py:360: The name tf.losses.get_total_loss is deprecated. Please use tf.compat.v1.losses.get_total_loss instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/legacy/trainer.py:369: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
            "\n",
            "W0503 01:26:45.067563 140519389960064 module_wrapper.py:139] From /content/models/research/object_detection/legacy/trainer.py:369: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/legacy/trainer.py:372: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0503 01:26:45.073743 140519389960064 module_wrapper.py:139] From /content/models/research/object_detection/legacy/trainer.py:372: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/legacy/trainer.py:377: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "W0503 01:26:45.073965 140519389960064 module_wrapper.py:139] From /content/models/research/object_detection/legacy/trainer.py:377: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/variables_helper.py:179: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "W0503 01:26:45.711210 140519389960064 module_wrapper.py:139] From /content/models/research/object_detection/utils/variables_helper.py:179: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/variables_helper.py:139: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n",
            "\n",
            "W0503 01:26:45.713517 140519389960064 module_wrapper.py:139] From /content/models/research/object_detection/utils/variables_helper.py:139: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n",
            "\n",
            "W0503 01:26:45.716926 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/Conv/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.717049 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/Conv/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.717110 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/Conv/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.717174 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/Conv/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.717228 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/Conv/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.717279 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/Conv/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.717344 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/Conv/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.717399 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/Conv/weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.717451 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/Conv/weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.717503 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/Conv_1/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.717550 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/Conv_1/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.717595 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/Conv_1/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.717644 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/Conv_1/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.717705 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/Conv_1/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.717753 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/Conv_1/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.717829 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/Conv_1/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.717879 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/Conv_1/weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.717939 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/Conv_1/weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.717991 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv/depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.718039 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv/depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.718085 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv/depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.718135 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv/depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.718181 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv/depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.718228 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv/depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.718286 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv/depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.718336 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv/depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.718386 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv/depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.718437 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv/project/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.718484 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv/project/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.718531 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv/project/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.718581 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv/project/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.718628 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv/project/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.718689 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv/project/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.718749 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv/project/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.718841 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv/project/weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.718891 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv/project/weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.718944 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.718992 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.719039 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.719091 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.719139 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.719185 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.719245 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.719294 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.719340 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.719392 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/expand/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.719440 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/expand/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.719489 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/expand/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.719541 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/expand/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.719589 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/expand/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.719635 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/expand/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.719699 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/expand/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.719746 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/expand/weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.719809 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/expand/weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.719861 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/project/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.719909 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/project/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.719955 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/project/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.720014 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/project/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.720062 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/project/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.720108 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/project/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.720167 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/project/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.720215 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/project/weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.720263 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/project/weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.720314 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.720361 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.720407 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.720458 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.720506 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.720552 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.720610 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.720664 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.720712 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.720762 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/expand/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.720829 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/expand/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.720880 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/expand/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.720931 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/expand/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.720978 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/expand/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.721024 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/expand/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.721084 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/expand/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.721133 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/expand/weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.721180 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/expand/weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.721231 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/project/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.767102 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/project/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.767210 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/project/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.767295 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/project/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.767360 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/project/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.767422 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/project/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.767502 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/project/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.767572 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/project/weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.767637 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/project/weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.767734 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.767830 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.767901 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.767975 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.768043 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.768110 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.768193 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.768263 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.768328 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.768398 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/expand/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.768464 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/expand/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.768529 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/expand/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.768601 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/expand/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.768671 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/expand/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.768734 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/expand/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.768838 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/expand/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.768909 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/expand/weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.768989 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/expand/weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.769061 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/project/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.769129 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/project/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.769195 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/project/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.769267 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/project/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.769331 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/project/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.769394 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/project/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.769476 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/project/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.769544 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/project/weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.769608 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/project/weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.769689 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.769759 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.769844 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.769917 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.769982 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.770044 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.770125 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.770195 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.770261 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.770333 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/expand/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.770400 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/expand/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.770467 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/expand/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.770540 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/expand/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.770606 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/expand/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.770677 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/expand/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.770757 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/expand/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.770845 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/expand/weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.770912 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/expand/weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.770984 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/project/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.771052 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/project/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.771115 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/project/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.771187 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/project/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.771255 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/project/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.771319 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/project/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.771400 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/project/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.771469 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/project/weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.771534 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/project/weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.771605 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.771682 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.771750 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.771840 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.771909 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.771973 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.772055 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.772123 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.772190 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.772264 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/expand/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.772332 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/expand/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.772395 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/expand/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.772463 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/expand/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.772527 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/expand/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.772587 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/expand/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.772710 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/expand/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.772794 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/expand/weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.772864 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/expand/weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.772937 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/project/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.773006 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/project/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.773072 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/project/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.773142 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/project/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.773210 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/project/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.773275 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/project/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.773354 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/project/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.773420 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/project/weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.773483 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/project/weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.773550 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.773614 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.773688 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.773761 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.773847 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.773911 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.773990 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.774059 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.774124 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.774195 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/expand/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.774262 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/expand/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.774327 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/expand/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.774397 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/expand/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.774463 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/expand/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.774527 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/expand/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.774608 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/expand/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.774684 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/expand/weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.774746 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/expand/weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.774835 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/project/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.774903 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/project/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.774967 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/project/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.775038 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/project/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.775105 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/project/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.775170 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/project/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.775251 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/project/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.775321 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/project/weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.775385 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/project/weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.775455 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.775521 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.775584 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.775663 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.775733 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.775814 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.775897 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.775967 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.776031 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.776113 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/expand/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.776195 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/expand/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.776260 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/expand/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.776330 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/expand/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.776397 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/expand/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.776461 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/expand/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.776540 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/expand/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.776608 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/expand/weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.776682 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/expand/weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.776757 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/project/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.776841 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/project/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.776909 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/project/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.776980 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/project/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.777047 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/project/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.777110 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/project/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.777189 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/project/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.777259 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/project/weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.777325 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/project/weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.777397 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.777463 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.777528 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.777599 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.777673 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.777738 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.777833 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.777917 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.777986 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.778059 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/expand/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.778125 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/expand/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.778185 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/expand/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.778256 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/expand/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.778321 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/expand/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.778385 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/expand/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.778465 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/expand/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.778535 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/expand/weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.778599 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/expand/weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.778678 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/project/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.778746 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/project/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.778828 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/project/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.778901 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/project/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.778967 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/project/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.779032 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/project/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.779113 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/project/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.779190 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/project/weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.779255 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/project/weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.779327 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.779393 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.779457 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.779528 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.779595 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.779667 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.779751 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.779839 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.779906 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.779992 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/expand/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.780060 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/expand/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.780124 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/expand/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.780194 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/expand/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.780262 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/expand/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.780326 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/expand/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.780406 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/expand/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.780475 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/expand/weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.780539 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/expand/weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.780634 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/project/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.780783 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/project/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.780871 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/project/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.780945 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/project/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.781012 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/project/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.781078 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/project/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.781157 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/project/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.781228 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/project/weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.781292 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/project/weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.781363 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.781428 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.781492 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.781563 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.781629 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.781708 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.781802 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.781877 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.781942 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.782013 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/expand/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.782078 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/expand/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.782142 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/expand/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.782227 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/expand/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.782297 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/expand/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.782361 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/expand/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.782441 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/expand/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.782510 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/expand/weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.782572 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/expand/weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.782644 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/project/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.782725 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/project/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.782815 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/project/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.782893 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/project/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.782961 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/project/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.783025 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/project/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.783105 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/project/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.783173 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/project/weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.783222 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/project/weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.783276 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.783323 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.783366 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.783413 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.783457 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.783499 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.783552 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.783596 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.783638 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.783701 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/expand/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.783744 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/expand/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.783802 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/expand/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.783852 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/expand/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.783895 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/expand/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.783937 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/expand/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.783990 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/expand/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.784082 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/expand/weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.784143 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/expand/weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.784216 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/project/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.784284 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/project/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.784350 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/project/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.784431 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/project/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.784497 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/project/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.784561 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/project/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.784638 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/project/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.784717 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/project/weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.784796 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/project/weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.784872 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.784940 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.785036 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.785106 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.785173 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.785237 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.785314 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.785382 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.785445 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.785516 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/expand/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.785581 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/expand/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.785645 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/expand/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.785729 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/expand/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.785810 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/expand/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.785878 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/expand/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.785960 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/expand/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.786028 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/expand/weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.786092 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/expand/weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.786163 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/project/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.786230 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/project/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.786292 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/project/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.786361 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/project/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.786426 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/project/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.786489 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/project/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.786568 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/project/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.786636 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/project/weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.786709 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/project/weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.786797 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.786868 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.786933 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.787004 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.787070 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.787133 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.787213 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.787281 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.787345 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.787416 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/expand/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.787482 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/expand/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.787547 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/expand/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.787616 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/expand/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.787692 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/expand/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.787758 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/expand/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.787857 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/expand/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.787928 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/expand/weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.787992 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/expand/weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.788063 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/project/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.788129 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/project/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.788192 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/project/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.788262 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/project/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.788328 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/project/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.788392 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/project/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.788470 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/project/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.788539 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/project/weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.788603 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/project/weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.788690 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.788758 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.788840 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.788912 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.788980 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.789045 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.789123 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.789191 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.789254 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.789324 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/expand/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.789389 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/expand/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.789452 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/expand/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.789523 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/expand/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.789589 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/expand/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.789661 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/expand/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.789743 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/expand/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.789830 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/expand/weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.789895 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/expand/weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.789965 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/project/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.790032 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/project/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.790095 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/project/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.790167 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/project/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.790234 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/project/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.790298 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/project/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.790377 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/project/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.790445 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/project/weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.790509 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/project/weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.790580 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.790638 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.790705 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.790785 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.790853 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.790916 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.790994 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.791061 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.791126 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.791198 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/expand/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.791264 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/expand/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.791328 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/expand/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.791399 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/expand/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.791465 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/expand/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.791529 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/expand/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.791608 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/expand/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.791684 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/expand/weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.791751 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/expand/weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.791839 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/project/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.791907 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/project/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.791975 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/project/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.792046 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/project/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.792113 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/project/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.792177 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/project/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.792257 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/project/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.792324 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/project/weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.792388 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/project/weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.792458 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.792523 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.792586 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.792663 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.792733 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.792815 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.792897 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.792966 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.793030 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.793100 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/expand/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.793165 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/expand/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.793230 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/expand/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.793302 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/expand/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.793368 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/expand/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.793432 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/expand/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.793510 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/expand/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.793578 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/expand/weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.793643 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/expand/weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.793725 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/project/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.793807 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/project/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.793874 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/project/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.793945 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/project/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.794011 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/project/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.794075 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/project/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.794153 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/project/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.794223 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/project/weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.794288 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/project/weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.794358 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.794424 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.794488 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.794559 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.794624 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.794695 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.794789 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.794862 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.794928 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.795000 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.795067 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.795131 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.795202 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.795269 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.795332 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.795411 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.795480 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.795545 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.795616 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.795690 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.795756 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.795845 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.795913 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.795978 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.796058 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.796126 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.796191 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.796263 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.796328 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.796392 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.796465 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.796533 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.796596 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.796681 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.796752 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.796833 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.796906 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.796972 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.797037 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.797108 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.797174 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.797237 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.797318 140519389960064 variables_helper.py:154] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 256, 512]], model variable shape: [[3, 3, 256, 512]]. This variable will not be initialized from the checkpoint.\n",
            "W0503 01:26:45.797390 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.797458 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.797523 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.797593 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.797667 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.797734 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.797819 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.797899 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.797968 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.798051 140519389960064 variables_helper.py:154] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 128, 256]], model variable shape: [[3, 3, 128, 256]]. This variable will not be initialized from the checkpoint.\n",
            "W0503 01:26:45.798122 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.798191 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.798256 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.798327 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.798393 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.798457 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.798527 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.798594 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.798664 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.798748 140519389960064 variables_helper.py:154] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 128, 256]], model variable shape: [[3, 3, 128, 256]]. This variable will not be initialized from the checkpoint.\n",
            "W0503 01:26:45.798835 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.798904 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.798969 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/weights/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.799040 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.799106 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.799170 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.799241 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.799308 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.799372 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0503 01:26:45.799452 140519389960064 variables_helper.py:154] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 64, 128]], model variable shape: [[3, 3, 64, 128]]. This variable will not be initialized from the checkpoint.\n",
            "W0503 01:26:45.799522 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0503 01:26:45.799589 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/weights/RMSProp] is not available in checkpoint\n",
            "W0503 01:26:45.799661 140519389960064 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/weights/RMSProp_1] is not available in checkpoint\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/slim/python/slim/learning.py:742: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.MonitoredTrainingSession\n",
            "W0503 01:26:46.526504 140519389960064 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/slim/python/slim/learning.py:742: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.MonitoredTrainingSession\n",
            "2020-05-03 01:26:47.813041: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
            "2020-05-03 01:26:47.817425: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000160000 Hz\n",
            "2020-05-03 01:26:47.817602: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x19fe39c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-05-03 01:26:47.817632: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-05-03 01:26:47.819585: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-05-03 01:26:47.897132: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-03 01:26:47.897608: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x19fe3800 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-05-03 01:26:47.897640: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P4, Compute Capability 6.1\n",
            "2020-05-03 01:26:47.897845: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-03 01:26:47.898172: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-05-03 01:26:47.898466: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-05-03 01:26:47.899621: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-05-03 01:26:47.900746: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-05-03 01:26:47.901088: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-05-03 01:26:47.902427: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-05-03 01:26:47.903456: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-05-03 01:26:47.906600: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-05-03 01:26:47.906720: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-03 01:26:47.907094: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-03 01:26:47.907379: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-05-03 01:26:47.907441: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-05-03 01:26:47.908376: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-05-03 01:26:47.908402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-05-03 01:26:47.908413: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-05-03 01:26:47.908527: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-03 01:26:47.908909: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-03 01:26:47.909213: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-05-03 01:26:47.909252: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5165 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "INFO:tensorflow:Restoring parameters from train/model.ckpt-3561\n",
            "I0503 01:26:47.912194 140519389960064 saver.py:1284] Restoring parameters from train/model.ckpt-3561\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "W0503 01:26:49.582962 140519389960064 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0503 01:26:49.587537 140519389960064 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0503 01:26:50.085795 140519389960064 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Starting Session.\n",
            "I0503 01:26:58.470120 140519389960064 learning.py:754] Starting Session.\n",
            "INFO:tensorflow:Saving checkpoint to path train/model.ckpt\n",
            "I0503 01:26:58.858909 140515693082368 supervisor.py:1117] Saving checkpoint to path train/model.ckpt\n",
            "INFO:tensorflow:Starting Queues.\n",
            "I0503 01:26:58.864491 140519389960064 learning.py:768] Starting Queues.\n",
            "INFO:tensorflow:global_step/sec: 0\n",
            "I0503 01:27:12.789635 140515684689664 supervisor.py:1099] global_step/sec: 0\n",
            "2020-05-03 01:27:13.832640: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-05-03 01:27:15.348125: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "INFO:tensorflow:Recording summary at step 3561.\n",
            "I0503 01:27:17.743512 140515676296960 supervisor.py:1050] Recording summary at step 3561.\n",
            "INFO:tensorflow:global step 3562: loss = 0.7746 (20.814 sec/step)\n",
            "I0503 01:27:20.300306 140519389960064 learning.py:507] global step 3562: loss = 0.7746 (20.814 sec/step)\n",
            "INFO:tensorflow:global step 3563: loss = 1.0824 (1.224 sec/step)\n",
            "I0503 01:27:22.130784 140519389960064 learning.py:507] global step 3563: loss = 1.0824 (1.224 sec/step)\n",
            "INFO:tensorflow:global step 3564: loss = 0.7867 (0.865 sec/step)\n",
            "I0503 01:27:22.997727 140519389960064 learning.py:507] global step 3564: loss = 0.7867 (0.865 sec/step)\n",
            "INFO:tensorflow:global step 3565: loss = 0.9267 (0.732 sec/step)\n",
            "I0503 01:27:23.776614 140519389960064 learning.py:507] global step 3565: loss = 0.9267 (0.732 sec/step)\n",
            "INFO:tensorflow:global step 3566: loss = 0.7639 (0.783 sec/step)\n",
            "I0503 01:27:24.564697 140519389960064 learning.py:507] global step 3566: loss = 0.7639 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 3567: loss = 0.7057 (0.661 sec/step)\n",
            "I0503 01:27:25.226918 140519389960064 learning.py:507] global step 3567: loss = 0.7057 (0.661 sec/step)\n",
            "INFO:tensorflow:global step 3568: loss = 0.7747 (0.781 sec/step)\n",
            "I0503 01:27:26.009454 140519389960064 learning.py:507] global step 3568: loss = 0.7747 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 3569: loss = 0.8558 (0.623 sec/step)\n",
            "I0503 01:27:26.745475 140519389960064 learning.py:507] global step 3569: loss = 0.8558 (0.623 sec/step)\n",
            "INFO:tensorflow:global step 3570: loss = 0.7922 (0.740 sec/step)\n",
            "I0503 01:27:27.553790 140519389960064 learning.py:507] global step 3570: loss = 0.7922 (0.740 sec/step)\n",
            "INFO:tensorflow:global step 3571: loss = 0.7742 (0.912 sec/step)\n",
            "I0503 01:27:28.467599 140519389960064 learning.py:507] global step 3571: loss = 0.7742 (0.912 sec/step)\n",
            "INFO:tensorflow:global step 3572: loss = 0.9376 (0.769 sec/step)\n",
            "I0503 01:27:29.240094 140519389960064 learning.py:507] global step 3572: loss = 0.9376 (0.769 sec/step)\n",
            "INFO:tensorflow:global step 3573: loss = 0.7644 (0.899 sec/step)\n",
            "I0503 01:27:30.140688 140519389960064 learning.py:507] global step 3573: loss = 0.7644 (0.899 sec/step)\n",
            "INFO:tensorflow:global step 3574: loss = 0.7523 (0.812 sec/step)\n",
            "I0503 01:27:30.954927 140519389960064 learning.py:507] global step 3574: loss = 0.7523 (0.812 sec/step)\n",
            "INFO:tensorflow:global step 3575: loss = 0.9193 (0.840 sec/step)\n",
            "I0503 01:27:31.796410 140519389960064 learning.py:507] global step 3575: loss = 0.9193 (0.840 sec/step)\n",
            "INFO:tensorflow:global step 3576: loss = 0.6651 (0.817 sec/step)\n",
            "I0503 01:27:32.615192 140519389960064 learning.py:507] global step 3576: loss = 0.6651 (0.817 sec/step)\n",
            "INFO:tensorflow:global step 3577: loss = 1.1499 (0.728 sec/step)\n",
            "I0503 01:27:33.421401 140519389960064 learning.py:507] global step 3577: loss = 1.1499 (0.728 sec/step)\n",
            "INFO:tensorflow:global step 3578: loss = 0.8200 (0.912 sec/step)\n",
            "I0503 01:27:34.336858 140519389960064 learning.py:507] global step 3578: loss = 0.8200 (0.912 sec/step)\n",
            "INFO:tensorflow:global step 3579: loss = 0.6924 (0.892 sec/step)\n",
            "I0503 01:27:35.229840 140519389960064 learning.py:507] global step 3579: loss = 0.6924 (0.892 sec/step)\n",
            "INFO:tensorflow:global step 3580: loss = 0.5967 (0.791 sec/step)\n",
            "I0503 01:27:36.022495 140519389960064 learning.py:507] global step 3580: loss = 0.5967 (0.791 sec/step)\n",
            "INFO:tensorflow:global step 3581: loss = 0.9747 (0.738 sec/step)\n",
            "I0503 01:27:36.762096 140519389960064 learning.py:507] global step 3581: loss = 0.9747 (0.738 sec/step)\n",
            "INFO:tensorflow:global step 3582: loss = 0.6883 (0.888 sec/step)\n",
            "I0503 01:27:37.651538 140519389960064 learning.py:507] global step 3582: loss = 0.6883 (0.888 sec/step)\n",
            "INFO:tensorflow:global step 3583: loss = 0.6575 (0.899 sec/step)\n",
            "I0503 01:27:38.552485 140519389960064 learning.py:507] global step 3583: loss = 0.6575 (0.899 sec/step)\n",
            "INFO:tensorflow:global step 3584: loss = 0.9472 (0.952 sec/step)\n",
            "I0503 01:27:39.506589 140519389960064 learning.py:507] global step 3584: loss = 0.9472 (0.952 sec/step)\n",
            "INFO:tensorflow:global step 3585: loss = 0.9111 (0.960 sec/step)\n",
            "I0503 01:27:40.469575 140519389960064 learning.py:507] global step 3585: loss = 0.9111 (0.960 sec/step)\n",
            "INFO:tensorflow:global step 3586: loss = 1.1648 (0.796 sec/step)\n",
            "I0503 01:27:41.269753 140519389960064 learning.py:507] global step 3586: loss = 1.1648 (0.796 sec/step)\n",
            "INFO:tensorflow:global step 3587: loss = 0.6893 (0.764 sec/step)\n",
            "I0503 01:27:42.123250 140519389960064 learning.py:507] global step 3587: loss = 0.6893 (0.764 sec/step)\n",
            "INFO:tensorflow:global step 3588: loss = 0.8126 (0.809 sec/step)\n",
            "I0503 01:27:42.934311 140519389960064 learning.py:507] global step 3588: loss = 0.8126 (0.809 sec/step)\n",
            "INFO:tensorflow:global step 3589: loss = 0.6831 (0.876 sec/step)\n",
            "I0503 01:27:43.812615 140519389960064 learning.py:507] global step 3589: loss = 0.6831 (0.876 sec/step)\n",
            "INFO:tensorflow:global step 3590: loss = 0.7760 (0.818 sec/step)\n",
            "I0503 01:27:44.631712 140519389960064 learning.py:507] global step 3590: loss = 0.7760 (0.818 sec/step)\n",
            "INFO:tensorflow:global step 3591: loss = 0.5794 (0.878 sec/step)\n",
            "I0503 01:27:45.511458 140519389960064 learning.py:507] global step 3591: loss = 0.5794 (0.878 sec/step)\n",
            "INFO:tensorflow:global step 3592: loss = 0.7121 (0.986 sec/step)\n",
            "I0503 01:27:46.499083 140519389960064 learning.py:507] global step 3592: loss = 0.7121 (0.986 sec/step)\n",
            "INFO:tensorflow:global step 3593: loss = 0.8445 (0.820 sec/step)\n",
            "I0503 01:27:47.321227 140519389960064 learning.py:507] global step 3593: loss = 0.8445 (0.820 sec/step)\n",
            "INFO:tensorflow:global step 3594: loss = 0.7801 (0.802 sec/step)\n",
            "I0503 01:27:48.125217 140519389960064 learning.py:507] global step 3594: loss = 0.7801 (0.802 sec/step)\n",
            "INFO:tensorflow:global step 3595: loss = 1.1793 (0.882 sec/step)\n",
            "I0503 01:27:49.008857 140519389960064 learning.py:507] global step 3595: loss = 1.1793 (0.882 sec/step)\n",
            "INFO:tensorflow:global step 3596: loss = 0.8363 (0.841 sec/step)\n",
            "I0503 01:27:49.851388 140519389960064 learning.py:507] global step 3596: loss = 0.8363 (0.841 sec/step)\n",
            "INFO:tensorflow:global step 3597: loss = 0.6996 (0.796 sec/step)\n",
            "I0503 01:27:50.649168 140519389960064 learning.py:507] global step 3597: loss = 0.6996 (0.796 sec/step)\n",
            "INFO:tensorflow:global step 3598: loss = 0.7526 (0.864 sec/step)\n",
            "I0503 01:27:51.515003 140519389960064 learning.py:507] global step 3598: loss = 0.7526 (0.864 sec/step)\n",
            "INFO:tensorflow:global step 3599: loss = 0.8408 (0.781 sec/step)\n",
            "I0503 01:27:52.297371 140519389960064 learning.py:507] global step 3599: loss = 0.8408 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 3600: loss = 0.7813 (0.772 sec/step)\n",
            "I0503 01:27:53.071192 140519389960064 learning.py:507] global step 3600: loss = 0.7813 (0.772 sec/step)\n",
            "INFO:tensorflow:global step 3601: loss = 1.1723 (0.773 sec/step)\n",
            "I0503 01:27:53.845952 140519389960064 learning.py:507] global step 3601: loss = 1.1723 (0.773 sec/step)\n",
            "INFO:tensorflow:global step 3602: loss = 0.9247 (0.843 sec/step)\n",
            "I0503 01:27:54.691428 140519389960064 learning.py:507] global step 3602: loss = 0.9247 (0.843 sec/step)\n",
            "INFO:tensorflow:global step 3603: loss = 0.9425 (0.809 sec/step)\n",
            "I0503 01:27:55.501584 140519389960064 learning.py:507] global step 3603: loss = 0.9425 (0.809 sec/step)\n",
            "INFO:tensorflow:global step 3604: loss = 0.8281 (0.855 sec/step)\n",
            "I0503 01:27:56.358749 140519389960064 learning.py:507] global step 3604: loss = 0.8281 (0.855 sec/step)\n",
            "INFO:tensorflow:global step 3605: loss = 0.6664 (0.877 sec/step)\n",
            "I0503 01:27:57.237668 140519389960064 learning.py:507] global step 3605: loss = 0.6664 (0.877 sec/step)\n",
            "INFO:tensorflow:global step 3606: loss = 1.0771 (0.736 sec/step)\n",
            "I0503 01:27:57.976097 140519389960064 learning.py:507] global step 3606: loss = 1.0771 (0.736 sec/step)\n",
            "INFO:tensorflow:global step 3607: loss = 0.9717 (0.709 sec/step)\n",
            "I0503 01:27:58.686318 140519389960064 learning.py:507] global step 3607: loss = 0.9717 (0.709 sec/step)\n",
            "INFO:tensorflow:global step 3608: loss = 0.8077 (0.919 sec/step)\n",
            "I0503 01:27:59.607020 140519389960064 learning.py:507] global step 3608: loss = 0.8077 (0.919 sec/step)\n",
            "INFO:tensorflow:global step 3609: loss = 0.8703 (0.776 sec/step)\n",
            "I0503 01:28:00.384580 140519389960064 learning.py:507] global step 3609: loss = 0.8703 (0.776 sec/step)\n",
            "INFO:tensorflow:global step 3610: loss = 1.0118 (0.831 sec/step)\n",
            "I0503 01:28:01.217575 140519389960064 learning.py:507] global step 3610: loss = 1.0118 (0.831 sec/step)\n",
            "INFO:tensorflow:global step 3611: loss = 0.9934 (0.755 sec/step)\n",
            "I0503 01:28:01.973946 140519389960064 learning.py:507] global step 3611: loss = 0.9934 (0.755 sec/step)\n",
            "INFO:tensorflow:global step 3612: loss = 0.8970 (0.772 sec/step)\n",
            "I0503 01:28:02.747696 140519389960064 learning.py:507] global step 3612: loss = 0.8970 (0.772 sec/step)\n",
            "INFO:tensorflow:global step 3613: loss = 0.9447 (0.832 sec/step)\n",
            "I0503 01:28:03.581006 140519389960064 learning.py:507] global step 3613: loss = 0.9447 (0.832 sec/step)\n",
            "INFO:tensorflow:global step 3614: loss = 0.8894 (0.923 sec/step)\n",
            "I0503 01:28:04.506364 140519389960064 learning.py:507] global step 3614: loss = 0.8894 (0.923 sec/step)\n",
            "INFO:tensorflow:global step 3615: loss = 0.8024 (0.770 sec/step)\n",
            "I0503 01:28:05.278050 140519389960064 learning.py:507] global step 3615: loss = 0.8024 (0.770 sec/step)\n",
            "INFO:tensorflow:global step 3616: loss = 0.7994 (0.816 sec/step)\n",
            "I0503 01:28:06.095866 140519389960064 learning.py:507] global step 3616: loss = 0.7994 (0.816 sec/step)\n",
            "INFO:tensorflow:global step 3617: loss = 1.1402 (0.755 sec/step)\n",
            "I0503 01:28:06.852125 140519389960064 learning.py:507] global step 3617: loss = 1.1402 (0.755 sec/step)\n",
            "INFO:tensorflow:global step 3618: loss = 1.3938 (0.801 sec/step)\n",
            "I0503 01:28:07.654558 140519389960064 learning.py:507] global step 3618: loss = 1.3938 (0.801 sec/step)\n",
            "INFO:tensorflow:global step 3619: loss = 0.8161 (0.902 sec/step)\n",
            "I0503 01:28:08.558266 140519389960064 learning.py:507] global step 3619: loss = 0.8161 (0.902 sec/step)\n",
            "INFO:tensorflow:global step 3620: loss = 0.8707 (0.876 sec/step)\n",
            "I0503 01:28:09.435817 140519389960064 learning.py:507] global step 3620: loss = 0.8707 (0.876 sec/step)\n",
            "INFO:tensorflow:global step 3621: loss = 0.7603 (0.882 sec/step)\n",
            "I0503 01:28:10.319056 140519389960064 learning.py:507] global step 3621: loss = 0.7603 (0.882 sec/step)\n",
            "INFO:tensorflow:global step 3622: loss = 0.8690 (0.768 sec/step)\n",
            "I0503 01:28:11.088821 140519389960064 learning.py:507] global step 3622: loss = 0.8690 (0.768 sec/step)\n",
            "INFO:tensorflow:global step 3623: loss = 1.1767 (0.771 sec/step)\n",
            "I0503 01:28:11.861920 140519389960064 learning.py:507] global step 3623: loss = 1.1767 (0.771 sec/step)\n",
            "INFO:tensorflow:global step 3624: loss = 0.9230 (0.886 sec/step)\n",
            "I0503 01:28:12.749577 140519389960064 learning.py:507] global step 3624: loss = 0.9230 (0.886 sec/step)\n",
            "INFO:tensorflow:global step 3625: loss = 0.7286 (0.836 sec/step)\n",
            "I0503 01:28:13.587598 140519389960064 learning.py:507] global step 3625: loss = 0.7286 (0.836 sec/step)\n",
            "INFO:tensorflow:global step 3626: loss = 0.7597 (0.744 sec/step)\n",
            "I0503 01:28:14.333006 140519389960064 learning.py:507] global step 3626: loss = 0.7597 (0.744 sec/step)\n",
            "INFO:tensorflow:global step 3627: loss = 0.7061 (0.884 sec/step)\n",
            "I0503 01:28:15.223563 140519389960064 learning.py:507] global step 3627: loss = 0.7061 (0.884 sec/step)\n",
            "INFO:tensorflow:global step 3628: loss = 0.9830 (0.770 sec/step)\n",
            "I0503 01:28:16.053304 140519389960064 learning.py:507] global step 3628: loss = 0.9830 (0.770 sec/step)\n",
            "INFO:tensorflow:global step 3629: loss = 0.7716 (0.843 sec/step)\n",
            "I0503 01:28:16.917567 140519389960064 learning.py:507] global step 3629: loss = 0.7716 (0.843 sec/step)\n",
            "INFO:tensorflow:global step 3630: loss = 0.8382 (0.888 sec/step)\n",
            "I0503 01:28:17.807653 140519389960064 learning.py:507] global step 3630: loss = 0.8382 (0.888 sec/step)\n",
            "INFO:tensorflow:global step 3631: loss = 0.7860 (0.932 sec/step)\n",
            "I0503 01:28:18.741084 140519389960064 learning.py:507] global step 3631: loss = 0.7860 (0.932 sec/step)\n",
            "INFO:tensorflow:global step 3632: loss = 0.8045 (0.831 sec/step)\n",
            "I0503 01:28:19.574111 140519389960064 learning.py:507] global step 3632: loss = 0.8045 (0.831 sec/step)\n",
            "INFO:tensorflow:global step 3633: loss = 0.7012 (0.866 sec/step)\n",
            "I0503 01:28:20.441684 140519389960064 learning.py:507] global step 3633: loss = 0.7012 (0.866 sec/step)\n",
            "INFO:tensorflow:global step 3634: loss = 0.7536 (0.856 sec/step)\n",
            "I0503 01:28:21.299582 140519389960064 learning.py:507] global step 3634: loss = 0.7536 (0.856 sec/step)\n",
            "INFO:tensorflow:global step 3635: loss = 0.6794 (0.726 sec/step)\n",
            "I0503 01:28:22.027534 140519389960064 learning.py:507] global step 3635: loss = 0.6794 (0.726 sec/step)\n",
            "INFO:tensorflow:global step 3636: loss = 0.8363 (0.774 sec/step)\n",
            "I0503 01:28:22.869704 140519389960064 learning.py:507] global step 3636: loss = 0.8363 (0.774 sec/step)\n",
            "INFO:tensorflow:global step 3637: loss = 0.7479 (0.819 sec/step)\n",
            "I0503 01:28:23.857806 140519389960064 learning.py:507] global step 3637: loss = 0.7479 (0.819 sec/step)\n",
            "INFO:tensorflow:global step 3638: loss = 0.8762 (0.831 sec/step)\n",
            "I0503 01:28:24.729003 140519389960064 learning.py:507] global step 3638: loss = 0.8762 (0.831 sec/step)\n",
            "INFO:tensorflow:global step 3639: loss = 0.8665 (0.767 sec/step)\n",
            "I0503 01:28:25.497994 140519389960064 learning.py:507] global step 3639: loss = 0.8665 (0.767 sec/step)\n",
            "INFO:tensorflow:global step 3640: loss = 0.7840 (0.769 sec/step)\n",
            "I0503 01:28:26.268418 140519389960064 learning.py:507] global step 3640: loss = 0.7840 (0.769 sec/step)\n",
            "INFO:tensorflow:global step 3641: loss = 0.8211 (0.792 sec/step)\n",
            "I0503 01:28:27.061814 140519389960064 learning.py:507] global step 3641: loss = 0.8211 (0.792 sec/step)\n",
            "INFO:tensorflow:global step 3642: loss = 0.7688 (0.997 sec/step)\n",
            "I0503 01:28:28.061816 140519389960064 learning.py:507] global step 3642: loss = 0.7688 (0.997 sec/step)\n",
            "INFO:tensorflow:global step 3643: loss = 0.9667 (0.905 sec/step)\n",
            "I0503 01:28:28.969500 140519389960064 learning.py:507] global step 3643: loss = 0.9667 (0.905 sec/step)\n",
            "INFO:tensorflow:global step 3644: loss = 0.9507 (0.752 sec/step)\n",
            "I0503 01:28:29.723012 140519389960064 learning.py:507] global step 3644: loss = 0.9507 (0.752 sec/step)\n",
            "INFO:tensorflow:global step 3645: loss = 0.9204 (0.769 sec/step)\n",
            "I0503 01:28:30.493132 140519389960064 learning.py:507] global step 3645: loss = 0.9204 (0.769 sec/step)\n",
            "INFO:tensorflow:global step 3646: loss = 0.7750 (0.710 sec/step)\n",
            "I0503 01:28:31.204257 140519389960064 learning.py:507] global step 3646: loss = 0.7750 (0.710 sec/step)\n",
            "INFO:tensorflow:global step 3647: loss = 0.8402 (0.736 sec/step)\n",
            "I0503 01:28:31.942260 140519389960064 learning.py:507] global step 3647: loss = 0.8402 (0.736 sec/step)\n",
            "INFO:tensorflow:global step 3648: loss = 0.7527 (0.843 sec/step)\n",
            "I0503 01:28:32.786394 140519389960064 learning.py:507] global step 3648: loss = 0.7527 (0.843 sec/step)\n",
            "INFO:tensorflow:global step 3649: loss = 0.7470 (0.887 sec/step)\n",
            "I0503 01:28:33.674968 140519389960064 learning.py:507] global step 3649: loss = 0.7470 (0.887 sec/step)\n",
            "INFO:tensorflow:global step 3650: loss = 0.8180 (0.777 sec/step)\n",
            "I0503 01:28:34.453657 140519389960064 learning.py:507] global step 3650: loss = 0.8180 (0.777 sec/step)\n",
            "INFO:tensorflow:global step 3651: loss = 0.8953 (0.829 sec/step)\n",
            "I0503 01:28:35.283960 140519389960064 learning.py:507] global step 3651: loss = 0.8953 (0.829 sec/step)\n",
            "INFO:tensorflow:global step 3652: loss = 0.8218 (0.867 sec/step)\n",
            "I0503 01:28:36.152257 140519389960064 learning.py:507] global step 3652: loss = 0.8218 (0.867 sec/step)\n",
            "INFO:tensorflow:global step 3653: loss = 0.8473 (0.828 sec/step)\n",
            "I0503 01:28:36.981951 140519389960064 learning.py:507] global step 3653: loss = 0.8473 (0.828 sec/step)\n",
            "INFO:tensorflow:global step 3654: loss = 0.8221 (0.854 sec/step)\n",
            "I0503 01:28:37.837286 140519389960064 learning.py:507] global step 3654: loss = 0.8221 (0.854 sec/step)\n",
            "INFO:tensorflow:global step 3655: loss = 0.7432 (0.823 sec/step)\n",
            "I0503 01:28:38.661866 140519389960064 learning.py:507] global step 3655: loss = 0.7432 (0.823 sec/step)\n",
            "INFO:tensorflow:global step 3656: loss = 0.9087 (0.824 sec/step)\n",
            "I0503 01:28:39.487930 140519389960064 learning.py:507] global step 3656: loss = 0.9087 (0.824 sec/step)\n",
            "INFO:tensorflow:global step 3657: loss = 1.0829 (0.852 sec/step)\n",
            "I0503 01:28:40.341608 140519389960064 learning.py:507] global step 3657: loss = 1.0829 (0.852 sec/step)\n",
            "INFO:tensorflow:global step 3658: loss = 0.8242 (0.730 sec/step)\n",
            "I0503 01:28:41.073622 140519389960064 learning.py:507] global step 3658: loss = 0.8242 (0.730 sec/step)\n",
            "INFO:tensorflow:global step 3659: loss = 0.8280 (0.666 sec/step)\n",
            "I0503 01:28:41.741242 140519389960064 learning.py:507] global step 3659: loss = 0.8280 (0.666 sec/step)\n",
            "INFO:tensorflow:global step 3660: loss = 0.8022 (1.160 sec/step)\n",
            "I0503 01:28:42.902410 140519389960064 learning.py:507] global step 3660: loss = 0.8022 (1.160 sec/step)\n",
            "INFO:tensorflow:global step 3661: loss = 1.0514 (0.790 sec/step)\n",
            "I0503 01:28:43.693629 140519389960064 learning.py:507] global step 3661: loss = 1.0514 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 3662: loss = 0.8188 (0.657 sec/step)\n",
            "I0503 01:28:44.352503 140519389960064 learning.py:507] global step 3662: loss = 0.8188 (0.657 sec/step)\n",
            "INFO:tensorflow:global step 3663: loss = 0.7857 (0.919 sec/step)\n",
            "I0503 01:28:45.272856 140519389960064 learning.py:507] global step 3663: loss = 0.7857 (0.919 sec/step)\n",
            "INFO:tensorflow:global step 3664: loss = 0.8260 (0.861 sec/step)\n",
            "I0503 01:28:46.135540 140519389960064 learning.py:507] global step 3664: loss = 0.8260 (0.861 sec/step)\n",
            "INFO:tensorflow:global step 3665: loss = 0.7444 (0.908 sec/step)\n",
            "I0503 01:28:47.046200 140519389960064 learning.py:507] global step 3665: loss = 0.7444 (0.908 sec/step)\n",
            "INFO:tensorflow:global step 3666: loss = 0.8343 (0.883 sec/step)\n",
            "I0503 01:28:47.930621 140519389960064 learning.py:507] global step 3666: loss = 0.8343 (0.883 sec/step)\n",
            "INFO:tensorflow:global step 3667: loss = 1.1175 (0.819 sec/step)\n",
            "I0503 01:28:48.751472 140519389960064 learning.py:507] global step 3667: loss = 1.1175 (0.819 sec/step)\n",
            "INFO:tensorflow:global step 3668: loss = 0.6409 (0.843 sec/step)\n",
            "I0503 01:28:49.595762 140519389960064 learning.py:507] global step 3668: loss = 0.6409 (0.843 sec/step)\n",
            "INFO:tensorflow:global step 3669: loss = 0.7385 (0.803 sec/step)\n",
            "I0503 01:28:50.400493 140519389960064 learning.py:507] global step 3669: loss = 0.7385 (0.803 sec/step)\n",
            "INFO:tensorflow:global step 3670: loss = 0.7982 (0.915 sec/step)\n",
            "I0503 01:28:51.316603 140519389960064 learning.py:507] global step 3670: loss = 0.7982 (0.915 sec/step)\n",
            "INFO:tensorflow:global step 3671: loss = 0.8339 (0.825 sec/step)\n",
            "I0503 01:28:52.144488 140519389960064 learning.py:507] global step 3671: loss = 0.8339 (0.825 sec/step)\n",
            "INFO:tensorflow:global step 3672: loss = 0.7581 (0.831 sec/step)\n",
            "I0503 01:28:52.976670 140519389960064 learning.py:507] global step 3672: loss = 0.7581 (0.831 sec/step)\n",
            "INFO:tensorflow:global step 3673: loss = 0.9581 (0.824 sec/step)\n",
            "I0503 01:28:53.802575 140519389960064 learning.py:507] global step 3673: loss = 0.9581 (0.824 sec/step)\n",
            "INFO:tensorflow:global step 3674: loss = 0.9443 (0.752 sec/step)\n",
            "I0503 01:28:54.556644 140519389960064 learning.py:507] global step 3674: loss = 0.9443 (0.752 sec/step)\n",
            "INFO:tensorflow:global step 3675: loss = 0.8828 (0.947 sec/step)\n",
            "I0503 01:28:55.515569 140519389960064 learning.py:507] global step 3675: loss = 0.8828 (0.947 sec/step)\n",
            "INFO:tensorflow:global step 3676: loss = 0.6584 (0.884 sec/step)\n",
            "I0503 01:28:56.412424 140519389960064 learning.py:507] global step 3676: loss = 0.6584 (0.884 sec/step)\n",
            "INFO:tensorflow:global step 3677: loss = 0.8245 (0.949 sec/step)\n",
            "I0503 01:28:57.363447 140519389960064 learning.py:507] global step 3677: loss = 0.8245 (0.949 sec/step)\n",
            "INFO:tensorflow:global step 3678: loss = 0.9801 (0.713 sec/step)\n",
            "I0503 01:28:58.077705 140519389960064 learning.py:507] global step 3678: loss = 0.9801 (0.713 sec/step)\n",
            "INFO:tensorflow:global step 3679: loss = 0.8843 (0.805 sec/step)\n",
            "I0503 01:28:58.886081 140519389960064 learning.py:507] global step 3679: loss = 0.8843 (0.805 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 3679.\n",
            "I0503 01:29:00.191781 140515676296960 supervisor.py:1050] Recording summary at step 3679.\n",
            "INFO:tensorflow:global step 3680: loss = 0.7517 (1.659 sec/step)\n",
            "I0503 01:29:00.547301 140519389960064 learning.py:507] global step 3680: loss = 0.7517 (1.659 sec/step)\n",
            "INFO:tensorflow:global step 3681: loss = 0.6670 (0.771 sec/step)\n",
            "I0503 01:29:01.319563 140519389960064 learning.py:507] global step 3681: loss = 0.6670 (0.771 sec/step)\n",
            "INFO:tensorflow:global step 3682: loss = 0.8477 (0.693 sec/step)\n",
            "I0503 01:29:02.085844 140519389960064 learning.py:507] global step 3682: loss = 0.8477 (0.693 sec/step)\n",
            "INFO:tensorflow:global step 3683: loss = 0.8819 (0.751 sec/step)\n",
            "I0503 01:29:02.841659 140519389960064 learning.py:507] global step 3683: loss = 0.8819 (0.751 sec/step)\n",
            "INFO:tensorflow:global_step/sec: 1.10815\n",
            "I0503 01:29:02.883022 140515684689664 supervisor.py:1099] global_step/sec: 1.10815\n",
            "INFO:tensorflow:global step 3684: loss = 0.8884 (0.806 sec/step)\n",
            "I0503 01:29:03.649620 140519389960064 learning.py:507] global step 3684: loss = 0.8884 (0.806 sec/step)\n",
            "INFO:tensorflow:global step 3685: loss = 0.7419 (0.772 sec/step)\n",
            "I0503 01:29:04.425972 140519389960064 learning.py:507] global step 3685: loss = 0.7419 (0.772 sec/step)\n",
            "INFO:tensorflow:global step 3686: loss = 0.8481 (0.969 sec/step)\n",
            "I0503 01:29:05.396342 140519389960064 learning.py:507] global step 3686: loss = 0.8481 (0.969 sec/step)\n",
            "INFO:tensorflow:global step 3687: loss = 0.6956 (0.726 sec/step)\n",
            "I0503 01:29:06.288232 140519389960064 learning.py:507] global step 3687: loss = 0.6956 (0.726 sec/step)\n",
            "INFO:tensorflow:global step 3688: loss = 0.5540 (0.981 sec/step)\n",
            "I0503 01:29:07.273705 140519389960064 learning.py:507] global step 3688: loss = 0.5540 (0.981 sec/step)\n",
            "INFO:tensorflow:global step 3689: loss = 0.7751 (0.765 sec/step)\n",
            "I0503 01:29:08.039935 140519389960064 learning.py:507] global step 3689: loss = 0.7751 (0.765 sec/step)\n",
            "INFO:tensorflow:global step 3690: loss = 0.8278 (0.960 sec/step)\n",
            "I0503 01:29:09.001873 140519389960064 learning.py:507] global step 3690: loss = 0.8278 (0.960 sec/step)\n",
            "INFO:tensorflow:global step 3691: loss = 0.8543 (0.708 sec/step)\n",
            "I0503 01:29:09.711398 140519389960064 learning.py:507] global step 3691: loss = 0.8543 (0.708 sec/step)\n",
            "INFO:tensorflow:global step 3692: loss = 0.9162 (1.029 sec/step)\n",
            "I0503 01:29:10.741702 140519389960064 learning.py:507] global step 3692: loss = 0.9162 (1.029 sec/step)\n",
            "INFO:tensorflow:global step 3693: loss = 1.0337 (0.821 sec/step)\n",
            "I0503 01:29:11.564063 140519389960064 learning.py:507] global step 3693: loss = 1.0337 (0.821 sec/step)\n",
            "INFO:tensorflow:global step 3694: loss = 0.8420 (1.472 sec/step)\n",
            "I0503 01:29:13.072898 140519389960064 learning.py:507] global step 3694: loss = 0.8420 (1.472 sec/step)\n",
            "INFO:tensorflow:global step 3695: loss = 0.7565 (1.106 sec/step)\n",
            "I0503 01:29:14.198270 140519389960064 learning.py:507] global step 3695: loss = 0.7565 (1.106 sec/step)\n",
            "INFO:tensorflow:global step 3696: loss = 0.7144 (0.852 sec/step)\n",
            "I0503 01:29:15.098593 140519389960064 learning.py:507] global step 3696: loss = 0.7144 (0.852 sec/step)\n",
            "INFO:tensorflow:global step 3697: loss = 1.1906 (0.733 sec/step)\n",
            "I0503 01:29:15.839043 140519389960064 learning.py:507] global step 3697: loss = 1.1906 (0.733 sec/step)\n",
            "INFO:tensorflow:global step 3698: loss = 0.8318 (1.417 sec/step)\n",
            "I0503 01:29:17.258627 140519389960064 learning.py:507] global step 3698: loss = 0.8318 (1.417 sec/step)\n",
            "INFO:tensorflow:global step 3699: loss = 0.8148 (0.870 sec/step)\n",
            "I0503 01:29:18.130938 140519389960064 learning.py:507] global step 3699: loss = 0.8148 (0.870 sec/step)\n",
            "INFO:tensorflow:global step 3700: loss = 0.8007 (0.884 sec/step)\n",
            "I0503 01:29:19.016620 140519389960064 learning.py:507] global step 3700: loss = 0.8007 (0.884 sec/step)\n",
            "INFO:tensorflow:global step 3701: loss = 0.8307 (0.855 sec/step)\n",
            "I0503 01:29:19.873430 140519389960064 learning.py:507] global step 3701: loss = 0.8307 (0.855 sec/step)\n",
            "INFO:tensorflow:global step 3702: loss = 0.8602 (0.905 sec/step)\n",
            "I0503 01:29:20.779670 140519389960064 learning.py:507] global step 3702: loss = 0.8602 (0.905 sec/step)\n",
            "INFO:tensorflow:global step 3703: loss = 0.8055 (0.856 sec/step)\n",
            "I0503 01:29:21.637615 140519389960064 learning.py:507] global step 3703: loss = 0.8055 (0.856 sec/step)\n",
            "INFO:tensorflow:global step 3704: loss = 0.9448 (1.397 sec/step)\n",
            "I0503 01:29:23.036294 140519389960064 learning.py:507] global step 3704: loss = 0.9448 (1.397 sec/step)\n",
            "INFO:tensorflow:global step 3705: loss = 0.7824 (0.714 sec/step)\n",
            "I0503 01:29:23.752188 140519389960064 learning.py:507] global step 3705: loss = 0.7824 (0.714 sec/step)\n",
            "INFO:tensorflow:global step 3706: loss = 0.8136 (0.887 sec/step)\n",
            "I0503 01:29:24.740438 140519389960064 learning.py:507] global step 3706: loss = 0.8136 (0.887 sec/step)\n",
            "INFO:tensorflow:global step 3707: loss = 0.9920 (1.077 sec/step)\n",
            "I0503 01:29:25.891174 140519389960064 learning.py:507] global step 3707: loss = 0.9920 (1.077 sec/step)\n",
            "INFO:tensorflow:global step 3708: loss = 1.0813 (0.832 sec/step)\n",
            "I0503 01:29:26.794088 140519389960064 learning.py:507] global step 3708: loss = 1.0813 (0.832 sec/step)\n",
            "INFO:tensorflow:global step 3709: loss = 0.7083 (0.764 sec/step)\n",
            "I0503 01:29:27.666564 140519389960064 learning.py:507] global step 3709: loss = 0.7083 (0.764 sec/step)\n",
            "INFO:tensorflow:global step 3710: loss = 0.7432 (0.917 sec/step)\n",
            "I0503 01:29:28.584893 140519389960064 learning.py:507] global step 3710: loss = 0.7432 (0.917 sec/step)\n",
            "INFO:tensorflow:global step 3711: loss = 0.8417 (0.905 sec/step)\n",
            "I0503 01:29:29.490916 140519389960064 learning.py:507] global step 3711: loss = 0.8417 (0.905 sec/step)\n",
            "INFO:tensorflow:global step 3712: loss = 0.9481 (0.972 sec/step)\n",
            "I0503 01:29:30.464365 140519389960064 learning.py:507] global step 3712: loss = 0.9481 (0.972 sec/step)\n",
            "INFO:tensorflow:global step 3713: loss = 0.9847 (1.084 sec/step)\n",
            "I0503 01:29:31.550441 140519389960064 learning.py:507] global step 3713: loss = 0.9847 (1.084 sec/step)\n",
            "INFO:tensorflow:global step 3714: loss = 0.9817 (0.804 sec/step)\n",
            "I0503 01:29:32.356225 140519389960064 learning.py:507] global step 3714: loss = 0.9817 (0.804 sec/step)\n",
            "INFO:tensorflow:global step 3715: loss = 0.9415 (0.732 sec/step)\n",
            "I0503 01:29:33.095272 140519389960064 learning.py:507] global step 3715: loss = 0.9415 (0.732 sec/step)\n",
            "INFO:tensorflow:global step 3716: loss = 0.6734 (0.849 sec/step)\n",
            "I0503 01:29:34.008619 140519389960064 learning.py:507] global step 3716: loss = 0.6734 (0.849 sec/step)\n",
            "INFO:tensorflow:global step 3717: loss = 1.0789 (0.831 sec/step)\n",
            "I0503 01:29:34.960619 140519389960064 learning.py:507] global step 3717: loss = 1.0789 (0.831 sec/step)\n",
            "INFO:tensorflow:global step 3718: loss = 0.6600 (0.827 sec/step)\n",
            "I0503 01:29:35.807997 140519389960064 learning.py:507] global step 3718: loss = 0.6600 (0.827 sec/step)\n",
            "INFO:tensorflow:global step 3719: loss = 0.6591 (0.874 sec/step)\n",
            "I0503 01:29:36.717340 140519389960064 learning.py:507] global step 3719: loss = 0.6591 (0.874 sec/step)\n",
            "INFO:tensorflow:global step 3720: loss = 0.8924 (0.836 sec/step)\n",
            "I0503 01:29:37.555711 140519389960064 learning.py:507] global step 3720: loss = 0.8924 (0.836 sec/step)\n",
            "INFO:tensorflow:global step 3721: loss = 0.9297 (0.804 sec/step)\n",
            "I0503 01:29:38.361886 140519389960064 learning.py:507] global step 3721: loss = 0.9297 (0.804 sec/step)\n",
            "INFO:tensorflow:global step 3722: loss = 0.8462 (1.041 sec/step)\n",
            "I0503 01:29:39.404259 140519389960064 learning.py:507] global step 3722: loss = 0.8462 (1.041 sec/step)\n",
            "INFO:tensorflow:global step 3723: loss = 0.9437 (0.654 sec/step)\n",
            "I0503 01:29:40.060144 140519389960064 learning.py:507] global step 3723: loss = 0.9437 (0.654 sec/step)\n",
            "INFO:tensorflow:global step 3724: loss = 1.5300 (1.506 sec/step)\n",
            "I0503 01:29:41.570012 140519389960064 learning.py:507] global step 3724: loss = 1.5300 (1.506 sec/step)\n",
            "INFO:tensorflow:global step 3725: loss = 0.7252 (0.879 sec/step)\n",
            "I0503 01:29:42.450423 140519389960064 learning.py:507] global step 3725: loss = 0.7252 (0.879 sec/step)\n",
            "INFO:tensorflow:global step 3726: loss = 0.8023 (0.882 sec/step)\n",
            "I0503 01:29:43.333619 140519389960064 learning.py:507] global step 3726: loss = 0.8023 (0.882 sec/step)\n",
            "INFO:tensorflow:global step 3727: loss = 0.8035 (0.830 sec/step)\n",
            "I0503 01:29:44.164813 140519389960064 learning.py:507] global step 3727: loss = 0.8035 (0.830 sec/step)\n",
            "INFO:tensorflow:global step 3728: loss = 0.6515 (0.729 sec/step)\n",
            "I0503 01:29:44.948826 140519389960064 learning.py:507] global step 3728: loss = 0.6515 (0.729 sec/step)\n",
            "INFO:tensorflow:global step 3729: loss = 0.7062 (1.249 sec/step)\n",
            "I0503 01:29:46.199726 140519389960064 learning.py:507] global step 3729: loss = 0.7062 (1.249 sec/step)\n",
            "INFO:tensorflow:global step 3730: loss = 0.8479 (0.716 sec/step)\n",
            "I0503 01:29:46.917037 140519389960064 learning.py:507] global step 3730: loss = 0.8479 (0.716 sec/step)\n",
            "INFO:tensorflow:global step 3731: loss = 0.8257 (0.866 sec/step)\n",
            "I0503 01:29:47.784252 140519389960064 learning.py:507] global step 3731: loss = 0.8257 (0.866 sec/step)\n",
            "INFO:tensorflow:global step 3732: loss = 0.6190 (0.864 sec/step)\n",
            "I0503 01:29:48.650071 140519389960064 learning.py:507] global step 3732: loss = 0.6190 (0.864 sec/step)\n",
            "INFO:tensorflow:global step 3733: loss = 0.6762 (0.908 sec/step)\n",
            "I0503 01:29:49.559683 140519389960064 learning.py:507] global step 3733: loss = 0.6762 (0.908 sec/step)\n",
            "INFO:tensorflow:global step 3734: loss = 0.7196 (0.771 sec/step)\n",
            "I0503 01:29:50.332333 140519389960064 learning.py:507] global step 3734: loss = 0.7196 (0.771 sec/step)\n",
            "INFO:tensorflow:global step 3735: loss = 0.7189 (0.910 sec/step)\n",
            "I0503 01:29:51.244029 140519389960064 learning.py:507] global step 3735: loss = 0.7189 (0.910 sec/step)\n",
            "INFO:tensorflow:global step 3736: loss = 0.7703 (0.811 sec/step)\n",
            "I0503 01:29:52.057007 140519389960064 learning.py:507] global step 3736: loss = 0.7703 (0.811 sec/step)\n",
            "INFO:tensorflow:global step 3737: loss = 0.8849 (0.873 sec/step)\n",
            "I0503 01:29:52.931165 140519389960064 learning.py:507] global step 3737: loss = 0.8849 (0.873 sec/step)\n",
            "INFO:tensorflow:global step 3738: loss = 1.1222 (0.832 sec/step)\n",
            "I0503 01:29:53.764800 140519389960064 learning.py:507] global step 3738: loss = 1.1222 (0.832 sec/step)\n",
            "INFO:tensorflow:global step 3739: loss = 0.7367 (0.715 sec/step)\n",
            "I0503 01:29:54.542735 140519389960064 learning.py:507] global step 3739: loss = 0.7367 (0.715 sec/step)\n",
            "INFO:tensorflow:global step 3740: loss = 0.6474 (0.776 sec/step)\n",
            "I0503 01:29:55.324919 140519389960064 learning.py:507] global step 3740: loss = 0.6474 (0.776 sec/step)\n",
            "INFO:tensorflow:global step 3741: loss = 0.6739 (0.832 sec/step)\n",
            "I0503 01:29:56.158832 140519389960064 learning.py:507] global step 3741: loss = 0.6739 (0.832 sec/step)\n",
            "INFO:tensorflow:global step 3742: loss = 0.6040 (0.848 sec/step)\n",
            "I0503 01:29:57.008305 140519389960064 learning.py:507] global step 3742: loss = 0.6040 (0.848 sec/step)\n",
            "INFO:tensorflow:global step 3743: loss = 0.8941 (0.687 sec/step)\n",
            "I0503 01:29:57.698241 140519389960064 learning.py:507] global step 3743: loss = 0.8941 (0.687 sec/step)\n",
            "INFO:tensorflow:global step 3744: loss = 0.8912 (0.698 sec/step)\n",
            "I0503 01:29:58.403332 140519389960064 learning.py:507] global step 3744: loss = 0.8912 (0.698 sec/step)\n",
            "INFO:tensorflow:global step 3745: loss = 1.1679 (0.753 sec/step)\n",
            "I0503 01:29:59.160143 140519389960064 learning.py:507] global step 3745: loss = 1.1679 (0.753 sec/step)\n",
            "INFO:tensorflow:global step 3746: loss = 1.0028 (0.700 sec/step)\n",
            "I0503 01:29:59.895388 140519389960064 learning.py:507] global step 3746: loss = 1.0028 (0.700 sec/step)\n",
            "INFO:tensorflow:global step 3747: loss = 0.7334 (0.737 sec/step)\n",
            "I0503 01:30:00.634076 140519389960064 learning.py:507] global step 3747: loss = 0.7334 (0.737 sec/step)\n",
            "INFO:tensorflow:global step 3748: loss = 0.8083 (1.295 sec/step)\n",
            "I0503 01:30:01.930783 140519389960064 learning.py:507] global step 3748: loss = 0.8083 (1.295 sec/step)\n",
            "INFO:tensorflow:global step 3749: loss = 0.7508 (0.860 sec/step)\n",
            "I0503 01:30:02.792534 140519389960064 learning.py:507] global step 3749: loss = 0.7508 (0.860 sec/step)\n",
            "INFO:tensorflow:global step 3750: loss = 0.9127 (0.818 sec/step)\n",
            "I0503 01:30:03.612904 140519389960064 learning.py:507] global step 3750: loss = 0.9127 (0.818 sec/step)\n",
            "INFO:tensorflow:global step 3751: loss = 0.7792 (0.855 sec/step)\n",
            "I0503 01:30:04.470554 140519389960064 learning.py:507] global step 3751: loss = 0.7792 (0.855 sec/step)\n",
            "INFO:tensorflow:global step 3752: loss = 0.7176 (0.782 sec/step)\n",
            "I0503 01:30:05.253884 140519389960064 learning.py:507] global step 3752: loss = 0.7176 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 3753: loss = 0.5921 (0.832 sec/step)\n",
            "I0503 01:30:06.107333 140519389960064 learning.py:507] global step 3753: loss = 0.5921 (0.832 sec/step)\n",
            "INFO:tensorflow:global step 3754: loss = 0.6559 (0.830 sec/step)\n",
            "I0503 01:30:06.949473 140519389960064 learning.py:507] global step 3754: loss = 0.6559 (0.830 sec/step)\n",
            "INFO:tensorflow:global step 3755: loss = 0.7880 (0.821 sec/step)\n",
            "I0503 01:30:07.772473 140519389960064 learning.py:507] global step 3755: loss = 0.7880 (0.821 sec/step)\n",
            "INFO:tensorflow:global step 3756: loss = 0.7038 (0.635 sec/step)\n",
            "I0503 01:30:08.409015 140519389960064 learning.py:507] global step 3756: loss = 0.7038 (0.635 sec/step)\n",
            "INFO:tensorflow:global step 3757: loss = 0.8131 (1.347 sec/step)\n",
            "I0503 01:30:09.757303 140519389960064 learning.py:507] global step 3757: loss = 0.8131 (1.347 sec/step)\n",
            "INFO:tensorflow:global step 3758: loss = 0.8889 (0.705 sec/step)\n",
            "I0503 01:30:10.464813 140519389960064 learning.py:507] global step 3758: loss = 0.8889 (0.705 sec/step)\n",
            "INFO:tensorflow:global step 3759: loss = 1.0754 (1.171 sec/step)\n",
            "I0503 01:30:11.637994 140519389960064 learning.py:507] global step 3759: loss = 1.0754 (1.171 sec/step)\n",
            "INFO:tensorflow:global step 3760: loss = 0.8330 (0.858 sec/step)\n",
            "I0503 01:30:12.497331 140519389960064 learning.py:507] global step 3760: loss = 0.8330 (0.858 sec/step)\n",
            "INFO:tensorflow:global step 3761: loss = 0.8782 (0.857 sec/step)\n",
            "I0503 01:30:13.355937 140519389960064 learning.py:507] global step 3761: loss = 0.8782 (0.857 sec/step)\n",
            "INFO:tensorflow:global step 3762: loss = 0.6360 (0.818 sec/step)\n",
            "I0503 01:30:14.241981 140519389960064 learning.py:507] global step 3762: loss = 0.6360 (0.818 sec/step)\n",
            "INFO:tensorflow:global step 3763: loss = 0.9849 (0.857 sec/step)\n",
            "I0503 01:30:15.101410 140519389960064 learning.py:507] global step 3763: loss = 0.9849 (0.857 sec/step)\n",
            "INFO:tensorflow:global step 3764: loss = 0.7251 (0.779 sec/step)\n",
            "I0503 01:30:15.882396 140519389960064 learning.py:507] global step 3764: loss = 0.7251 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 3765: loss = 0.8239 (1.477 sec/step)\n",
            "I0503 01:30:17.360763 140519389960064 learning.py:507] global step 3765: loss = 0.8239 (1.477 sec/step)\n",
            "INFO:tensorflow:global step 3766: loss = 0.7367 (0.784 sec/step)\n",
            "I0503 01:30:18.194204 140519389960064 learning.py:507] global step 3766: loss = 0.7367 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 3767: loss = 0.8924 (0.777 sec/step)\n",
            "I0503 01:30:19.025697 140519389960064 learning.py:507] global step 3767: loss = 0.8924 (0.777 sec/step)\n",
            "INFO:tensorflow:global step 3768: loss = 0.8595 (0.788 sec/step)\n",
            "I0503 01:30:19.816648 140519389960064 learning.py:507] global step 3768: loss = 0.8595 (0.788 sec/step)\n",
            "INFO:tensorflow:global step 3769: loss = 0.8475 (0.822 sec/step)\n",
            "I0503 01:30:20.640060 140519389960064 learning.py:507] global step 3769: loss = 0.8475 (0.822 sec/step)\n",
            "INFO:tensorflow:global step 3770: loss = 0.7449 (0.746 sec/step)\n",
            "I0503 01:30:21.463837 140519389960064 learning.py:507] global step 3770: loss = 0.7449 (0.746 sec/step)\n",
            "INFO:tensorflow:global step 3771: loss = 0.9237 (0.887 sec/step)\n",
            "I0503 01:30:22.353614 140519389960064 learning.py:507] global step 3771: loss = 0.9237 (0.887 sec/step)\n",
            "INFO:tensorflow:global step 3772: loss = 0.7981 (0.757 sec/step)\n",
            "I0503 01:30:23.116666 140519389960064 learning.py:507] global step 3772: loss = 0.7981 (0.757 sec/step)\n",
            "INFO:tensorflow:global step 3773: loss = 0.7228 (0.993 sec/step)\n",
            "I0503 01:30:24.111005 140519389960064 learning.py:507] global step 3773: loss = 0.7228 (0.993 sec/step)\n",
            "INFO:tensorflow:global step 3774: loss = 0.8873 (0.758 sec/step)\n",
            "I0503 01:30:24.907273 140519389960064 learning.py:507] global step 3774: loss = 0.8873 (0.758 sec/step)\n",
            "INFO:tensorflow:global step 3775: loss = 0.9194 (0.976 sec/step)\n",
            "I0503 01:30:25.897492 140519389960064 learning.py:507] global step 3775: loss = 0.9194 (0.976 sec/step)\n",
            "INFO:tensorflow:global step 3776: loss = 0.8423 (0.834 sec/step)\n",
            "I0503 01:30:26.732865 140519389960064 learning.py:507] global step 3776: loss = 0.8423 (0.834 sec/step)\n",
            "INFO:tensorflow:global step 3777: loss = 0.9438 (0.887 sec/step)\n",
            "I0503 01:30:27.620887 140519389960064 learning.py:507] global step 3777: loss = 0.9438 (0.887 sec/step)\n",
            "INFO:tensorflow:global step 3778: loss = 0.8292 (0.860 sec/step)\n",
            "I0503 01:30:28.482741 140519389960064 learning.py:507] global step 3778: loss = 0.8292 (0.860 sec/step)\n",
            "INFO:tensorflow:global step 3779: loss = 0.9402 (0.796 sec/step)\n",
            "I0503 01:30:29.280721 140519389960064 learning.py:507] global step 3779: loss = 0.9402 (0.796 sec/step)\n",
            "INFO:tensorflow:global step 3780: loss = 0.6972 (0.851 sec/step)\n",
            "I0503 01:30:30.134929 140519389960064 learning.py:507] global step 3780: loss = 0.6972 (0.851 sec/step)\n",
            "INFO:tensorflow:global step 3781: loss = 1.0673 (0.941 sec/step)\n",
            "I0503 01:30:31.078942 140519389960064 learning.py:507] global step 3781: loss = 1.0673 (0.941 sec/step)\n",
            "INFO:tensorflow:global step 3782: loss = 0.8960 (0.807 sec/step)\n",
            "I0503 01:30:31.887505 140519389960064 learning.py:507] global step 3782: loss = 0.8960 (0.807 sec/step)\n",
            "INFO:tensorflow:global step 3783: loss = 0.8449 (0.834 sec/step)\n",
            "I0503 01:30:32.722682 140519389960064 learning.py:507] global step 3783: loss = 0.8449 (0.834 sec/step)\n",
            "INFO:tensorflow:global step 3784: loss = 0.6695 (0.941 sec/step)\n",
            "I0503 01:30:33.665608 140519389960064 learning.py:507] global step 3784: loss = 0.6695 (0.941 sec/step)\n",
            "INFO:tensorflow:global step 3785: loss = 0.7730 (0.750 sec/step)\n",
            "I0503 01:30:34.417106 140519389960064 learning.py:507] global step 3785: loss = 0.7730 (0.750 sec/step)\n",
            "INFO:tensorflow:global step 3786: loss = 0.7263 (0.914 sec/step)\n",
            "I0503 01:30:35.332583 140519389960064 learning.py:507] global step 3786: loss = 0.7263 (0.914 sec/step)\n",
            "INFO:tensorflow:global step 3787: loss = 0.8058 (0.866 sec/step)\n",
            "I0503 01:30:36.199845 140519389960064 learning.py:507] global step 3787: loss = 0.8058 (0.866 sec/step)\n",
            "INFO:tensorflow:global step 3788: loss = 0.7673 (0.873 sec/step)\n",
            "I0503 01:30:37.074325 140519389960064 learning.py:507] global step 3788: loss = 0.7673 (0.873 sec/step)\n",
            "INFO:tensorflow:global step 3789: loss = 0.7018 (0.842 sec/step)\n",
            "I0503 01:30:37.917706 140519389960064 learning.py:507] global step 3789: loss = 0.7018 (0.842 sec/step)\n",
            "INFO:tensorflow:global step 3790: loss = 0.7895 (0.768 sec/step)\n",
            "I0503 01:30:38.686957 140519389960064 learning.py:507] global step 3790: loss = 0.7895 (0.768 sec/step)\n",
            "INFO:tensorflow:global step 3791: loss = 0.6483 (0.741 sec/step)\n",
            "I0503 01:30:39.429304 140519389960064 learning.py:507] global step 3791: loss = 0.6483 (0.741 sec/step)\n",
            "INFO:tensorflow:global step 3792: loss = 0.8221 (0.822 sec/step)\n",
            "I0503 01:30:40.253070 140519389960064 learning.py:507] global step 3792: loss = 0.8221 (0.822 sec/step)\n",
            "INFO:tensorflow:global step 3793: loss = 0.8000 (0.850 sec/step)\n",
            "I0503 01:30:41.104977 140519389960064 learning.py:507] global step 3793: loss = 0.8000 (0.850 sec/step)\n",
            "INFO:tensorflow:global step 3794: loss = 0.8157 (0.682 sec/step)\n",
            "I0503 01:30:41.793507 140519389960064 learning.py:507] global step 3794: loss = 0.8157 (0.682 sec/step)\n",
            "INFO:tensorflow:global step 3795: loss = 0.5861 (0.920 sec/step)\n",
            "I0503 01:30:42.714812 140519389960064 learning.py:507] global step 3795: loss = 0.5861 (0.920 sec/step)\n",
            "INFO:tensorflow:global step 3796: loss = 0.6407 (0.827 sec/step)\n",
            "I0503 01:30:43.543709 140519389960064 learning.py:507] global step 3796: loss = 0.6407 (0.827 sec/step)\n",
            "INFO:tensorflow:global step 3797: loss = 0.7974 (0.768 sec/step)\n",
            "I0503 01:30:44.314010 140519389960064 learning.py:507] global step 3797: loss = 0.7974 (0.768 sec/step)\n",
            "INFO:tensorflow:global step 3798: loss = 0.9815 (0.848 sec/step)\n",
            "I0503 01:30:45.163438 140519389960064 learning.py:507] global step 3798: loss = 0.9815 (0.848 sec/step)\n",
            "INFO:tensorflow:global step 3799: loss = 0.8334 (0.767 sec/step)\n",
            "I0503 01:30:45.931838 140519389960064 learning.py:507] global step 3799: loss = 0.8334 (0.767 sec/step)\n",
            "INFO:tensorflow:global step 3800: loss = 0.8853 (0.850 sec/step)\n",
            "I0503 01:30:46.784212 140519389960064 learning.py:507] global step 3800: loss = 0.8853 (0.850 sec/step)\n",
            "INFO:tensorflow:global step 3801: loss = 0.7130 (0.842 sec/step)\n",
            "I0503 01:30:47.628031 140519389960064 learning.py:507] global step 3801: loss = 0.7130 (0.842 sec/step)\n",
            "INFO:tensorflow:global step 3802: loss = 0.9166 (0.792 sec/step)\n",
            "I0503 01:30:48.421502 140519389960064 learning.py:507] global step 3802: loss = 0.9166 (0.792 sec/step)\n",
            "INFO:tensorflow:global step 3803: loss = 0.6782 (0.781 sec/step)\n",
            "I0503 01:30:49.204542 140519389960064 learning.py:507] global step 3803: loss = 0.6782 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 3804: loss = 0.7159 (0.872 sec/step)\n",
            "I0503 01:30:50.078455 140519389960064 learning.py:507] global step 3804: loss = 0.7159 (0.872 sec/step)\n",
            "INFO:tensorflow:global step 3805: loss = 0.8539 (0.807 sec/step)\n",
            "I0503 01:30:50.887229 140519389960064 learning.py:507] global step 3805: loss = 0.8539 (0.807 sec/step)\n",
            "INFO:tensorflow:global step 3806: loss = 1.0637 (0.811 sec/step)\n",
            "I0503 01:30:51.699440 140519389960064 learning.py:507] global step 3806: loss = 1.0637 (0.811 sec/step)\n",
            "INFO:tensorflow:global step 3807: loss = 0.8430 (0.904 sec/step)\n",
            "I0503 01:30:52.604866 140519389960064 learning.py:507] global step 3807: loss = 0.8430 (0.904 sec/step)\n",
            "INFO:tensorflow:global step 3808: loss = 0.6809 (0.700 sec/step)\n",
            "I0503 01:30:53.307030 140519389960064 learning.py:507] global step 3808: loss = 0.6809 (0.700 sec/step)\n",
            "INFO:tensorflow:global step 3809: loss = 0.6816 (0.774 sec/step)\n",
            "I0503 01:30:54.082834 140519389960064 learning.py:507] global step 3809: loss = 0.6816 (0.774 sec/step)\n",
            "INFO:tensorflow:global step 3810: loss = 0.7040 (0.874 sec/step)\n",
            "I0503 01:30:54.958102 140519389960064 learning.py:507] global step 3810: loss = 0.7040 (0.874 sec/step)\n",
            "INFO:tensorflow:global step 3811: loss = 0.7701 (0.790 sec/step)\n",
            "I0503 01:30:55.750021 140519389960064 learning.py:507] global step 3811: loss = 0.7701 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 3812: loss = 0.8637 (0.751 sec/step)\n",
            "I0503 01:30:56.502040 140519389960064 learning.py:507] global step 3812: loss = 0.8637 (0.751 sec/step)\n",
            "INFO:tensorflow:global step 3813: loss = 0.6545 (0.906 sec/step)\n",
            "I0503 01:30:57.410140 140519389960064 learning.py:507] global step 3813: loss = 0.6545 (0.906 sec/step)\n",
            "INFO:tensorflow:global step 3814: loss = 0.6781 (0.733 sec/step)\n",
            "I0503 01:30:58.144874 140519389960064 learning.py:507] global step 3814: loss = 0.6781 (0.733 sec/step)\n",
            "INFO:tensorflow:global step 3815: loss = 0.8732 (0.861 sec/step)\n",
            "I0503 01:30:59.349199 140519389960064 learning.py:507] global step 3815: loss = 0.8732 (0.861 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 3815.\n",
            "I0503 01:31:00.100095 140515676296960 supervisor.py:1050] Recording summary at step 3815.\n",
            "INFO:tensorflow:global step 3816: loss = 0.7734 (0.985 sec/step)\n",
            "I0503 01:31:00.416044 140519389960064 learning.py:507] global step 3816: loss = 0.7734 (0.985 sec/step)\n",
            "INFO:tensorflow:global step 3817: loss = 0.6485 (0.870 sec/step)\n",
            "I0503 01:31:01.287650 140519389960064 learning.py:507] global step 3817: loss = 0.6485 (0.870 sec/step)\n",
            "INFO:tensorflow:global step 3818: loss = 0.6368 (0.962 sec/step)\n",
            "I0503 01:31:02.251722 140519389960064 learning.py:507] global step 3818: loss = 0.6368 (0.962 sec/step)\n",
            "INFO:tensorflow:global_step/sec: 1.12532\n",
            "I0503 01:31:02.848666 140515684689664 supervisor.py:1099] global_step/sec: 1.12532\n",
            "INFO:tensorflow:global step 3819: loss = 0.7143 (0.662 sec/step)\n",
            "I0503 01:31:02.927994 140519389960064 learning.py:507] global step 3819: loss = 0.7143 (0.662 sec/step)\n",
            "INFO:tensorflow:global step 3820: loss = 0.7535 (0.786 sec/step)\n",
            "I0503 01:31:03.720639 140519389960064 learning.py:507] global step 3820: loss = 0.7535 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 3821: loss = 0.8989 (0.663 sec/step)\n",
            "I0503 01:31:04.384909 140519389960064 learning.py:507] global step 3821: loss = 0.8989 (0.663 sec/step)\n",
            "INFO:tensorflow:global step 3822: loss = 0.7736 (0.834 sec/step)\n",
            "I0503 01:31:05.220810 140519389960064 learning.py:507] global step 3822: loss = 0.7736 (0.834 sec/step)\n",
            "INFO:tensorflow:global step 3823: loss = 0.7635 (0.844 sec/step)\n",
            "I0503 01:31:06.066804 140519389960064 learning.py:507] global step 3823: loss = 0.7635 (0.844 sec/step)\n",
            "INFO:tensorflow:global step 3824: loss = 0.9283 (0.857 sec/step)\n",
            "I0503 01:31:06.925572 140519389960064 learning.py:507] global step 3824: loss = 0.9283 (0.857 sec/step)\n",
            "INFO:tensorflow:global step 3825: loss = 0.8962 (0.803 sec/step)\n",
            "I0503 01:31:07.730426 140519389960064 learning.py:507] global step 3825: loss = 0.8962 (0.803 sec/step)\n",
            "INFO:tensorflow:global step 3826: loss = 0.6895 (0.802 sec/step)\n",
            "I0503 01:31:08.534975 140519389960064 learning.py:507] global step 3826: loss = 0.6895 (0.802 sec/step)\n",
            "INFO:tensorflow:global step 3827: loss = 0.8213 (0.891 sec/step)\n",
            "I0503 01:31:09.427445 140519389960064 learning.py:507] global step 3827: loss = 0.8213 (0.891 sec/step)\n",
            "INFO:tensorflow:global step 3828: loss = 0.7547 (0.858 sec/step)\n",
            "I0503 01:31:10.286693 140519389960064 learning.py:507] global step 3828: loss = 0.7547 (0.858 sec/step)\n",
            "INFO:tensorflow:global step 3829: loss = 0.6369 (0.733 sec/step)\n",
            "I0503 01:31:11.021381 140519389960064 learning.py:507] global step 3829: loss = 0.6369 (0.733 sec/step)\n",
            "INFO:tensorflow:global step 3830: loss = 0.7567 (0.807 sec/step)\n",
            "I0503 01:31:11.830708 140519389960064 learning.py:507] global step 3830: loss = 0.7567 (0.807 sec/step)\n",
            "INFO:tensorflow:global step 3831: loss = 0.8874 (0.803 sec/step)\n",
            "I0503 01:31:12.635582 140519389960064 learning.py:507] global step 3831: loss = 0.8874 (0.803 sec/step)\n",
            "INFO:tensorflow:global step 3832: loss = 0.8176 (0.893 sec/step)\n",
            "I0503 01:31:13.529672 140519389960064 learning.py:507] global step 3832: loss = 0.8176 (0.893 sec/step)\n",
            "INFO:tensorflow:global step 3833: loss = 0.8859 (0.723 sec/step)\n",
            "I0503 01:31:14.254338 140519389960064 learning.py:507] global step 3833: loss = 0.8859 (0.723 sec/step)\n",
            "INFO:tensorflow:global step 3834: loss = 0.7669 (0.942 sec/step)\n",
            "I0503 01:31:15.197629 140519389960064 learning.py:507] global step 3834: loss = 0.7669 (0.942 sec/step)\n",
            "INFO:tensorflow:global step 3835: loss = 1.0096 (0.811 sec/step)\n",
            "I0503 01:31:16.010361 140519389960064 learning.py:507] global step 3835: loss = 1.0096 (0.811 sec/step)\n",
            "INFO:tensorflow:global step 3836: loss = 0.7566 (0.870 sec/step)\n",
            "I0503 01:31:16.882415 140519389960064 learning.py:507] global step 3836: loss = 0.7566 (0.870 sec/step)\n",
            "INFO:tensorflow:global step 3837: loss = 1.0607 (0.711 sec/step)\n",
            "I0503 01:31:17.594908 140519389960064 learning.py:507] global step 3837: loss = 1.0607 (0.711 sec/step)\n",
            "INFO:tensorflow:global step 3838: loss = 1.0374 (0.857 sec/step)\n",
            "I0503 01:31:18.453244 140519389960064 learning.py:507] global step 3838: loss = 1.0374 (0.857 sec/step)\n",
            "INFO:tensorflow:global step 3839: loss = 0.7411 (0.950 sec/step)\n",
            "I0503 01:31:19.405245 140519389960064 learning.py:507] global step 3839: loss = 0.7411 (0.950 sec/step)\n",
            "INFO:tensorflow:global step 3840: loss = 0.8279 (0.941 sec/step)\n",
            "I0503 01:31:20.347740 140519389960064 learning.py:507] global step 3840: loss = 0.8279 (0.941 sec/step)\n",
            "INFO:tensorflow:global step 3841: loss = 0.9116 (0.856 sec/step)\n",
            "I0503 01:31:21.204818 140519389960064 learning.py:507] global step 3841: loss = 0.9116 (0.856 sec/step)\n",
            "INFO:tensorflow:global step 3842: loss = 0.7466 (0.874 sec/step)\n",
            "I0503 01:31:22.080182 140519389960064 learning.py:507] global step 3842: loss = 0.7466 (0.874 sec/step)\n",
            "INFO:tensorflow:global step 3843: loss = 0.8340 (0.698 sec/step)\n",
            "I0503 01:31:22.779584 140519389960064 learning.py:507] global step 3843: loss = 0.8340 (0.698 sec/step)\n",
            "INFO:tensorflow:global step 3844: loss = 0.8663 (0.831 sec/step)\n",
            "I0503 01:31:23.612611 140519389960064 learning.py:507] global step 3844: loss = 0.8663 (0.831 sec/step)\n",
            "INFO:tensorflow:global step 3845: loss = 0.7958 (0.897 sec/step)\n",
            "I0503 01:31:24.511091 140519389960064 learning.py:507] global step 3845: loss = 0.7958 (0.897 sec/step)\n",
            "INFO:tensorflow:global step 3846: loss = 0.6898 (0.899 sec/step)\n",
            "I0503 01:31:25.411446 140519389960064 learning.py:507] global step 3846: loss = 0.6898 (0.899 sec/step)\n",
            "INFO:tensorflow:global step 3847: loss = 0.8684 (0.835 sec/step)\n",
            "I0503 01:31:26.247827 140519389960064 learning.py:507] global step 3847: loss = 0.8684 (0.835 sec/step)\n",
            "INFO:tensorflow:global step 3848: loss = 0.7840 (0.761 sec/step)\n",
            "I0503 01:31:27.010490 140519389960064 learning.py:507] global step 3848: loss = 0.7840 (0.761 sec/step)\n",
            "INFO:tensorflow:global step 3849: loss = 0.7354 (0.802 sec/step)\n",
            "I0503 01:31:27.814669 140519389960064 learning.py:507] global step 3849: loss = 0.7354 (0.802 sec/step)\n",
            "INFO:tensorflow:global step 3850: loss = 0.8559 (0.887 sec/step)\n",
            "I0503 01:31:28.703715 140519389960064 learning.py:507] global step 3850: loss = 0.8559 (0.887 sec/step)\n",
            "INFO:tensorflow:global step 3851: loss = 0.6575 (0.843 sec/step)\n",
            "I0503 01:31:29.548599 140519389960064 learning.py:507] global step 3851: loss = 0.6575 (0.843 sec/step)\n",
            "INFO:tensorflow:global step 3852: loss = 1.0532 (0.855 sec/step)\n",
            "I0503 01:31:30.405375 140519389960064 learning.py:507] global step 3852: loss = 1.0532 (0.855 sec/step)\n",
            "INFO:tensorflow:global step 3853: loss = 0.9369 (0.906 sec/step)\n",
            "I0503 01:31:31.312846 140519389960064 learning.py:507] global step 3853: loss = 0.9369 (0.906 sec/step)\n",
            "INFO:tensorflow:global step 3854: loss = 0.6647 (0.790 sec/step)\n",
            "I0503 01:31:32.104759 140519389960064 learning.py:507] global step 3854: loss = 0.6647 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 3855: loss = 1.0932 (0.798 sec/step)\n",
            "I0503 01:31:32.906294 140519389960064 learning.py:507] global step 3855: loss = 1.0932 (0.798 sec/step)\n",
            "INFO:tensorflow:global step 3856: loss = 0.8846 (0.929 sec/step)\n",
            "I0503 01:31:33.836552 140519389960064 learning.py:507] global step 3856: loss = 0.8846 (0.929 sec/step)\n",
            "INFO:tensorflow:global step 3857: loss = 0.7743 (0.695 sec/step)\n",
            "I0503 01:31:34.533221 140519389960064 learning.py:507] global step 3857: loss = 0.7743 (0.695 sec/step)\n",
            "INFO:tensorflow:global step 3858: loss = 0.7179 (0.929 sec/step)\n",
            "I0503 01:31:35.464336 140519389960064 learning.py:507] global step 3858: loss = 0.7179 (0.929 sec/step)\n",
            "INFO:tensorflow:global step 3859: loss = 0.7904 (0.855 sec/step)\n",
            "I0503 01:31:36.320588 140519389960064 learning.py:507] global step 3859: loss = 0.7904 (0.855 sec/step)\n",
            "INFO:tensorflow:global step 3860: loss = 0.7865 (0.761 sec/step)\n",
            "I0503 01:31:37.083376 140519389960064 learning.py:507] global step 3860: loss = 0.7865 (0.761 sec/step)\n",
            "INFO:tensorflow:global step 3861: loss = 0.6967 (1.637 sec/step)\n",
            "I0503 01:31:38.722569 140519389960064 learning.py:507] global step 3861: loss = 0.6967 (1.637 sec/step)\n",
            "INFO:tensorflow:global step 3862: loss = 0.7819 (0.967 sec/step)\n",
            "I0503 01:31:39.692228 140519389960064 learning.py:507] global step 3862: loss = 0.7819 (0.967 sec/step)\n",
            "INFO:tensorflow:global step 3863: loss = 0.8773 (0.714 sec/step)\n",
            "I0503 01:31:40.462011 140519389960064 learning.py:507] global step 3863: loss = 0.8773 (0.714 sec/step)\n",
            "INFO:tensorflow:global step 3864: loss = 0.8831 (0.858 sec/step)\n",
            "I0503 01:31:41.322175 140519389960064 learning.py:507] global step 3864: loss = 0.8831 (0.858 sec/step)\n",
            "INFO:tensorflow:global step 3865: loss = 0.8616 (0.792 sec/step)\n",
            "I0503 01:31:42.191213 140519389960064 learning.py:507] global step 3865: loss = 0.8616 (0.792 sec/step)\n",
            "INFO:tensorflow:global step 3866: loss = 0.9086 (0.957 sec/step)\n",
            "I0503 01:31:43.153309 140519389960064 learning.py:507] global step 3866: loss = 0.9086 (0.957 sec/step)\n",
            "INFO:tensorflow:global step 3867: loss = 0.7155 (0.799 sec/step)\n",
            "I0503 01:31:43.954954 140519389960064 learning.py:507] global step 3867: loss = 0.7155 (0.799 sec/step)\n",
            "INFO:tensorflow:global step 3868: loss = 0.7733 (1.116 sec/step)\n",
            "I0503 01:31:45.072573 140519389960064 learning.py:507] global step 3868: loss = 0.7733 (1.116 sec/step)\n",
            "INFO:tensorflow:global step 3869: loss = 1.0523 (0.656 sec/step)\n",
            "I0503 01:31:45.735418 140519389960064 learning.py:507] global step 3869: loss = 1.0523 (0.656 sec/step)\n",
            "INFO:tensorflow:global step 3870: loss = 0.8240 (0.899 sec/step)\n",
            "I0503 01:31:46.643859 140519389960064 learning.py:507] global step 3870: loss = 0.8240 (0.899 sec/step)\n",
            "INFO:tensorflow:global step 3871: loss = 0.7451 (0.813 sec/step)\n",
            "I0503 01:31:47.458833 140519389960064 learning.py:507] global step 3871: loss = 0.7451 (0.813 sec/step)\n",
            "INFO:tensorflow:global step 3872: loss = 0.8023 (0.932 sec/step)\n",
            "I0503 01:31:48.392630 140519389960064 learning.py:507] global step 3872: loss = 0.8023 (0.932 sec/step)\n",
            "INFO:tensorflow:global step 3873: loss = 0.7450 (0.919 sec/step)\n",
            "I0503 01:31:49.313082 140519389960064 learning.py:507] global step 3873: loss = 0.7450 (0.919 sec/step)\n",
            "INFO:tensorflow:global step 3874: loss = 0.6841 (0.792 sec/step)\n",
            "I0503 01:31:50.106737 140519389960064 learning.py:507] global step 3874: loss = 0.6841 (0.792 sec/step)\n",
            "INFO:tensorflow:global step 3875: loss = 0.9076 (0.839 sec/step)\n",
            "I0503 01:31:50.947470 140519389960064 learning.py:507] global step 3875: loss = 0.9076 (0.839 sec/step)\n",
            "INFO:tensorflow:global step 3876: loss = 0.7572 (0.956 sec/step)\n",
            "I0503 01:31:51.905591 140519389960064 learning.py:507] global step 3876: loss = 0.7572 (0.956 sec/step)\n",
            "INFO:tensorflow:global step 3877: loss = 0.8321 (0.841 sec/step)\n",
            "I0503 01:31:52.747897 140519389960064 learning.py:507] global step 3877: loss = 0.8321 (0.841 sec/step)\n",
            "INFO:tensorflow:global step 3878: loss = 0.5387 (0.836 sec/step)\n",
            "I0503 01:31:53.586933 140519389960064 learning.py:507] global step 3878: loss = 0.5387 (0.836 sec/step)\n",
            "INFO:tensorflow:global step 3879: loss = 0.7549 (0.812 sec/step)\n",
            "I0503 01:31:54.400545 140519389960064 learning.py:507] global step 3879: loss = 0.7549 (0.812 sec/step)\n",
            "INFO:tensorflow:global step 3880: loss = 0.7640 (0.783 sec/step)\n",
            "I0503 01:31:55.184913 140519389960064 learning.py:507] global step 3880: loss = 0.7640 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 3881: loss = 0.7086 (0.837 sec/step)\n",
            "I0503 01:31:56.024664 140519389960064 learning.py:507] global step 3881: loss = 0.7086 (0.837 sec/step)\n",
            "INFO:tensorflow:global step 3882: loss = 0.7251 (0.875 sec/step)\n",
            "I0503 01:31:56.901685 140519389960064 learning.py:507] global step 3882: loss = 0.7251 (0.875 sec/step)\n",
            "INFO:tensorflow:global step 3883: loss = 0.9913 (0.799 sec/step)\n",
            "I0503 01:31:57.702681 140519389960064 learning.py:507] global step 3883: loss = 0.9913 (0.799 sec/step)\n",
            "INFO:tensorflow:global step 3884: loss = 0.7562 (0.783 sec/step)\n",
            "I0503 01:31:58.487451 140519389960064 learning.py:507] global step 3884: loss = 0.7562 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 3885: loss = 0.9247 (1.124 sec/step)\n",
            "I0503 01:31:59.613539 140519389960064 learning.py:507] global step 3885: loss = 0.9247 (1.124 sec/step)\n",
            "INFO:tensorflow:global step 3886: loss = 0.8667 (0.872 sec/step)\n",
            "I0503 01:32:00.486783 140519389960064 learning.py:507] global step 3886: loss = 0.8667 (0.872 sec/step)\n",
            "INFO:tensorflow:global step 3887: loss = 0.7731 (0.709 sec/step)\n",
            "I0503 01:32:01.198830 140519389960064 learning.py:507] global step 3887: loss = 0.7731 (0.709 sec/step)\n",
            "INFO:tensorflow:global step 3888: loss = 0.7854 (0.811 sec/step)\n",
            "I0503 01:32:02.011467 140519389960064 learning.py:507] global step 3888: loss = 0.7854 (0.811 sec/step)\n",
            "INFO:tensorflow:global step 3889: loss = 0.7977 (0.719 sec/step)\n",
            "I0503 01:32:02.731841 140519389960064 learning.py:507] global step 3889: loss = 0.7977 (0.719 sec/step)\n",
            "INFO:tensorflow:global step 3890: loss = 1.0853 (0.875 sec/step)\n",
            "I0503 01:32:03.608813 140519389960064 learning.py:507] global step 3890: loss = 1.0853 (0.875 sec/step)\n",
            "INFO:tensorflow:global step 3891: loss = 0.6491 (0.729 sec/step)\n",
            "I0503 01:32:04.340038 140519389960064 learning.py:507] global step 3891: loss = 0.6491 (0.729 sec/step)\n",
            "INFO:tensorflow:global step 3892: loss = 0.9249 (0.792 sec/step)\n",
            "I0503 01:32:05.133359 140519389960064 learning.py:507] global step 3892: loss = 0.9249 (0.792 sec/step)\n",
            "INFO:tensorflow:global step 3893: loss = 0.7910 (0.800 sec/step)\n",
            "I0503 01:32:05.935194 140519389960064 learning.py:507] global step 3893: loss = 0.7910 (0.800 sec/step)\n",
            "INFO:tensorflow:global step 3894: loss = 0.6996 (0.881 sec/step)\n",
            "I0503 01:32:06.818206 140519389960064 learning.py:507] global step 3894: loss = 0.6996 (0.881 sec/step)\n",
            "INFO:tensorflow:global step 3895: loss = 0.9414 (0.785 sec/step)\n",
            "I0503 01:32:07.604668 140519389960064 learning.py:507] global step 3895: loss = 0.9414 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 3896: loss = 0.8326 (0.675 sec/step)\n",
            "I0503 01:32:08.281796 140519389960064 learning.py:507] global step 3896: loss = 0.8326 (0.675 sec/step)\n",
            "INFO:tensorflow:global step 3897: loss = 0.9284 (0.770 sec/step)\n",
            "I0503 01:32:09.053712 140519389960064 learning.py:507] global step 3897: loss = 0.9284 (0.770 sec/step)\n",
            "INFO:tensorflow:global step 3898: loss = 0.8758 (0.811 sec/step)\n",
            "I0503 01:32:09.865783 140519389960064 learning.py:507] global step 3898: loss = 0.8758 (0.811 sec/step)\n",
            "INFO:tensorflow:global step 3899: loss = 0.7334 (0.933 sec/step)\n",
            "I0503 01:32:10.800312 140519389960064 learning.py:507] global step 3899: loss = 0.7334 (0.933 sec/step)\n",
            "INFO:tensorflow:global step 3900: loss = 0.7959 (0.726 sec/step)\n",
            "I0503 01:32:11.527652 140519389960064 learning.py:507] global step 3900: loss = 0.7959 (0.726 sec/step)\n",
            "INFO:tensorflow:global step 3901: loss = 0.7718 (1.297 sec/step)\n",
            "I0503 01:32:12.826585 140519389960064 learning.py:507] global step 3901: loss = 0.7718 (1.297 sec/step)\n",
            "INFO:tensorflow:global step 3902: loss = 0.8174 (0.673 sec/step)\n",
            "I0503 01:32:13.534198 140519389960064 learning.py:507] global step 3902: loss = 0.8174 (0.673 sec/step)\n",
            "INFO:tensorflow:global step 3903: loss = 1.0369 (0.705 sec/step)\n",
            "I0503 01:32:14.245715 140519389960064 learning.py:507] global step 3903: loss = 1.0369 (0.705 sec/step)\n",
            "INFO:tensorflow:global step 3904: loss = 0.8580 (1.290 sec/step)\n",
            "I0503 01:32:15.537055 140519389960064 learning.py:507] global step 3904: loss = 0.8580 (1.290 sec/step)\n",
            "INFO:tensorflow:global step 3905: loss = 0.6245 (0.832 sec/step)\n",
            "I0503 01:32:16.404416 140519389960064 learning.py:507] global step 3905: loss = 0.6245 (0.832 sec/step)\n",
            "INFO:tensorflow:global step 3906: loss = 0.8018 (1.023 sec/step)\n",
            "I0503 01:32:17.432820 140519389960064 learning.py:507] global step 3906: loss = 0.8018 (1.023 sec/step)\n",
            "INFO:tensorflow:global step 3907: loss = 0.7112 (0.796 sec/step)\n",
            "I0503 01:32:18.230520 140519389960064 learning.py:507] global step 3907: loss = 0.7112 (0.796 sec/step)\n",
            "INFO:tensorflow:global step 3908: loss = 0.9857 (0.919 sec/step)\n",
            "I0503 01:32:19.150923 140519389960064 learning.py:507] global step 3908: loss = 0.9857 (0.919 sec/step)\n",
            "INFO:tensorflow:global step 3909: loss = 0.8594 (0.822 sec/step)\n",
            "I0503 01:32:19.974817 140519389960064 learning.py:507] global step 3909: loss = 0.8594 (0.822 sec/step)\n",
            "INFO:tensorflow:global step 3910: loss = 0.6449 (0.872 sec/step)\n",
            "I0503 01:32:20.849025 140519389960064 learning.py:507] global step 3910: loss = 0.6449 (0.872 sec/step)\n",
            "INFO:tensorflow:global step 3911: loss = 0.9068 (0.869 sec/step)\n",
            "I0503 01:32:21.719125 140519389960064 learning.py:507] global step 3911: loss = 0.9068 (0.869 sec/step)\n",
            "INFO:tensorflow:global step 3912: loss = 0.7558 (0.783 sec/step)\n",
            "I0503 01:32:22.503454 140519389960064 learning.py:507] global step 3912: loss = 0.7558 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 3913: loss = 1.3537 (0.834 sec/step)\n",
            "I0503 01:32:23.339316 140519389960064 learning.py:507] global step 3913: loss = 1.3537 (0.834 sec/step)\n",
            "INFO:tensorflow:global step 3914: loss = 0.7874 (0.789 sec/step)\n",
            "I0503 01:32:24.130738 140519389960064 learning.py:507] global step 3914: loss = 0.7874 (0.789 sec/step)\n",
            "INFO:tensorflow:global step 3915: loss = 0.8548 (0.956 sec/step)\n",
            "I0503 01:32:25.089663 140519389960064 learning.py:507] global step 3915: loss = 0.8548 (0.956 sec/step)\n",
            "INFO:tensorflow:global step 3916: loss = 0.7027 (0.866 sec/step)\n",
            "I0503 01:32:25.957037 140519389960064 learning.py:507] global step 3916: loss = 0.7027 (0.866 sec/step)\n",
            "INFO:tensorflow:global step 3917: loss = 0.7339 (0.681 sec/step)\n",
            "I0503 01:32:26.640184 140519389960064 learning.py:507] global step 3917: loss = 0.7339 (0.681 sec/step)\n",
            "INFO:tensorflow:global step 3918: loss = 0.8148 (1.100 sec/step)\n",
            "I0503 01:32:27.741808 140519389960064 learning.py:507] global step 3918: loss = 0.8148 (1.100 sec/step)\n",
            "INFO:tensorflow:global step 3919: loss = 0.7605 (0.753 sec/step)\n",
            "I0503 01:32:28.528699 140519389960064 learning.py:507] global step 3919: loss = 0.7605 (0.753 sec/step)\n",
            "INFO:tensorflow:global step 3920: loss = 0.6960 (0.883 sec/step)\n",
            "I0503 01:32:29.416716 140519389960064 learning.py:507] global step 3920: loss = 0.6960 (0.883 sec/step)\n",
            "INFO:tensorflow:global step 3921: loss = 0.6767 (0.879 sec/step)\n",
            "I0503 01:32:30.297590 140519389960064 learning.py:507] global step 3921: loss = 0.6767 (0.879 sec/step)\n",
            "INFO:tensorflow:global step 3922: loss = 0.7645 (0.873 sec/step)\n",
            "I0503 01:32:31.171999 140519389960064 learning.py:507] global step 3922: loss = 0.7645 (0.873 sec/step)\n",
            "INFO:tensorflow:global step 3923: loss = 0.5797 (0.782 sec/step)\n",
            "I0503 01:32:32.075851 140519389960064 learning.py:507] global step 3923: loss = 0.5797 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 3924: loss = 1.1859 (0.799 sec/step)\n",
            "I0503 01:32:32.924372 140519389960064 learning.py:507] global step 3924: loss = 1.1859 (0.799 sec/step)\n",
            "INFO:tensorflow:global step 3925: loss = 0.8524 (0.722 sec/step)\n",
            "I0503 01:32:33.647635 140519389960064 learning.py:507] global step 3925: loss = 0.8524 (0.722 sec/step)\n",
            "INFO:tensorflow:global step 3926: loss = 1.0448 (0.797 sec/step)\n",
            "I0503 01:32:34.446324 140519389960064 learning.py:507] global step 3926: loss = 1.0448 (0.797 sec/step)\n",
            "INFO:tensorflow:global step 3927: loss = 0.7072 (0.852 sec/step)\n",
            "I0503 01:32:35.299425 140519389960064 learning.py:507] global step 3927: loss = 0.7072 (0.852 sec/step)\n",
            "INFO:tensorflow:global step 3928: loss = 0.7493 (0.740 sec/step)\n",
            "I0503 01:32:36.040644 140519389960064 learning.py:507] global step 3928: loss = 0.7493 (0.740 sec/step)\n",
            "INFO:tensorflow:global step 3929: loss = 0.8720 (0.847 sec/step)\n",
            "I0503 01:32:36.956164 140519389960064 learning.py:507] global step 3929: loss = 0.8720 (0.847 sec/step)\n",
            "INFO:tensorflow:global step 3930: loss = 0.8002 (1.063 sec/step)\n",
            "I0503 01:32:38.021491 140519389960064 learning.py:507] global step 3930: loss = 0.8002 (1.063 sec/step)\n",
            "INFO:tensorflow:global step 3931: loss = 0.7357 (0.887 sec/step)\n",
            "I0503 01:32:38.909729 140519389960064 learning.py:507] global step 3931: loss = 0.7357 (0.887 sec/step)\n",
            "INFO:tensorflow:global step 3932: loss = 0.7269 (0.864 sec/step)\n",
            "I0503 01:32:39.776430 140519389960064 learning.py:507] global step 3932: loss = 0.7269 (0.864 sec/step)\n",
            "INFO:tensorflow:global step 3933: loss = 0.8371 (0.787 sec/step)\n",
            "I0503 01:32:40.564988 140519389960064 learning.py:507] global step 3933: loss = 0.8371 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 3934: loss = 1.2493 (0.798 sec/step)\n",
            "I0503 01:32:41.364492 140519389960064 learning.py:507] global step 3934: loss = 1.2493 (0.798 sec/step)\n",
            "INFO:tensorflow:global step 3935: loss = 0.6601 (0.868 sec/step)\n",
            "I0503 01:32:42.233793 140519389960064 learning.py:507] global step 3935: loss = 0.6601 (0.868 sec/step)\n",
            "INFO:tensorflow:global step 3936: loss = 0.6694 (0.756 sec/step)\n",
            "I0503 01:32:42.991238 140519389960064 learning.py:507] global step 3936: loss = 0.6694 (0.756 sec/step)\n",
            "INFO:tensorflow:global step 3937: loss = 0.8296 (0.770 sec/step)\n",
            "I0503 01:32:43.762473 140519389960064 learning.py:507] global step 3937: loss = 0.8296 (0.770 sec/step)\n",
            "INFO:tensorflow:global step 3938: loss = 0.9374 (0.817 sec/step)\n",
            "I0503 01:32:44.582587 140519389960064 learning.py:507] global step 3938: loss = 0.9374 (0.817 sec/step)\n",
            "INFO:tensorflow:global step 3939: loss = 1.0798 (0.666 sec/step)\n",
            "I0503 01:32:45.257957 140519389960064 learning.py:507] global step 3939: loss = 1.0798 (0.666 sec/step)\n",
            "INFO:tensorflow:global step 3940: loss = 0.8228 (0.813 sec/step)\n",
            "I0503 01:32:46.072624 140519389960064 learning.py:507] global step 3940: loss = 0.8228 (0.813 sec/step)\n",
            "INFO:tensorflow:global step 3941: loss = 0.6699 (0.851 sec/step)\n",
            "I0503 01:32:46.925633 140519389960064 learning.py:507] global step 3941: loss = 0.6699 (0.851 sec/step)\n",
            "INFO:tensorflow:global step 3942: loss = 0.8602 (0.923 sec/step)\n",
            "I0503 01:32:47.850296 140519389960064 learning.py:507] global step 3942: loss = 0.8602 (0.923 sec/step)\n",
            "INFO:tensorflow:global step 3943: loss = 0.9148 (0.753 sec/step)\n",
            "I0503 01:32:48.605098 140519389960064 learning.py:507] global step 3943: loss = 0.9148 (0.753 sec/step)\n",
            "INFO:tensorflow:global step 3944: loss = 0.9080 (0.957 sec/step)\n",
            "I0503 01:32:49.564198 140519389960064 learning.py:507] global step 3944: loss = 0.9080 (0.957 sec/step)\n",
            "INFO:tensorflow:global step 3945: loss = 0.8934 (0.834 sec/step)\n",
            "I0503 01:32:50.399587 140519389960064 learning.py:507] global step 3945: loss = 0.8934 (0.834 sec/step)\n",
            "INFO:tensorflow:global step 3946: loss = 0.8311 (0.743 sec/step)\n",
            "I0503 01:32:51.144130 140519389960064 learning.py:507] global step 3946: loss = 0.8311 (0.743 sec/step)\n",
            "INFO:tensorflow:global step 3947: loss = 0.9549 (0.827 sec/step)\n",
            "I0503 01:32:51.972568 140519389960064 learning.py:507] global step 3947: loss = 0.9549 (0.827 sec/step)\n",
            "INFO:tensorflow:global step 3948: loss = 0.8989 (0.838 sec/step)\n",
            "I0503 01:32:52.812098 140519389960064 learning.py:507] global step 3948: loss = 0.8989 (0.838 sec/step)\n",
            "INFO:tensorflow:global step 3949: loss = 0.7900 (0.910 sec/step)\n",
            "I0503 01:32:53.724205 140519389960064 learning.py:507] global step 3949: loss = 0.7900 (0.910 sec/step)\n",
            "INFO:tensorflow:global step 3950: loss = 0.7095 (0.598 sec/step)\n",
            "I0503 01:32:54.335916 140519389960064 learning.py:507] global step 3950: loss = 0.7095 (0.598 sec/step)\n",
            "INFO:tensorflow:global step 3951: loss = 0.6270 (0.851 sec/step)\n",
            "I0503 01:32:55.188849 140519389960064 learning.py:507] global step 3951: loss = 0.6270 (0.851 sec/step)\n",
            "INFO:tensorflow:global step 3952: loss = 0.8236 (0.784 sec/step)\n",
            "I0503 01:32:55.974629 140519389960064 learning.py:507] global step 3952: loss = 0.8236 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 3953: loss = 0.9296 (0.899 sec/step)\n",
            "I0503 01:32:56.875008 140519389960064 learning.py:507] global step 3953: loss = 0.9296 (0.899 sec/step)\n",
            "INFO:tensorflow:global step 3954: loss = 0.8525 (0.763 sec/step)\n",
            "I0503 01:32:57.690964 140519389960064 learning.py:507] global step 3954: loss = 0.8525 (0.763 sec/step)\n",
            "INFO:tensorflow:global step 3955: loss = 0.7791 (0.908 sec/step)\n",
            "I0503 01:32:58.612714 140519389960064 learning.py:507] global step 3955: loss = 0.7791 (0.908 sec/step)\n",
            "INFO:tensorflow:global step 3956: loss = 0.7958 (1.860 sec/step)\n",
            "I0503 01:33:00.484932 140519389960064 learning.py:507] global step 3956: loss = 0.7958 (1.860 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 3956.\n",
            "I0503 01:33:00.918426 140515676296960 supervisor.py:1050] Recording summary at step 3956.\n",
            "INFO:tensorflow:global step 3957: loss = 0.5959 (0.806 sec/step)\n",
            "I0503 01:33:01.312103 140519389960064 learning.py:507] global step 3957: loss = 0.5959 (0.806 sec/step)\n",
            "INFO:tensorflow:global step 3958: loss = 0.8055 (0.994 sec/step)\n",
            "I0503 01:33:02.308188 140519389960064 learning.py:507] global step 3958: loss = 0.8055 (0.994 sec/step)\n",
            "INFO:tensorflow:global_step/sec: 1.16514\n",
            "I0503 01:33:03.005801 140515684689664 supervisor.py:1099] global_step/sec: 1.16514\n",
            "INFO:tensorflow:global step 3959: loss = 0.8245 (0.800 sec/step)\n",
            "I0503 01:33:03.134945 140519389960064 learning.py:507] global step 3959: loss = 0.8245 (0.800 sec/step)\n",
            "INFO:tensorflow:global step 3960: loss = 1.0340 (1.108 sec/step)\n",
            "I0503 01:33:04.245692 140519389960064 learning.py:507] global step 3960: loss = 1.0340 (1.108 sec/step)\n",
            "INFO:tensorflow:global step 3961: loss = 0.6502 (0.878 sec/step)\n",
            "I0503 01:33:05.125175 140519389960064 learning.py:507] global step 3961: loss = 0.6502 (0.878 sec/step)\n",
            "INFO:tensorflow:global step 3962: loss = 0.6739 (0.731 sec/step)\n",
            "I0503 01:33:05.858176 140519389960064 learning.py:507] global step 3962: loss = 0.6739 (0.731 sec/step)\n",
            "INFO:tensorflow:global step 3963: loss = 0.7769 (0.833 sec/step)\n",
            "I0503 01:33:06.692559 140519389960064 learning.py:507] global step 3963: loss = 0.7769 (0.833 sec/step)\n",
            "INFO:tensorflow:global step 3964: loss = 0.7840 (0.881 sec/step)\n",
            "I0503 01:33:07.575013 140519389960064 learning.py:507] global step 3964: loss = 0.7840 (0.881 sec/step)\n",
            "INFO:tensorflow:global step 3965: loss = 0.7490 (0.743 sec/step)\n",
            "I0503 01:33:08.320831 140519389960064 learning.py:507] global step 3965: loss = 0.7490 (0.743 sec/step)\n",
            "INFO:tensorflow:global step 3966: loss = 0.7662 (0.966 sec/step)\n",
            "I0503 01:33:09.288935 140519389960064 learning.py:507] global step 3966: loss = 0.7662 (0.966 sec/step)\n",
            "INFO:tensorflow:global step 3967: loss = 0.7552 (0.823 sec/step)\n",
            "I0503 01:33:10.113531 140519389960064 learning.py:507] global step 3967: loss = 0.7552 (0.823 sec/step)\n",
            "INFO:tensorflow:global step 3968: loss = 0.9285 (0.906 sec/step)\n",
            "I0503 01:33:11.021121 140519389960064 learning.py:507] global step 3968: loss = 0.9285 (0.906 sec/step)\n",
            "INFO:tensorflow:global step 3969: loss = 0.9446 (0.778 sec/step)\n",
            "I0503 01:33:11.800638 140519389960064 learning.py:507] global step 3969: loss = 0.9446 (0.778 sec/step)\n",
            "INFO:tensorflow:global step 3970: loss = 0.7195 (0.706 sec/step)\n",
            "I0503 01:33:12.508512 140519389960064 learning.py:507] global step 3970: loss = 0.7195 (0.706 sec/step)\n",
            "INFO:tensorflow:global step 3971: loss = 1.0381 (0.851 sec/step)\n",
            "I0503 01:33:13.361008 140519389960064 learning.py:507] global step 3971: loss = 1.0381 (0.851 sec/step)\n",
            "INFO:tensorflow:global step 3972: loss = 0.7555 (0.899 sec/step)\n",
            "I0503 01:33:14.261427 140519389960064 learning.py:507] global step 3972: loss = 0.7555 (0.899 sec/step)\n",
            "INFO:tensorflow:global step 3973: loss = 0.8344 (0.805 sec/step)\n",
            "I0503 01:33:15.067960 140519389960064 learning.py:507] global step 3973: loss = 0.8344 (0.805 sec/step)\n",
            "INFO:tensorflow:global step 3974: loss = 0.8647 (0.734 sec/step)\n",
            "I0503 01:33:15.804288 140519389960064 learning.py:507] global step 3974: loss = 0.8647 (0.734 sec/step)\n",
            "INFO:tensorflow:global step 3975: loss = 0.9665 (0.842 sec/step)\n",
            "I0503 01:33:16.647468 140519389960064 learning.py:507] global step 3975: loss = 0.9665 (0.842 sec/step)\n",
            "INFO:tensorflow:global step 3976: loss = 0.7294 (0.886 sec/step)\n",
            "I0503 01:33:17.535267 140519389960064 learning.py:507] global step 3976: loss = 0.7294 (0.886 sec/step)\n",
            "INFO:tensorflow:global step 3977: loss = 0.7106 (0.787 sec/step)\n",
            "I0503 01:33:18.323367 140519389960064 learning.py:507] global step 3977: loss = 0.7106 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 3978: loss = 0.8093 (0.905 sec/step)\n",
            "I0503 01:33:19.230328 140519389960064 learning.py:507] global step 3978: loss = 0.8093 (0.905 sec/step)\n",
            "INFO:tensorflow:global step 3979: loss = 0.9170 (0.791 sec/step)\n",
            "I0503 01:33:20.023113 140519389960064 learning.py:507] global step 3979: loss = 0.9170 (0.791 sec/step)\n",
            "INFO:tensorflow:global step 3980: loss = 0.6719 (0.781 sec/step)\n",
            "I0503 01:33:20.806181 140519389960064 learning.py:507] global step 3980: loss = 0.6719 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 3981: loss = 0.7228 (0.904 sec/step)\n",
            "I0503 01:33:21.711426 140519389960064 learning.py:507] global step 3981: loss = 0.7228 (0.904 sec/step)\n",
            "INFO:tensorflow:global step 3982: loss = 0.7402 (0.779 sec/step)\n",
            "I0503 01:33:22.492390 140519389960064 learning.py:507] global step 3982: loss = 0.7402 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 3983: loss = 0.6549 (0.781 sec/step)\n",
            "I0503 01:33:23.275305 140519389960064 learning.py:507] global step 3983: loss = 0.6549 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 3984: loss = 0.8383 (0.769 sec/step)\n",
            "I0503 01:33:24.045575 140519389960064 learning.py:507] global step 3984: loss = 0.8383 (0.769 sec/step)\n",
            "INFO:tensorflow:global step 3985: loss = 0.8499 (0.745 sec/step)\n",
            "I0503 01:33:24.792617 140519389960064 learning.py:507] global step 3985: loss = 0.8499 (0.745 sec/step)\n",
            "INFO:tensorflow:global step 3986: loss = 0.5899 (0.761 sec/step)\n",
            "I0503 01:33:25.555217 140519389960064 learning.py:507] global step 3986: loss = 0.5899 (0.761 sec/step)\n",
            "INFO:tensorflow:global step 3987: loss = 0.6549 (0.799 sec/step)\n",
            "I0503 01:33:26.355709 140519389960064 learning.py:507] global step 3987: loss = 0.6549 (0.799 sec/step)\n",
            "INFO:tensorflow:global step 3988: loss = 0.8508 (0.948 sec/step)\n",
            "I0503 01:33:27.305710 140519389960064 learning.py:507] global step 3988: loss = 0.8508 (0.948 sec/step)\n",
            "INFO:tensorflow:global step 3989: loss = 0.7007 (0.848 sec/step)\n",
            "I0503 01:33:28.155603 140519389960064 learning.py:507] global step 3989: loss = 0.7007 (0.848 sec/step)\n",
            "INFO:tensorflow:global step 3990: loss = 0.7760 (0.810 sec/step)\n",
            "I0503 01:33:28.967383 140519389960064 learning.py:507] global step 3990: loss = 0.7760 (0.810 sec/step)\n",
            "INFO:tensorflow:global step 3991: loss = 1.0273 (0.754 sec/step)\n",
            "I0503 01:33:29.722856 140519389960064 learning.py:507] global step 3991: loss = 1.0273 (0.754 sec/step)\n",
            "INFO:tensorflow:global step 3992: loss = 0.7398 (0.848 sec/step)\n",
            "I0503 01:33:30.573398 140519389960064 learning.py:507] global step 3992: loss = 0.7398 (0.848 sec/step)\n",
            "INFO:tensorflow:global step 3993: loss = 0.5716 (0.810 sec/step)\n",
            "I0503 01:33:31.385325 140519389960064 learning.py:507] global step 3993: loss = 0.5716 (0.810 sec/step)\n",
            "INFO:tensorflow:global step 3994: loss = 0.8189 (0.749 sec/step)\n",
            "I0503 01:33:32.163666 140519389960064 learning.py:507] global step 3994: loss = 0.8189 (0.749 sec/step)\n",
            "INFO:tensorflow:global step 3995: loss = 0.6125 (0.917 sec/step)\n",
            "I0503 01:33:33.083565 140519389960064 learning.py:507] global step 3995: loss = 0.6125 (0.917 sec/step)\n",
            "INFO:tensorflow:global step 3996: loss = 0.9651 (0.861 sec/step)\n",
            "I0503 01:33:33.946084 140519389960064 learning.py:507] global step 3996: loss = 0.9651 (0.861 sec/step)\n",
            "INFO:tensorflow:global step 3997: loss = 0.8446 (0.740 sec/step)\n",
            "I0503 01:33:34.687520 140519389960064 learning.py:507] global step 3997: loss = 0.8446 (0.740 sec/step)\n",
            "INFO:tensorflow:global step 3998: loss = 0.8856 (0.913 sec/step)\n",
            "I0503 01:33:35.601863 140519389960064 learning.py:507] global step 3998: loss = 0.8856 (0.913 sec/step)\n",
            "INFO:tensorflow:global step 3999: loss = 0.6892 (0.896 sec/step)\n",
            "I0503 01:33:36.500865 140519389960064 learning.py:507] global step 3999: loss = 0.6892 (0.896 sec/step)\n",
            "INFO:tensorflow:global step 4000: loss = 0.6788 (0.965 sec/step)\n",
            "I0503 01:33:37.467272 140519389960064 learning.py:507] global step 4000: loss = 0.6788 (0.965 sec/step)\n",
            "INFO:tensorflow:global step 4001: loss = 0.9292 (0.797 sec/step)\n",
            "I0503 01:33:38.265763 140519389960064 learning.py:507] global step 4001: loss = 0.9292 (0.797 sec/step)\n",
            "INFO:tensorflow:global step 4002: loss = 0.8839 (0.813 sec/step)\n",
            "I0503 01:33:39.079998 140519389960064 learning.py:507] global step 4002: loss = 0.8839 (0.813 sec/step)\n",
            "INFO:tensorflow:global step 4003: loss = 0.8392 (0.809 sec/step)\n",
            "I0503 01:33:39.890725 140519389960064 learning.py:507] global step 4003: loss = 0.8392 (0.809 sec/step)\n",
            "INFO:tensorflow:global step 4004: loss = 0.9748 (0.770 sec/step)\n",
            "I0503 01:33:40.662640 140519389960064 learning.py:507] global step 4004: loss = 0.9748 (0.770 sec/step)\n",
            "INFO:tensorflow:global step 4005: loss = 0.5269 (1.054 sec/step)\n",
            "I0503 01:33:41.718284 140519389960064 learning.py:507] global step 4005: loss = 0.5269 (1.054 sec/step)\n",
            "INFO:tensorflow:global step 4006: loss = 1.0604 (0.776 sec/step)\n",
            "I0503 01:33:42.584287 140519389960064 learning.py:507] global step 4006: loss = 1.0604 (0.776 sec/step)\n",
            "INFO:tensorflow:global step 4007: loss = 0.9330 (0.823 sec/step)\n",
            "I0503 01:33:43.497244 140519389960064 learning.py:507] global step 4007: loss = 0.9330 (0.823 sec/step)\n",
            "INFO:tensorflow:global step 4008: loss = 0.7233 (0.853 sec/step)\n",
            "I0503 01:33:44.358615 140519389960064 learning.py:507] global step 4008: loss = 0.7233 (0.853 sec/step)\n",
            "INFO:tensorflow:global step 4009: loss = 0.8442 (0.922 sec/step)\n",
            "I0503 01:33:45.282620 140519389960064 learning.py:507] global step 4009: loss = 0.8442 (0.922 sec/step)\n",
            "INFO:tensorflow:global step 4010: loss = 0.9224 (0.767 sec/step)\n",
            "I0503 01:33:46.054792 140519389960064 learning.py:507] global step 4010: loss = 0.9224 (0.767 sec/step)\n",
            "INFO:tensorflow:global step 4011: loss = 0.6915 (0.670 sec/step)\n",
            "I0503 01:33:46.727554 140519389960064 learning.py:507] global step 4011: loss = 0.6915 (0.670 sec/step)\n",
            "INFO:tensorflow:global step 4012: loss = 0.7447 (1.037 sec/step)\n",
            "I0503 01:33:47.766803 140519389960064 learning.py:507] global step 4012: loss = 0.7447 (1.037 sec/step)\n",
            "INFO:tensorflow:global step 4013: loss = 0.7776 (0.888 sec/step)\n",
            "I0503 01:33:48.656809 140519389960064 learning.py:507] global step 4013: loss = 0.7776 (0.888 sec/step)\n",
            "INFO:tensorflow:global step 4014: loss = 0.7880 (0.879 sec/step)\n",
            "I0503 01:33:49.537618 140519389960064 learning.py:507] global step 4014: loss = 0.7880 (0.879 sec/step)\n",
            "INFO:tensorflow:global step 4015: loss = 1.3187 (0.807 sec/step)\n",
            "I0503 01:33:50.346528 140519389960064 learning.py:507] global step 4015: loss = 1.3187 (0.807 sec/step)\n",
            "INFO:tensorflow:global step 4016: loss = 0.7601 (0.900 sec/step)\n",
            "I0503 01:33:51.248602 140519389960064 learning.py:507] global step 4016: loss = 0.7601 (0.900 sec/step)\n",
            "INFO:tensorflow:global step 4017: loss = 0.7621 (0.846 sec/step)\n",
            "I0503 01:33:52.095852 140519389960064 learning.py:507] global step 4017: loss = 0.7621 (0.846 sec/step)\n",
            "INFO:tensorflow:global step 4018: loss = 0.7761 (0.893 sec/step)\n",
            "I0503 01:33:52.990655 140519389960064 learning.py:507] global step 4018: loss = 0.7761 (0.893 sec/step)\n",
            "INFO:tensorflow:global step 4019: loss = 0.8260 (0.911 sec/step)\n",
            "I0503 01:33:53.902627 140519389960064 learning.py:507] global step 4019: loss = 0.8260 (0.911 sec/step)\n",
            "INFO:tensorflow:global step 4020: loss = 0.7889 (0.751 sec/step)\n",
            "I0503 01:33:54.654740 140519389960064 learning.py:507] global step 4020: loss = 0.7889 (0.751 sec/step)\n",
            "INFO:tensorflow:global step 4021: loss = 0.7719 (0.889 sec/step)\n",
            "I0503 01:33:55.544899 140519389960064 learning.py:507] global step 4021: loss = 0.7719 (0.889 sec/step)\n",
            "INFO:tensorflow:global step 4022: loss = 0.7412 (0.810 sec/step)\n",
            "I0503 01:33:56.356376 140519389960064 learning.py:507] global step 4022: loss = 0.7412 (0.810 sec/step)\n",
            "INFO:tensorflow:global step 4023: loss = 0.8107 (0.714 sec/step)\n",
            "I0503 01:33:57.072008 140519389960064 learning.py:507] global step 4023: loss = 0.8107 (0.714 sec/step)\n",
            "INFO:tensorflow:global step 4024: loss = 0.6626 (0.793 sec/step)\n",
            "I0503 01:33:57.866678 140519389960064 learning.py:507] global step 4024: loss = 0.6626 (0.793 sec/step)\n",
            "INFO:tensorflow:global step 4025: loss = 0.7571 (0.900 sec/step)\n",
            "I0503 01:33:58.768460 140519389960064 learning.py:507] global step 4025: loss = 0.7571 (0.900 sec/step)\n",
            "INFO:tensorflow:global step 4026: loss = 0.9242 (0.845 sec/step)\n",
            "I0503 01:33:59.615277 140519389960064 learning.py:507] global step 4026: loss = 0.9242 (0.845 sec/step)\n",
            "INFO:tensorflow:global step 4027: loss = 0.7254 (0.937 sec/step)\n",
            "I0503 01:34:00.553561 140519389960064 learning.py:507] global step 4027: loss = 0.7254 (0.937 sec/step)\n",
            "INFO:tensorflow:global step 4028: loss = 0.7408 (0.879 sec/step)\n",
            "I0503 01:34:01.434352 140519389960064 learning.py:507] global step 4028: loss = 0.7408 (0.879 sec/step)\n",
            "INFO:tensorflow:global step 4029: loss = 0.9170 (0.706 sec/step)\n",
            "I0503 01:34:02.148501 140519389960064 learning.py:507] global step 4029: loss = 0.9170 (0.706 sec/step)\n",
            "INFO:tensorflow:global step 4030: loss = 0.7335 (0.865 sec/step)\n",
            "I0503 01:34:03.015805 140519389960064 learning.py:507] global step 4030: loss = 0.7335 (0.865 sec/step)\n",
            "INFO:tensorflow:global step 4031: loss = 0.6789 (0.848 sec/step)\n",
            "I0503 01:34:03.865876 140519389960064 learning.py:507] global step 4031: loss = 0.6789 (0.848 sec/step)\n",
            "INFO:tensorflow:global step 4032: loss = 0.7830 (0.788 sec/step)\n",
            "I0503 01:34:04.699085 140519389960064 learning.py:507] global step 4032: loss = 0.7830 (0.788 sec/step)\n",
            "INFO:tensorflow:global step 4033: loss = 0.9333 (0.888 sec/step)\n",
            "I0503 01:34:05.590289 140519389960064 learning.py:507] global step 4033: loss = 0.9333 (0.888 sec/step)\n",
            "INFO:tensorflow:global step 4034: loss = 0.6667 (0.928 sec/step)\n",
            "I0503 01:34:06.520127 140519389960064 learning.py:507] global step 4034: loss = 0.6667 (0.928 sec/step)\n",
            "INFO:tensorflow:global step 4035: loss = 0.5347 (0.797 sec/step)\n",
            "I0503 01:34:07.321729 140519389960064 learning.py:507] global step 4035: loss = 0.5347 (0.797 sec/step)\n",
            "INFO:tensorflow:global step 4036: loss = 0.7793 (0.866 sec/step)\n",
            "I0503 01:34:08.190027 140519389960064 learning.py:507] global step 4036: loss = 0.7793 (0.866 sec/step)\n",
            "INFO:tensorflow:global step 4037: loss = 0.8790 (0.925 sec/step)\n",
            "I0503 01:34:09.118146 140519389960064 learning.py:507] global step 4037: loss = 0.8790 (0.925 sec/step)\n",
            "INFO:tensorflow:global step 4038: loss = 0.7177 (0.867 sec/step)\n",
            "I0503 01:34:09.986476 140519389960064 learning.py:507] global step 4038: loss = 0.7177 (0.867 sec/step)\n",
            "INFO:tensorflow:global step 4039: loss = 0.6656 (0.772 sec/step)\n",
            "I0503 01:34:10.759959 140519389960064 learning.py:507] global step 4039: loss = 0.6656 (0.772 sec/step)\n",
            "INFO:tensorflow:global step 4040: loss = 0.8745 (0.860 sec/step)\n",
            "I0503 01:34:11.621970 140519389960064 learning.py:507] global step 4040: loss = 0.8745 (0.860 sec/step)\n",
            "INFO:tensorflow:global step 4041: loss = 0.8960 (0.739 sec/step)\n",
            "I0503 01:34:12.362792 140519389960064 learning.py:507] global step 4041: loss = 0.8960 (0.739 sec/step)\n",
            "INFO:tensorflow:global step 4042: loss = 0.7824 (0.852 sec/step)\n",
            "I0503 01:34:13.216695 140519389960064 learning.py:507] global step 4042: loss = 0.7824 (0.852 sec/step)\n",
            "INFO:tensorflow:global step 4043: loss = 0.7229 (0.879 sec/step)\n",
            "I0503 01:34:14.097906 140519389960064 learning.py:507] global step 4043: loss = 0.7229 (0.879 sec/step)\n",
            "INFO:tensorflow:global step 4044: loss = 0.6474 (0.836 sec/step)\n",
            "I0503 01:34:14.935304 140519389960064 learning.py:507] global step 4044: loss = 0.6474 (0.836 sec/step)\n",
            "INFO:tensorflow:global step 4045: loss = 0.8610 (0.838 sec/step)\n",
            "I0503 01:34:15.775011 140519389960064 learning.py:507] global step 4045: loss = 0.8610 (0.838 sec/step)\n",
            "INFO:tensorflow:global step 4046: loss = 0.8074 (0.897 sec/step)\n",
            "I0503 01:34:16.674079 140519389960064 learning.py:507] global step 4046: loss = 0.8074 (0.897 sec/step)\n",
            "INFO:tensorflow:global step 4047: loss = 1.0319 (0.782 sec/step)\n",
            "I0503 01:34:17.457409 140519389960064 learning.py:507] global step 4047: loss = 1.0319 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 4048: loss = 0.8340 (0.782 sec/step)\n",
            "I0503 01:34:18.241539 140519389960064 learning.py:507] global step 4048: loss = 0.8340 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 4049: loss = 0.9269 (0.793 sec/step)\n",
            "I0503 01:34:19.036043 140519389960064 learning.py:507] global step 4049: loss = 0.9269 (0.793 sec/step)\n",
            "INFO:tensorflow:global step 4050: loss = 1.0033 (0.900 sec/step)\n",
            "I0503 01:34:19.937963 140519389960064 learning.py:507] global step 4050: loss = 1.0033 (0.900 sec/step)\n",
            "INFO:tensorflow:global step 4051: loss = 0.7125 (0.840 sec/step)\n",
            "I0503 01:34:20.779864 140519389960064 learning.py:507] global step 4051: loss = 0.7125 (0.840 sec/step)\n",
            "INFO:tensorflow:global step 4052: loss = 0.8053 (0.843 sec/step)\n",
            "I0503 01:34:21.624178 140519389960064 learning.py:507] global step 4052: loss = 0.8053 (0.843 sec/step)\n",
            "INFO:tensorflow:global step 4053: loss = 0.7942 (0.838 sec/step)\n",
            "I0503 01:34:22.463813 140519389960064 learning.py:507] global step 4053: loss = 0.7942 (0.838 sec/step)\n",
            "INFO:tensorflow:global step 4054: loss = 0.5758 (0.780 sec/step)\n",
            "I0503 01:34:23.245193 140519389960064 learning.py:507] global step 4054: loss = 0.5758 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 4055: loss = 1.0030 (0.884 sec/step)\n",
            "I0503 01:34:24.130812 140519389960064 learning.py:507] global step 4055: loss = 1.0030 (0.884 sec/step)\n",
            "INFO:tensorflow:global step 4056: loss = 0.7221 (0.820 sec/step)\n",
            "I0503 01:34:24.952430 140519389960064 learning.py:507] global step 4056: loss = 0.7221 (0.820 sec/step)\n",
            "INFO:tensorflow:global step 4057: loss = 0.6256 (0.831 sec/step)\n",
            "I0503 01:34:25.785510 140519389960064 learning.py:507] global step 4057: loss = 0.6256 (0.831 sec/step)\n",
            "INFO:tensorflow:global step 4058: loss = 0.6964 (0.715 sec/step)\n",
            "I0503 01:34:26.502188 140519389960064 learning.py:507] global step 4058: loss = 0.6964 (0.715 sec/step)\n",
            "INFO:tensorflow:global step 4059: loss = 0.9552 (1.099 sec/step)\n",
            "I0503 01:34:27.602817 140519389960064 learning.py:507] global step 4059: loss = 0.9552 (1.099 sec/step)\n",
            "INFO:tensorflow:global step 4060: loss = 0.6625 (0.980 sec/step)\n",
            "I0503 01:34:28.584253 140519389960064 learning.py:507] global step 4060: loss = 0.6625 (0.980 sec/step)\n",
            "INFO:tensorflow:global step 4061: loss = 0.8922 (0.947 sec/step)\n",
            "I0503 01:34:29.532711 140519389960064 learning.py:507] global step 4061: loss = 0.8922 (0.947 sec/step)\n",
            "INFO:tensorflow:global step 4062: loss = 0.6923 (0.803 sec/step)\n",
            "I0503 01:34:30.337706 140519389960064 learning.py:507] global step 4062: loss = 0.6923 (0.803 sec/step)\n",
            "INFO:tensorflow:global step 4063: loss = 0.9065 (0.898 sec/step)\n",
            "I0503 01:34:31.237306 140519389960064 learning.py:507] global step 4063: loss = 0.9065 (0.898 sec/step)\n",
            "INFO:tensorflow:global step 4064: loss = 0.8332 (0.894 sec/step)\n",
            "I0503 01:34:32.133198 140519389960064 learning.py:507] global step 4064: loss = 0.8332 (0.894 sec/step)\n",
            "INFO:tensorflow:global step 4065: loss = 0.8434 (0.804 sec/step)\n",
            "I0503 01:34:32.939081 140519389960064 learning.py:507] global step 4065: loss = 0.8434 (0.804 sec/step)\n",
            "INFO:tensorflow:global step 4066: loss = 0.8054 (0.784 sec/step)\n",
            "I0503 01:34:33.725311 140519389960064 learning.py:507] global step 4066: loss = 0.8054 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 4067: loss = 0.6018 (0.931 sec/step)\n",
            "I0503 01:34:34.658385 140519389960064 learning.py:507] global step 4067: loss = 0.6018 (0.931 sec/step)\n",
            "INFO:tensorflow:global step 4068: loss = 1.1057 (0.868 sec/step)\n",
            "I0503 01:34:35.529149 140519389960064 learning.py:507] global step 4068: loss = 1.1057 (0.868 sec/step)\n",
            "INFO:tensorflow:global step 4069: loss = 0.6500 (0.905 sec/step)\n",
            "I0503 01:34:36.436129 140519389960064 learning.py:507] global step 4069: loss = 0.6500 (0.905 sec/step)\n",
            "INFO:tensorflow:global step 4070: loss = 0.9101 (0.765 sec/step)\n",
            "I0503 01:34:37.202391 140519389960064 learning.py:507] global step 4070: loss = 0.9101 (0.765 sec/step)\n",
            "INFO:tensorflow:global step 4071: loss = 0.9673 (0.838 sec/step)\n",
            "I0503 01:34:38.042345 140519389960064 learning.py:507] global step 4071: loss = 0.9673 (0.838 sec/step)\n",
            "INFO:tensorflow:global step 4072: loss = 0.9511 (0.796 sec/step)\n",
            "I0503 01:34:38.840430 140519389960064 learning.py:507] global step 4072: loss = 0.9511 (0.796 sec/step)\n",
            "INFO:tensorflow:global step 4073: loss = 0.7512 (0.894 sec/step)\n",
            "I0503 01:34:39.736809 140519389960064 learning.py:507] global step 4073: loss = 0.7512 (0.894 sec/step)\n",
            "INFO:tensorflow:global step 4074: loss = 0.7589 (0.902 sec/step)\n",
            "I0503 01:34:40.643244 140519389960064 learning.py:507] global step 4074: loss = 0.7589 (0.902 sec/step)\n",
            "INFO:tensorflow:global step 4075: loss = 0.8463 (0.934 sec/step)\n",
            "I0503 01:34:41.579254 140519389960064 learning.py:507] global step 4075: loss = 0.8463 (0.934 sec/step)\n",
            "INFO:tensorflow:global step 4076: loss = 0.7117 (0.758 sec/step)\n",
            "I0503 01:34:42.338958 140519389960064 learning.py:507] global step 4076: loss = 0.7117 (0.758 sec/step)\n",
            "INFO:tensorflow:global step 4077: loss = 0.9561 (0.815 sec/step)\n",
            "I0503 01:34:43.155992 140519389960064 learning.py:507] global step 4077: loss = 0.9561 (0.815 sec/step)\n",
            "INFO:tensorflow:global step 4078: loss = 0.7237 (0.855 sec/step)\n",
            "I0503 01:34:44.012466 140519389960064 learning.py:507] global step 4078: loss = 0.7237 (0.855 sec/step)\n",
            "INFO:tensorflow:global step 4079: loss = 0.7016 (0.821 sec/step)\n",
            "I0503 01:34:44.835362 140519389960064 learning.py:507] global step 4079: loss = 0.7016 (0.821 sec/step)\n",
            "INFO:tensorflow:global step 4080: loss = 0.8488 (0.719 sec/step)\n",
            "I0503 01:34:45.589816 140519389960064 learning.py:507] global step 4080: loss = 0.8488 (0.719 sec/step)\n",
            "INFO:tensorflow:global step 4081: loss = 0.7627 (0.813 sec/step)\n",
            "I0503 01:34:46.405750 140519389960064 learning.py:507] global step 4081: loss = 0.7627 (0.813 sec/step)\n",
            "INFO:tensorflow:global step 4082: loss = 0.8093 (0.780 sec/step)\n",
            "I0503 01:34:47.187362 140519389960064 learning.py:507] global step 4082: loss = 0.8093 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 4083: loss = 0.7605 (0.913 sec/step)\n",
            "I0503 01:34:48.102243 140519389960064 learning.py:507] global step 4083: loss = 0.7605 (0.913 sec/step)\n",
            "INFO:tensorflow:global step 4084: loss = 0.7124 (0.784 sec/step)\n",
            "I0503 01:34:48.887465 140519389960064 learning.py:507] global step 4084: loss = 0.7124 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 4085: loss = 0.6987 (0.822 sec/step)\n",
            "I0503 01:34:49.710546 140519389960064 learning.py:507] global step 4085: loss = 0.6987 (0.822 sec/step)\n",
            "INFO:tensorflow:global step 4086: loss = 0.7873 (0.846 sec/step)\n",
            "I0503 01:34:50.558063 140519389960064 learning.py:507] global step 4086: loss = 0.7873 (0.846 sec/step)\n",
            "INFO:tensorflow:global step 4087: loss = 0.8312 (0.702 sec/step)\n",
            "I0503 01:34:51.261615 140519389960064 learning.py:507] global step 4087: loss = 0.8312 (0.702 sec/step)\n",
            "INFO:tensorflow:global step 4088: loss = 0.8623 (0.809 sec/step)\n",
            "I0503 01:34:52.073379 140519389960064 learning.py:507] global step 4088: loss = 0.8623 (0.809 sec/step)\n",
            "INFO:tensorflow:global step 4089: loss = 0.7206 (0.786 sec/step)\n",
            "I0503 01:34:52.860704 140519389960064 learning.py:507] global step 4089: loss = 0.7206 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 4090: loss = 0.8359 (0.806 sec/step)\n",
            "I0503 01:34:53.668410 140519389960064 learning.py:507] global step 4090: loss = 0.8359 (0.806 sec/step)\n",
            "INFO:tensorflow:global step 4091: loss = 0.7850 (0.784 sec/step)\n",
            "I0503 01:34:54.459351 140519389960064 learning.py:507] global step 4091: loss = 0.7850 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 4092: loss = 0.7601 (0.918 sec/step)\n",
            "I0503 01:34:55.378971 140519389960064 learning.py:507] global step 4092: loss = 0.7601 (0.918 sec/step)\n",
            "INFO:tensorflow:global step 4093: loss = 0.7767 (0.798 sec/step)\n",
            "I0503 01:34:56.179544 140519389960064 learning.py:507] global step 4093: loss = 0.7767 (0.798 sec/step)\n",
            "INFO:tensorflow:global step 4094: loss = 0.7327 (0.767 sec/step)\n",
            "I0503 01:34:56.948128 140519389960064 learning.py:507] global step 4094: loss = 0.7327 (0.767 sec/step)\n",
            "INFO:tensorflow:global step 4095: loss = 0.6986 (0.716 sec/step)\n",
            "I0503 01:34:57.721410 140519389960064 learning.py:507] global step 4095: loss = 0.6986 (0.716 sec/step)\n",
            "INFO:tensorflow:global step 4096: loss = 0.8588 (0.784 sec/step)\n",
            "I0503 01:34:58.550872 140519389960064 learning.py:507] global step 4096: loss = 0.8588 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 4097: loss = 0.7888 (1.527 sec/step)\n",
            "I0503 01:35:00.081516 140519389960064 learning.py:507] global step 4097: loss = 0.7888 (1.527 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 4097.\n",
            "I0503 01:35:00.095434 140515676296960 supervisor.py:1050] Recording summary at step 4097.\n",
            "INFO:tensorflow:global step 4098: loss = 0.7940 (0.852 sec/step)\n",
            "I0503 01:35:00.935942 140519389960064 learning.py:507] global step 4098: loss = 0.7940 (0.852 sec/step)\n",
            "INFO:tensorflow:global step 4099: loss = 0.8065 (0.794 sec/step)\n",
            "I0503 01:35:01.731460 140519389960064 learning.py:507] global step 4099: loss = 0.8065 (0.794 sec/step)\n",
            "INFO:tensorflow:global step 4100: loss = 0.7620 (0.893 sec/step)\n",
            "I0503 01:35:02.625843 140519389960064 learning.py:507] global step 4100: loss = 0.7620 (0.893 sec/step)\n",
            "INFO:tensorflow:global_step/sec: 1.18486\n",
            "I0503 01:35:02.851139 140515684689664 supervisor.py:1099] global_step/sec: 1.18486\n",
            "INFO:tensorflow:global step 4101: loss = 0.6150 (0.856 sec/step)\n",
            "I0503 01:35:03.482896 140519389960064 learning.py:507] global step 4101: loss = 0.6150 (0.856 sec/step)\n",
            "INFO:tensorflow:global step 4102: loss = 0.7399 (0.896 sec/step)\n",
            "I0503 01:35:04.381325 140519389960064 learning.py:507] global step 4102: loss = 0.7399 (0.896 sec/step)\n",
            "INFO:tensorflow:global step 4103: loss = 0.7804 (0.808 sec/step)\n",
            "I0503 01:35:05.191025 140519389960064 learning.py:507] global step 4103: loss = 0.7804 (0.808 sec/step)\n",
            "INFO:tensorflow:global step 4104: loss = 0.6986 (0.887 sec/step)\n",
            "I0503 01:35:06.080092 140519389960064 learning.py:507] global step 4104: loss = 0.6986 (0.887 sec/step)\n",
            "INFO:tensorflow:global step 4105: loss = 0.7835 (0.844 sec/step)\n",
            "I0503 01:35:06.926285 140519389960064 learning.py:507] global step 4105: loss = 0.7835 (0.844 sec/step)\n",
            "INFO:tensorflow:global step 4106: loss = 0.5683 (0.821 sec/step)\n",
            "I0503 01:35:07.749228 140519389960064 learning.py:507] global step 4106: loss = 0.5683 (0.821 sec/step)\n",
            "INFO:tensorflow:global step 4107: loss = 0.8200 (0.811 sec/step)\n",
            "I0503 01:35:08.561607 140519389960064 learning.py:507] global step 4107: loss = 0.8200 (0.811 sec/step)\n",
            "INFO:tensorflow:global step 4108: loss = 0.6657 (0.952 sec/step)\n",
            "I0503 01:35:09.515546 140519389960064 learning.py:507] global step 4108: loss = 0.6657 (0.952 sec/step)\n",
            "INFO:tensorflow:global step 4109: loss = 0.7762 (0.839 sec/step)\n",
            "I0503 01:35:10.356554 140519389960064 learning.py:507] global step 4109: loss = 0.7762 (0.839 sec/step)\n",
            "INFO:tensorflow:global step 4110: loss = 0.9552 (0.767 sec/step)\n",
            "I0503 01:35:11.125430 140519389960064 learning.py:507] global step 4110: loss = 0.9552 (0.767 sec/step)\n",
            "INFO:tensorflow:global step 4111: loss = 0.7575 (0.847 sec/step)\n",
            "I0503 01:35:11.973752 140519389960064 learning.py:507] global step 4111: loss = 0.7575 (0.847 sec/step)\n",
            "INFO:tensorflow:global step 4112: loss = 0.6235 (0.900 sec/step)\n",
            "I0503 01:35:12.875803 140519389960064 learning.py:507] global step 4112: loss = 0.6235 (0.900 sec/step)\n",
            "INFO:tensorflow:global step 4113: loss = 0.9367 (0.900 sec/step)\n",
            "I0503 01:35:13.777077 140519389960064 learning.py:507] global step 4113: loss = 0.9367 (0.900 sec/step)\n",
            "INFO:tensorflow:global step 4114: loss = 0.6423 (0.916 sec/step)\n",
            "I0503 01:35:14.694919 140519389960064 learning.py:507] global step 4114: loss = 0.6423 (0.916 sec/step)\n",
            "INFO:tensorflow:global step 4115: loss = 0.7944 (0.743 sec/step)\n",
            "I0503 01:35:15.439817 140519389960064 learning.py:507] global step 4115: loss = 0.7944 (0.743 sec/step)\n",
            "INFO:tensorflow:global step 4116: loss = 0.7576 (0.857 sec/step)\n",
            "I0503 01:35:16.298301 140519389960064 learning.py:507] global step 4116: loss = 0.7576 (0.857 sec/step)\n",
            "INFO:tensorflow:global step 4117: loss = 0.7906 (0.766 sec/step)\n",
            "I0503 01:35:17.065521 140519389960064 learning.py:507] global step 4117: loss = 0.7906 (0.766 sec/step)\n",
            "INFO:tensorflow:global step 4118: loss = 0.9351 (0.859 sec/step)\n",
            "I0503 01:35:17.925830 140519389960064 learning.py:507] global step 4118: loss = 0.9351 (0.859 sec/step)\n",
            "INFO:tensorflow:global step 4119: loss = 1.1597 (0.625 sec/step)\n",
            "I0503 01:35:18.560189 140519389960064 learning.py:507] global step 4119: loss = 1.1597 (0.625 sec/step)\n",
            "INFO:tensorflow:global step 4120: loss = 0.8072 (0.947 sec/step)\n",
            "I0503 01:35:19.509050 140519389960064 learning.py:507] global step 4120: loss = 0.8072 (0.947 sec/step)\n",
            "INFO:tensorflow:global step 4121: loss = 0.7092 (0.929 sec/step)\n",
            "I0503 01:35:20.440355 140519389960064 learning.py:507] global step 4121: loss = 0.7092 (0.929 sec/step)\n",
            "INFO:tensorflow:global step 4122: loss = 0.6376 (0.917 sec/step)\n",
            "I0503 01:35:21.358697 140519389960064 learning.py:507] global step 4122: loss = 0.6376 (0.917 sec/step)\n",
            "INFO:tensorflow:global step 4123: loss = 0.7535 (0.706 sec/step)\n",
            "I0503 01:35:22.067354 140519389960064 learning.py:507] global step 4123: loss = 0.7535 (0.706 sec/step)\n",
            "INFO:tensorflow:global step 4124: loss = 0.7767 (1.116 sec/step)\n",
            "I0503 01:35:23.184910 140519389960064 learning.py:507] global step 4124: loss = 0.7767 (1.116 sec/step)\n",
            "INFO:tensorflow:global step 4125: loss = 0.7904 (0.851 sec/step)\n",
            "I0503 01:35:24.038069 140519389960064 learning.py:507] global step 4125: loss = 0.7904 (0.851 sec/step)\n",
            "INFO:tensorflow:global step 4126: loss = 0.8219 (0.816 sec/step)\n",
            "I0503 01:35:24.968473 140519389960064 learning.py:507] global step 4126: loss = 0.8219 (0.816 sec/step)\n",
            "INFO:tensorflow:global step 4127: loss = 0.8115 (0.883 sec/step)\n",
            "I0503 01:35:25.957825 140519389960064 learning.py:507] global step 4127: loss = 0.8115 (0.883 sec/step)\n",
            "INFO:tensorflow:global step 4128: loss = 0.8145 (0.800 sec/step)\n",
            "I0503 01:35:26.760069 140519389960064 learning.py:507] global step 4128: loss = 0.8145 (0.800 sec/step)\n",
            "INFO:tensorflow:global step 4129: loss = 0.5147 (0.924 sec/step)\n",
            "I0503 01:35:27.686159 140519389960064 learning.py:507] global step 4129: loss = 0.5147 (0.924 sec/step)\n",
            "INFO:tensorflow:global step 4130: loss = 0.6738 (0.856 sec/step)\n",
            "I0503 01:35:28.544187 140519389960064 learning.py:507] global step 4130: loss = 0.6738 (0.856 sec/step)\n",
            "INFO:tensorflow:global step 4131: loss = 0.8738 (0.663 sec/step)\n",
            "I0503 01:35:29.369784 140519389960064 learning.py:507] global step 4131: loss = 0.8738 (0.663 sec/step)\n",
            "INFO:tensorflow:global step 4132: loss = 1.0531 (0.999 sec/step)\n",
            "I0503 01:35:30.370953 140519389960064 learning.py:507] global step 4132: loss = 1.0531 (0.999 sec/step)\n",
            "INFO:tensorflow:global step 4133: loss = 0.8129 (0.710 sec/step)\n",
            "I0503 01:35:31.082842 140519389960064 learning.py:507] global step 4133: loss = 0.8129 (0.710 sec/step)\n",
            "INFO:tensorflow:global step 4134: loss = 0.8246 (0.803 sec/step)\n",
            "I0503 01:35:31.887061 140519389960064 learning.py:507] global step 4134: loss = 0.8246 (0.803 sec/step)\n",
            "INFO:tensorflow:global step 4135: loss = 0.9239 (0.918 sec/step)\n",
            "I0503 01:35:32.806358 140519389960064 learning.py:507] global step 4135: loss = 0.9239 (0.918 sec/step)\n",
            "INFO:tensorflow:global step 4136: loss = 0.6971 (0.711 sec/step)\n",
            "I0503 01:35:33.519214 140519389960064 learning.py:507] global step 4136: loss = 0.6971 (0.711 sec/step)\n",
            "INFO:tensorflow:global step 4137: loss = 0.7889 (0.793 sec/step)\n",
            "I0503 01:35:34.313894 140519389960064 learning.py:507] global step 4137: loss = 0.7889 (0.793 sec/step)\n",
            "INFO:tensorflow:global step 4138: loss = 0.9815 (0.903 sec/step)\n",
            "I0503 01:35:35.218845 140519389960064 learning.py:507] global step 4138: loss = 0.9815 (0.903 sec/step)\n",
            "INFO:tensorflow:global step 4139: loss = 0.6618 (0.786 sec/step)\n",
            "I0503 01:35:36.006249 140519389960064 learning.py:507] global step 4139: loss = 0.6618 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 4140: loss = 0.9105 (0.806 sec/step)\n",
            "I0503 01:35:36.813623 140519389960064 learning.py:507] global step 4140: loss = 0.9105 (0.806 sec/step)\n",
            "INFO:tensorflow:global step 4141: loss = 0.7126 (0.900 sec/step)\n",
            "I0503 01:35:37.715196 140519389960064 learning.py:507] global step 4141: loss = 0.7126 (0.900 sec/step)\n",
            "INFO:tensorflow:global step 4142: loss = 0.5479 (0.824 sec/step)\n",
            "I0503 01:35:38.540626 140519389960064 learning.py:507] global step 4142: loss = 0.5479 (0.824 sec/step)\n",
            "INFO:tensorflow:global step 4143: loss = 0.6422 (0.844 sec/step)\n",
            "I0503 01:35:39.386284 140519389960064 learning.py:507] global step 4143: loss = 0.6422 (0.844 sec/step)\n",
            "INFO:tensorflow:global step 4144: loss = 0.8506 (0.920 sec/step)\n",
            "I0503 01:35:40.309568 140519389960064 learning.py:507] global step 4144: loss = 0.8506 (0.920 sec/step)\n",
            "INFO:tensorflow:global step 4145: loss = 0.8627 (0.873 sec/step)\n",
            "I0503 01:35:41.184618 140519389960064 learning.py:507] global step 4145: loss = 0.8627 (0.873 sec/step)\n",
            "INFO:tensorflow:global step 4146: loss = 0.7933 (0.837 sec/step)\n",
            "I0503 01:35:42.023654 140519389960064 learning.py:507] global step 4146: loss = 0.7933 (0.837 sec/step)\n",
            "INFO:tensorflow:global step 4147: loss = 0.5814 (0.927 sec/step)\n",
            "I0503 01:35:42.952310 140519389960064 learning.py:507] global step 4147: loss = 0.5814 (0.927 sec/step)\n",
            "INFO:tensorflow:global step 4148: loss = 0.7675 (0.617 sec/step)\n",
            "I0503 01:35:43.612510 140519389960064 learning.py:507] global step 4148: loss = 0.7675 (0.617 sec/step)\n",
            "INFO:tensorflow:global step 4149: loss = 0.7914 (0.914 sec/step)\n",
            "I0503 01:35:44.556641 140519389960064 learning.py:507] global step 4149: loss = 0.7914 (0.914 sec/step)\n",
            "INFO:tensorflow:global step 4150: loss = 0.7274 (0.930 sec/step)\n",
            "I0503 01:35:45.487943 140519389960064 learning.py:507] global step 4150: loss = 0.7274 (0.930 sec/step)\n",
            "INFO:tensorflow:global step 4151: loss = 0.7977 (0.802 sec/step)\n",
            "I0503 01:35:46.291806 140519389960064 learning.py:507] global step 4151: loss = 0.7977 (0.802 sec/step)\n",
            "INFO:tensorflow:global step 4152: loss = 0.9102 (0.869 sec/step)\n",
            "I0503 01:35:47.162060 140519389960064 learning.py:507] global step 4152: loss = 0.9102 (0.869 sec/step)\n",
            "INFO:tensorflow:global step 4153: loss = 0.8126 (0.754 sec/step)\n",
            "I0503 01:35:47.917242 140519389960064 learning.py:507] global step 4153: loss = 0.8126 (0.754 sec/step)\n",
            "INFO:tensorflow:global step 4154: loss = 0.7142 (0.823 sec/step)\n",
            "I0503 01:35:48.742831 140519389960064 learning.py:507] global step 4154: loss = 0.7142 (0.823 sec/step)\n",
            "INFO:tensorflow:global step 4155: loss = 0.6942 (0.827 sec/step)\n",
            "I0503 01:35:49.571649 140519389960064 learning.py:507] global step 4155: loss = 0.6942 (0.827 sec/step)\n",
            "INFO:tensorflow:global step 4156: loss = 1.1015 (0.776 sec/step)\n",
            "I0503 01:35:50.350035 140519389960064 learning.py:507] global step 4156: loss = 1.1015 (0.776 sec/step)\n",
            "INFO:tensorflow:global step 4157: loss = 1.2110 (1.064 sec/step)\n",
            "I0503 01:35:51.415969 140519389960064 learning.py:507] global step 4157: loss = 1.2110 (1.064 sec/step)\n",
            "INFO:tensorflow:global step 4158: loss = 0.9459 (0.891 sec/step)\n",
            "I0503 01:35:52.308806 140519389960064 learning.py:507] global step 4158: loss = 0.9459 (0.891 sec/step)\n",
            "INFO:tensorflow:global step 4159: loss = 0.9097 (0.754 sec/step)\n",
            "I0503 01:35:53.064212 140519389960064 learning.py:507] global step 4159: loss = 0.9097 (0.754 sec/step)\n",
            "INFO:tensorflow:global step 4160: loss = 0.7668 (0.911 sec/step)\n",
            "I0503 01:35:53.976645 140519389960064 learning.py:507] global step 4160: loss = 0.7668 (0.911 sec/step)\n",
            "INFO:tensorflow:global step 4161: loss = 0.5319 (0.756 sec/step)\n",
            "I0503 01:35:54.734565 140519389960064 learning.py:507] global step 4161: loss = 0.5319 (0.756 sec/step)\n",
            "INFO:tensorflow:global step 4162: loss = 0.8480 (0.892 sec/step)\n",
            "I0503 01:35:55.628203 140519389960064 learning.py:507] global step 4162: loss = 0.8480 (0.892 sec/step)\n",
            "INFO:tensorflow:global step 4163: loss = 0.7450 (0.776 sec/step)\n",
            "I0503 01:35:56.405733 140519389960064 learning.py:507] global step 4163: loss = 0.7450 (0.776 sec/step)\n",
            "INFO:tensorflow:global step 4164: loss = 0.8438 (0.698 sec/step)\n",
            "I0503 01:35:57.105251 140519389960064 learning.py:507] global step 4164: loss = 0.8438 (0.698 sec/step)\n",
            "INFO:tensorflow:global step 4165: loss = 0.7079 (0.841 sec/step)\n",
            "I0503 01:35:57.949018 140519389960064 learning.py:507] global step 4165: loss = 0.7079 (0.841 sec/step)\n",
            "INFO:tensorflow:global step 4166: loss = 0.7501 (0.678 sec/step)\n",
            "I0503 01:35:58.630863 140519389960064 learning.py:507] global step 4166: loss = 0.7501 (0.678 sec/step)\n",
            "INFO:tensorflow:global step 4167: loss = 0.6942 (0.724 sec/step)\n",
            "I0503 01:35:59.357192 140519389960064 learning.py:507] global step 4167: loss = 0.6942 (0.724 sec/step)\n",
            "INFO:tensorflow:global step 4168: loss = 0.7972 (0.842 sec/step)\n",
            "I0503 01:36:00.201968 140519389960064 learning.py:507] global step 4168: loss = 0.7972 (0.842 sec/step)\n",
            "INFO:tensorflow:global step 4169: loss = 0.7312 (0.793 sec/step)\n",
            "I0503 01:36:00.996184 140519389960064 learning.py:507] global step 4169: loss = 0.7312 (0.793 sec/step)\n",
            "INFO:tensorflow:global step 4170: loss = 0.8128 (0.913 sec/step)\n",
            "I0503 01:36:01.910600 140519389960064 learning.py:507] global step 4170: loss = 0.8128 (0.913 sec/step)\n",
            "INFO:tensorflow:global step 4171: loss = 0.8535 (0.837 sec/step)\n",
            "I0503 01:36:02.749554 140519389960064 learning.py:507] global step 4171: loss = 0.8535 (0.837 sec/step)\n",
            "INFO:tensorflow:global step 4172: loss = 0.9357 (0.861 sec/step)\n",
            "I0503 01:36:03.612623 140519389960064 learning.py:507] global step 4172: loss = 0.9357 (0.861 sec/step)\n",
            "INFO:tensorflow:global step 4173: loss = 0.8454 (0.746 sec/step)\n",
            "I0503 01:36:04.360160 140519389960064 learning.py:507] global step 4173: loss = 0.8454 (0.746 sec/step)\n",
            "INFO:tensorflow:global step 4174: loss = 0.8921 (0.840 sec/step)\n",
            "I0503 01:36:05.201665 140519389960064 learning.py:507] global step 4174: loss = 0.8921 (0.840 sec/step)\n",
            "INFO:tensorflow:global step 4175: loss = 0.8029 (0.790 sec/step)\n",
            "I0503 01:36:05.993607 140519389960064 learning.py:507] global step 4175: loss = 0.8029 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 4176: loss = 0.6189 (0.866 sec/step)\n",
            "I0503 01:36:06.860932 140519389960064 learning.py:507] global step 4176: loss = 0.6189 (0.866 sec/step)\n",
            "INFO:tensorflow:global step 4177: loss = 0.7283 (0.814 sec/step)\n",
            "I0503 01:36:07.677453 140519389960064 learning.py:507] global step 4177: loss = 0.7283 (0.814 sec/step)\n",
            "INFO:tensorflow:global step 4178: loss = 0.8023 (0.879 sec/step)\n",
            "I0503 01:36:08.557716 140519389960064 learning.py:507] global step 4178: loss = 0.8023 (0.879 sec/step)\n",
            "INFO:tensorflow:global step 4179: loss = 0.8051 (0.735 sec/step)\n",
            "I0503 01:36:09.294094 140519389960064 learning.py:507] global step 4179: loss = 0.8051 (0.735 sec/step)\n",
            "INFO:tensorflow:global step 4180: loss = 0.8056 (0.821 sec/step)\n",
            "I0503 01:36:10.117371 140519389960064 learning.py:507] global step 4180: loss = 0.8056 (0.821 sec/step)\n",
            "INFO:tensorflow:global step 4181: loss = 0.9050 (0.821 sec/step)\n",
            "I0503 01:36:10.940215 140519389960064 learning.py:507] global step 4181: loss = 0.9050 (0.821 sec/step)\n",
            "INFO:tensorflow:global step 4182: loss = 0.7794 (0.826 sec/step)\n",
            "I0503 01:36:11.767467 140519389960064 learning.py:507] global step 4182: loss = 0.7794 (0.826 sec/step)\n",
            "INFO:tensorflow:global step 4183: loss = 1.0456 (0.784 sec/step)\n",
            "I0503 01:36:12.553106 140519389960064 learning.py:507] global step 4183: loss = 1.0456 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 4184: loss = 0.6278 (0.914 sec/step)\n",
            "I0503 01:36:13.468932 140519389960064 learning.py:507] global step 4184: loss = 0.6278 (0.914 sec/step)\n",
            "INFO:tensorflow:global step 4185: loss = 0.9068 (0.850 sec/step)\n",
            "I0503 01:36:14.320642 140519389960064 learning.py:507] global step 4185: loss = 0.9068 (0.850 sec/step)\n",
            "INFO:tensorflow:global step 4186: loss = 0.9102 (0.826 sec/step)\n",
            "I0503 01:36:15.147957 140519389960064 learning.py:507] global step 4186: loss = 0.9102 (0.826 sec/step)\n",
            "INFO:tensorflow:global step 4187: loss = 0.7079 (0.937 sec/step)\n",
            "I0503 01:36:16.086683 140519389960064 learning.py:507] global step 4187: loss = 0.7079 (0.937 sec/step)\n",
            "INFO:tensorflow:global step 4188: loss = 0.6341 (0.856 sec/step)\n",
            "I0503 01:36:16.944215 140519389960064 learning.py:507] global step 4188: loss = 0.6341 (0.856 sec/step)\n",
            "INFO:tensorflow:global step 4189: loss = 0.8186 (0.742 sec/step)\n",
            "I0503 01:36:17.688226 140519389960064 learning.py:507] global step 4189: loss = 0.8186 (0.742 sec/step)\n",
            "INFO:tensorflow:global step 4190: loss = 0.7032 (0.849 sec/step)\n",
            "I0503 01:36:18.538930 140519389960064 learning.py:507] global step 4190: loss = 0.7032 (0.849 sec/step)\n",
            "INFO:tensorflow:global step 4191: loss = 0.6410 (0.802 sec/step)\n",
            "I0503 01:36:19.342927 140519389960064 learning.py:507] global step 4191: loss = 0.6410 (0.802 sec/step)\n",
            "INFO:tensorflow:global step 4192: loss = 0.9898 (0.790 sec/step)\n",
            "I0503 01:36:20.134694 140519389960064 learning.py:507] global step 4192: loss = 0.9898 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 4193: loss = 0.8938 (0.762 sec/step)\n",
            "I0503 01:36:20.899250 140519389960064 learning.py:507] global step 4193: loss = 0.8938 (0.762 sec/step)\n",
            "INFO:tensorflow:global step 4194: loss = 0.7930 (0.748 sec/step)\n",
            "I0503 01:36:21.706533 140519389960064 learning.py:507] global step 4194: loss = 0.7930 (0.748 sec/step)\n",
            "INFO:tensorflow:global step 4195: loss = 0.9453 (0.726 sec/step)\n",
            "I0503 01:36:22.511510 140519389960064 learning.py:507] global step 4195: loss = 0.9453 (0.726 sec/step)\n",
            "INFO:tensorflow:global step 4196: loss = 0.8371 (0.705 sec/step)\n",
            "I0503 01:36:23.229203 140519389960064 learning.py:507] global step 4196: loss = 0.8371 (0.705 sec/step)\n",
            "INFO:tensorflow:global step 4197: loss = 0.6418 (0.875 sec/step)\n",
            "I0503 01:36:24.105825 140519389960064 learning.py:507] global step 4197: loss = 0.6418 (0.875 sec/step)\n",
            "INFO:tensorflow:global step 4198: loss = 0.9322 (0.775 sec/step)\n",
            "I0503 01:36:24.882649 140519389960064 learning.py:507] global step 4198: loss = 0.9322 (0.775 sec/step)\n",
            "INFO:tensorflow:global step 4199: loss = 0.9993 (0.700 sec/step)\n",
            "I0503 01:36:25.633679 140519389960064 learning.py:507] global step 4199: loss = 0.9993 (0.700 sec/step)\n",
            "INFO:tensorflow:global step 4200: loss = 0.5717 (1.029 sec/step)\n",
            "I0503 01:36:26.668680 140519389960064 learning.py:507] global step 4200: loss = 0.5717 (1.029 sec/step)\n",
            "INFO:tensorflow:global step 4201: loss = 0.6122 (0.803 sec/step)\n",
            "I0503 01:36:27.472754 140519389960064 learning.py:507] global step 4201: loss = 0.6122 (0.803 sec/step)\n",
            "INFO:tensorflow:global step 4202: loss = 0.7612 (0.790 sec/step)\n",
            "I0503 01:36:28.263718 140519389960064 learning.py:507] global step 4202: loss = 0.7612 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 4203: loss = 0.7358 (0.710 sec/step)\n",
            "I0503 01:36:29.022617 140519389960064 learning.py:507] global step 4203: loss = 0.7358 (0.710 sec/step)\n",
            "INFO:tensorflow:global step 4204: loss = 0.8346 (0.865 sec/step)\n",
            "I0503 01:36:29.888838 140519389960064 learning.py:507] global step 4204: loss = 0.8346 (0.865 sec/step)\n",
            "INFO:tensorflow:global step 4205: loss = 0.9626 (0.902 sec/step)\n",
            "I0503 01:36:30.792670 140519389960064 learning.py:507] global step 4205: loss = 0.9626 (0.902 sec/step)\n",
            "INFO:tensorflow:global step 4206: loss = 0.9010 (0.956 sec/step)\n",
            "I0503 01:36:31.750369 140519389960064 learning.py:507] global step 4206: loss = 0.9010 (0.956 sec/step)\n",
            "INFO:tensorflow:global step 4207: loss = 0.6192 (0.828 sec/step)\n",
            "I0503 01:36:32.579683 140519389960064 learning.py:507] global step 4207: loss = 0.6192 (0.828 sec/step)\n",
            "INFO:tensorflow:global step 4208: loss = 0.9501 (0.786 sec/step)\n",
            "I0503 01:36:33.366832 140519389960064 learning.py:507] global step 4208: loss = 0.9501 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 4209: loss = 0.7256 (0.773 sec/step)\n",
            "I0503 01:36:34.141236 140519389960064 learning.py:507] global step 4209: loss = 0.7256 (0.773 sec/step)\n",
            "INFO:tensorflow:global step 4210: loss = 0.6931 (0.820 sec/step)\n",
            "I0503 01:36:34.963270 140519389960064 learning.py:507] global step 4210: loss = 0.6931 (0.820 sec/step)\n",
            "INFO:tensorflow:global step 4211: loss = 0.6811 (0.797 sec/step)\n",
            "I0503 01:36:35.763151 140519389960064 learning.py:507] global step 4211: loss = 0.6811 (0.797 sec/step)\n",
            "INFO:tensorflow:global step 4212: loss = 0.6520 (0.864 sec/step)\n",
            "I0503 01:36:36.628506 140519389960064 learning.py:507] global step 4212: loss = 0.6520 (0.864 sec/step)\n",
            "INFO:tensorflow:global step 4213: loss = 0.8442 (0.672 sec/step)\n",
            "I0503 01:36:37.301716 140519389960064 learning.py:507] global step 4213: loss = 0.8442 (0.672 sec/step)\n",
            "INFO:tensorflow:global step 4214: loss = 0.6565 (0.751 sec/step)\n",
            "I0503 01:36:38.113729 140519389960064 learning.py:507] global step 4214: loss = 0.6565 (0.751 sec/step)\n",
            "INFO:tensorflow:global step 4215: loss = 0.7708 (0.724 sec/step)\n",
            "I0503 01:36:38.839485 140519389960064 learning.py:507] global step 4215: loss = 0.7708 (0.724 sec/step)\n",
            "INFO:tensorflow:global step 4216: loss = 0.7794 (0.894 sec/step)\n",
            "I0503 01:36:39.735463 140519389960064 learning.py:507] global step 4216: loss = 0.7794 (0.894 sec/step)\n",
            "INFO:tensorflow:global step 4217: loss = 0.6274 (0.914 sec/step)\n",
            "I0503 01:36:40.651034 140519389960064 learning.py:507] global step 4217: loss = 0.6274 (0.914 sec/step)\n",
            "INFO:tensorflow:global step 4218: loss = 0.6349 (0.882 sec/step)\n",
            "I0503 01:36:41.535048 140519389960064 learning.py:507] global step 4218: loss = 0.6349 (0.882 sec/step)\n",
            "INFO:tensorflow:global step 4219: loss = 0.8573 (0.908 sec/step)\n",
            "I0503 01:36:42.445000 140519389960064 learning.py:507] global step 4219: loss = 0.8573 (0.908 sec/step)\n",
            "INFO:tensorflow:global step 4220: loss = 0.8145 (0.921 sec/step)\n",
            "I0503 01:36:43.368048 140519389960064 learning.py:507] global step 4220: loss = 0.8145 (0.921 sec/step)\n",
            "INFO:tensorflow:global step 4221: loss = 0.8066 (0.825 sec/step)\n",
            "I0503 01:36:44.194928 140519389960064 learning.py:507] global step 4221: loss = 0.8066 (0.825 sec/step)\n",
            "INFO:tensorflow:global step 4222: loss = 0.6952 (0.845 sec/step)\n",
            "I0503 01:36:45.041738 140519389960064 learning.py:507] global step 4222: loss = 0.6952 (0.845 sec/step)\n",
            "INFO:tensorflow:global step 4223: loss = 0.6048 (0.855 sec/step)\n",
            "I0503 01:36:45.898864 140519389960064 learning.py:507] global step 4223: loss = 0.6048 (0.855 sec/step)\n",
            "INFO:tensorflow:global step 4224: loss = 0.8525 (0.890 sec/step)\n",
            "I0503 01:36:46.790300 140519389960064 learning.py:507] global step 4224: loss = 0.8525 (0.890 sec/step)\n",
            "INFO:tensorflow:global step 4225: loss = 0.6846 (0.736 sec/step)\n",
            "I0503 01:36:47.546296 140519389960064 learning.py:507] global step 4225: loss = 0.6846 (0.736 sec/step)\n",
            "INFO:tensorflow:global step 4226: loss = 0.6795 (1.263 sec/step)\n",
            "I0503 01:36:48.812038 140519389960064 learning.py:507] global step 4226: loss = 0.6795 (1.263 sec/step)\n",
            "INFO:tensorflow:global step 4227: loss = 0.9085 (0.764 sec/step)\n",
            "I0503 01:36:49.577957 140519389960064 learning.py:507] global step 4227: loss = 0.9085 (0.764 sec/step)\n",
            "INFO:tensorflow:global step 4228: loss = 0.5429 (0.912 sec/step)\n",
            "I0503 01:36:50.492132 140519389960064 learning.py:507] global step 4228: loss = 0.5429 (0.912 sec/step)\n",
            "INFO:tensorflow:global step 4229: loss = 0.8768 (0.824 sec/step)\n",
            "I0503 01:36:51.401515 140519389960064 learning.py:507] global step 4229: loss = 0.8768 (0.824 sec/step)\n",
            "INFO:tensorflow:global step 4230: loss = 0.7502 (0.756 sec/step)\n",
            "I0503 01:36:52.172713 140519389960064 learning.py:507] global step 4230: loss = 0.7502 (0.756 sec/step)\n",
            "INFO:tensorflow:global step 4231: loss = 0.8157 (0.934 sec/step)\n",
            "I0503 01:36:53.108167 140519389960064 learning.py:507] global step 4231: loss = 0.8157 (0.934 sec/step)\n",
            "INFO:tensorflow:global step 4232: loss = 0.7891 (0.899 sec/step)\n",
            "I0503 01:36:54.008505 140519389960064 learning.py:507] global step 4232: loss = 0.7891 (0.899 sec/step)\n",
            "INFO:tensorflow:global step 4233: loss = 0.8942 (0.786 sec/step)\n",
            "I0503 01:36:54.796078 140519389960064 learning.py:507] global step 4233: loss = 0.8942 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 4234: loss = 0.9240 (0.842 sec/step)\n",
            "I0503 01:36:55.639841 140519389960064 learning.py:507] global step 4234: loss = 0.9240 (0.842 sec/step)\n",
            "INFO:tensorflow:global step 4235: loss = 0.9504 (0.849 sec/step)\n",
            "I0503 01:36:56.490001 140519389960064 learning.py:507] global step 4235: loss = 0.9504 (0.849 sec/step)\n",
            "INFO:tensorflow:global step 4236: loss = 0.9069 (0.815 sec/step)\n",
            "I0503 01:36:57.306404 140519389960064 learning.py:507] global step 4236: loss = 0.9069 (0.815 sec/step)\n",
            "INFO:tensorflow:global step 4237: loss = 0.7957 (0.891 sec/step)\n",
            "I0503 01:36:58.199116 140519389960064 learning.py:507] global step 4237: loss = 0.7957 (0.891 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path train/model.ckpt\n",
            "I0503 01:36:58.859223 140515693082368 supervisor.py:1117] Saving checkpoint to path train/model.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "W0503 01:36:59.129659 140515693082368 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "INFO:tensorflow:global step 4238: loss = 0.6256 (0.945 sec/step)\n",
            "I0503 01:36:59.145923 140519389960064 learning.py:507] global step 4238: loss = 0.6256 (0.945 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 4238.\n",
            "I0503 01:37:00.272251 140515676296960 supervisor.py:1050] Recording summary at step 4238.\n",
            "INFO:tensorflow:global step 4239: loss = 0.7785 (1.197 sec/step)\n",
            "I0503 01:37:00.642644 140519389960064 learning.py:507] global step 4239: loss = 0.7785 (1.197 sec/step)\n",
            "INFO:tensorflow:global step 4240: loss = 0.6589 (0.801 sec/step)\n",
            "I0503 01:37:01.977104 140519389960064 learning.py:507] global step 4240: loss = 0.6589 (0.801 sec/step)\n",
            "INFO:tensorflow:global_step/sec: 1.17497\n",
            "I0503 01:37:02.854084 140515684689664 supervisor.py:1099] global_step/sec: 1.17497\n",
            "INFO:tensorflow:global step 4241: loss = 0.8220 (0.793 sec/step)\n",
            "I0503 01:37:02.869025 140519389960064 learning.py:507] global step 4241: loss = 0.8220 (0.793 sec/step)\n",
            "INFO:tensorflow:global step 4242: loss = 0.6688 (0.892 sec/step)\n",
            "I0503 01:37:03.770393 140519389960064 learning.py:507] global step 4242: loss = 0.6688 (0.892 sec/step)\n",
            "INFO:tensorflow:global step 4243: loss = 0.8631 (0.794 sec/step)\n",
            "I0503 01:37:04.565551 140519389960064 learning.py:507] global step 4243: loss = 0.8631 (0.794 sec/step)\n",
            "INFO:tensorflow:global step 4244: loss = 0.7551 (0.835 sec/step)\n",
            "I0503 01:37:05.402211 140519389960064 learning.py:507] global step 4244: loss = 0.7551 (0.835 sec/step)\n",
            "INFO:tensorflow:global step 4245: loss = 0.7279 (0.805 sec/step)\n",
            "I0503 01:37:06.209303 140519389960064 learning.py:507] global step 4245: loss = 0.7279 (0.805 sec/step)\n",
            "INFO:tensorflow:global step 4246: loss = 0.9404 (0.831 sec/step)\n",
            "I0503 01:37:07.041994 140519389960064 learning.py:507] global step 4246: loss = 0.9404 (0.831 sec/step)\n",
            "INFO:tensorflow:global step 4247: loss = 0.7323 (0.896 sec/step)\n",
            "I0503 01:37:07.940454 140519389960064 learning.py:507] global step 4247: loss = 0.7323 (0.896 sec/step)\n",
            "INFO:tensorflow:global step 4248: loss = 0.9003 (0.795 sec/step)\n",
            "I0503 01:37:08.737247 140519389960064 learning.py:507] global step 4248: loss = 0.9003 (0.795 sec/step)\n",
            "INFO:tensorflow:global step 4249: loss = 0.8359 (0.692 sec/step)\n",
            "I0503 01:37:09.431045 140519389960064 learning.py:507] global step 4249: loss = 0.8359 (0.692 sec/step)\n",
            "INFO:tensorflow:global step 4250: loss = 0.7273 (0.892 sec/step)\n",
            "I0503 01:37:10.325001 140519389960064 learning.py:507] global step 4250: loss = 0.7273 (0.892 sec/step)\n",
            "INFO:tensorflow:global step 4251: loss = 0.7081 (0.821 sec/step)\n",
            "I0503 01:37:11.147833 140519389960064 learning.py:507] global step 4251: loss = 0.7081 (0.821 sec/step)\n",
            "INFO:tensorflow:global step 4252: loss = 0.9173 (0.798 sec/step)\n",
            "I0503 01:37:11.947309 140519389960064 learning.py:507] global step 4252: loss = 0.9173 (0.798 sec/step)\n",
            "INFO:tensorflow:global step 4253: loss = 0.7347 (0.765 sec/step)\n",
            "I0503 01:37:12.713741 140519389960064 learning.py:507] global step 4253: loss = 0.7347 (0.765 sec/step)\n",
            "INFO:tensorflow:global step 4254: loss = 0.7163 (0.891 sec/step)\n",
            "I0503 01:37:13.606691 140519389960064 learning.py:507] global step 4254: loss = 0.7163 (0.891 sec/step)\n",
            "INFO:tensorflow:global step 4255: loss = 0.6609 (0.767 sec/step)\n",
            "I0503 01:37:14.375918 140519389960064 learning.py:507] global step 4255: loss = 0.6609 (0.767 sec/step)\n",
            "INFO:tensorflow:global step 4256: loss = 0.5967 (0.909 sec/step)\n",
            "I0503 01:37:15.286046 140519389960064 learning.py:507] global step 4256: loss = 0.5967 (0.909 sec/step)\n",
            "INFO:tensorflow:global step 4257: loss = 0.7717 (0.861 sec/step)\n",
            "I0503 01:37:16.148540 140519389960064 learning.py:507] global step 4257: loss = 0.7717 (0.861 sec/step)\n",
            "INFO:tensorflow:global step 4258: loss = 0.8678 (0.853 sec/step)\n",
            "I0503 01:37:17.002653 140519389960064 learning.py:507] global step 4258: loss = 0.8678 (0.853 sec/step)\n",
            "INFO:tensorflow:global step 4259: loss = 0.7900 (0.851 sec/step)\n",
            "I0503 01:37:17.855176 140519389960064 learning.py:507] global step 4259: loss = 0.7900 (0.851 sec/step)\n",
            "INFO:tensorflow:global step 4260: loss = 0.5996 (0.817 sec/step)\n",
            "I0503 01:37:18.673509 140519389960064 learning.py:507] global step 4260: loss = 0.5996 (0.817 sec/step)\n",
            "INFO:tensorflow:global step 4261: loss = 0.7833 (0.804 sec/step)\n",
            "I0503 01:37:19.580681 140519389960064 learning.py:507] global step 4261: loss = 0.7833 (0.804 sec/step)\n",
            "INFO:tensorflow:global step 4262: loss = 0.7296 (0.952 sec/step)\n",
            "I0503 01:37:20.548092 140519389960064 learning.py:507] global step 4262: loss = 0.7296 (0.952 sec/step)\n",
            "INFO:tensorflow:global step 4263: loss = 1.1297 (0.731 sec/step)\n",
            "I0503 01:37:21.328095 140519389960064 learning.py:507] global step 4263: loss = 1.1297 (0.731 sec/step)\n",
            "INFO:tensorflow:global step 4264: loss = 0.7744 (1.256 sec/step)\n",
            "I0503 01:37:22.613326 140519389960064 learning.py:507] global step 4264: loss = 0.7744 (1.256 sec/step)\n",
            "INFO:tensorflow:global step 4265: loss = 0.6523 (0.928 sec/step)\n",
            "I0503 01:37:23.543135 140519389960064 learning.py:507] global step 4265: loss = 0.6523 (0.928 sec/step)\n",
            "INFO:tensorflow:global step 4266: loss = 0.6472 (0.776 sec/step)\n",
            "I0503 01:37:24.322926 140519389960064 learning.py:507] global step 4266: loss = 0.6472 (0.776 sec/step)\n",
            "INFO:tensorflow:global step 4267: loss = 0.7071 (1.224 sec/step)\n",
            "I0503 01:37:25.549621 140519389960064 learning.py:507] global step 4267: loss = 0.7071 (1.224 sec/step)\n",
            "INFO:tensorflow:global step 4268: loss = 0.9793 (0.819 sec/step)\n",
            "I0503 01:37:26.484373 140519389960064 learning.py:507] global step 4268: loss = 0.9793 (0.819 sec/step)\n",
            "INFO:tensorflow:global step 4269: loss = 0.9216 (0.790 sec/step)\n",
            "I0503 01:37:27.311324 140519389960064 learning.py:507] global step 4269: loss = 0.9216 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 4270: loss = 0.6325 (0.752 sec/step)\n",
            "I0503 01:37:28.119277 140519389960064 learning.py:507] global step 4270: loss = 0.6325 (0.752 sec/step)\n",
            "INFO:tensorflow:global step 4271: loss = 0.8918 (0.877 sec/step)\n",
            "I0503 01:37:29.011946 140519389960064 learning.py:507] global step 4271: loss = 0.8918 (0.877 sec/step)\n",
            "INFO:tensorflow:global step 4272: loss = 0.6395 (0.840 sec/step)\n",
            "I0503 01:37:29.898603 140519389960064 learning.py:507] global step 4272: loss = 0.6395 (0.840 sec/step)\n",
            "INFO:tensorflow:global step 4273: loss = 0.7663 (0.742 sec/step)\n",
            "I0503 01:37:30.642296 140519389960064 learning.py:507] global step 4273: loss = 0.7663 (0.742 sec/step)\n",
            "INFO:tensorflow:global step 4274: loss = 0.6786 (0.793 sec/step)\n",
            "I0503 01:37:31.480585 140519389960064 learning.py:507] global step 4274: loss = 0.6786 (0.793 sec/step)\n",
            "INFO:tensorflow:global step 4275: loss = 0.9113 (0.873 sec/step)\n",
            "I0503 01:37:32.369809 140519389960064 learning.py:507] global step 4275: loss = 0.9113 (0.873 sec/step)\n",
            "INFO:tensorflow:global step 4276: loss = 0.9464 (0.834 sec/step)\n",
            "I0503 01:37:33.205580 140519389960064 learning.py:507] global step 4276: loss = 0.9464 (0.834 sec/step)\n",
            "INFO:tensorflow:global step 4277: loss = 0.6884 (0.949 sec/step)\n",
            "I0503 01:37:34.156328 140519389960064 learning.py:507] global step 4277: loss = 0.6884 (0.949 sec/step)\n",
            "INFO:tensorflow:global step 4278: loss = 0.7028 (0.802 sec/step)\n",
            "I0503 01:37:34.959891 140519389960064 learning.py:507] global step 4278: loss = 0.7028 (0.802 sec/step)\n",
            "INFO:tensorflow:global step 4279: loss = 0.9634 (0.810 sec/step)\n",
            "I0503 01:37:35.772093 140519389960064 learning.py:507] global step 4279: loss = 0.9634 (0.810 sec/step)\n",
            "INFO:tensorflow:global step 4280: loss = 0.7961 (0.835 sec/step)\n",
            "I0503 01:37:36.608711 140519389960064 learning.py:507] global step 4280: loss = 0.7961 (0.835 sec/step)\n",
            "INFO:tensorflow:global step 4281: loss = 0.8452 (0.812 sec/step)\n",
            "I0503 01:37:37.422210 140519389960064 learning.py:507] global step 4281: loss = 0.8452 (0.812 sec/step)\n",
            "INFO:tensorflow:global step 4282: loss = 0.7149 (0.804 sec/step)\n",
            "I0503 01:37:38.228072 140519389960064 learning.py:507] global step 4282: loss = 0.7149 (0.804 sec/step)\n",
            "INFO:tensorflow:global step 4283: loss = 0.7800 (0.885 sec/step)\n",
            "I0503 01:37:39.115078 140519389960064 learning.py:507] global step 4283: loss = 0.7800 (0.885 sec/step)\n",
            "INFO:tensorflow:global step 4284: loss = 0.7160 (0.827 sec/step)\n",
            "I0503 01:37:39.944135 140519389960064 learning.py:507] global step 4284: loss = 0.7160 (0.827 sec/step)\n",
            "INFO:tensorflow:global step 4285: loss = 0.8062 (0.826 sec/step)\n",
            "I0503 01:37:40.771213 140519389960064 learning.py:507] global step 4285: loss = 0.8062 (0.826 sec/step)\n",
            "INFO:tensorflow:global step 4286: loss = 0.7145 (0.784 sec/step)\n",
            "I0503 01:37:41.560382 140519389960064 learning.py:507] global step 4286: loss = 0.7145 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 4287: loss = 0.6376 (0.760 sec/step)\n",
            "I0503 01:37:42.321732 140519389960064 learning.py:507] global step 4287: loss = 0.6376 (0.760 sec/step)\n",
            "INFO:tensorflow:global step 4288: loss = 0.9270 (0.819 sec/step)\n",
            "I0503 01:37:43.142122 140519389960064 learning.py:507] global step 4288: loss = 0.9270 (0.819 sec/step)\n",
            "INFO:tensorflow:global step 4289: loss = 0.6432 (0.738 sec/step)\n",
            "I0503 01:37:43.942409 140519389960064 learning.py:507] global step 4289: loss = 0.6432 (0.738 sec/step)\n",
            "INFO:tensorflow:global step 4290: loss = 0.7251 (0.870 sec/step)\n",
            "I0503 01:37:44.814934 140519389960064 learning.py:507] global step 4290: loss = 0.7251 (0.870 sec/step)\n",
            "INFO:tensorflow:global step 4291: loss = 0.8089 (0.763 sec/step)\n",
            "I0503 01:37:45.580087 140519389960064 learning.py:507] global step 4291: loss = 0.8089 (0.763 sec/step)\n",
            "INFO:tensorflow:global step 4292: loss = 0.9669 (0.802 sec/step)\n",
            "I0503 01:37:46.383371 140519389960064 learning.py:507] global step 4292: loss = 0.9669 (0.802 sec/step)\n",
            "INFO:tensorflow:global step 4293: loss = 0.9111 (0.792 sec/step)\n",
            "I0503 01:37:47.176820 140519389960064 learning.py:507] global step 4293: loss = 0.9111 (0.792 sec/step)\n",
            "INFO:tensorflow:global step 4294: loss = 0.9940 (0.874 sec/step)\n",
            "I0503 01:37:48.052324 140519389960064 learning.py:507] global step 4294: loss = 0.9940 (0.874 sec/step)\n",
            "INFO:tensorflow:global step 4295: loss = 0.5429 (0.832 sec/step)\n",
            "I0503 01:37:48.886871 140519389960064 learning.py:507] global step 4295: loss = 0.5429 (0.832 sec/step)\n",
            "INFO:tensorflow:global step 4296: loss = 0.7371 (0.881 sec/step)\n",
            "I0503 01:37:49.769035 140519389960064 learning.py:507] global step 4296: loss = 0.7371 (0.881 sec/step)\n",
            "INFO:tensorflow:global step 4297: loss = 0.8413 (0.833 sec/step)\n",
            "I0503 01:37:50.603752 140519389960064 learning.py:507] global step 4297: loss = 0.8413 (0.833 sec/step)\n",
            "INFO:tensorflow:global step 4298: loss = 0.7644 (0.886 sec/step)\n",
            "I0503 01:37:51.491644 140519389960064 learning.py:507] global step 4298: loss = 0.7644 (0.886 sec/step)\n",
            "INFO:tensorflow:global step 4299: loss = 0.8449 (0.785 sec/step)\n",
            "I0503 01:37:52.277888 140519389960064 learning.py:507] global step 4299: loss = 0.8449 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 4300: loss = 0.5868 (0.673 sec/step)\n",
            "I0503 01:37:52.980150 140519389960064 learning.py:507] global step 4300: loss = 0.5868 (0.673 sec/step)\n",
            "INFO:tensorflow:global step 4301: loss = 0.9089 (0.818 sec/step)\n",
            "I0503 01:37:53.800504 140519389960064 learning.py:507] global step 4301: loss = 0.9089 (0.818 sec/step)\n",
            "INFO:tensorflow:global step 4302: loss = 0.6739 (0.798 sec/step)\n",
            "I0503 01:37:54.600443 140519389960064 learning.py:507] global step 4302: loss = 0.6739 (0.798 sec/step)\n",
            "INFO:tensorflow:global step 4303: loss = 0.7815 (0.801 sec/step)\n",
            "I0503 01:37:55.402721 140519389960064 learning.py:507] global step 4303: loss = 0.7815 (0.801 sec/step)\n",
            "INFO:tensorflow:global step 4304: loss = 0.6371 (0.848 sec/step)\n",
            "I0503 01:37:56.252513 140519389960064 learning.py:507] global step 4304: loss = 0.6371 (0.848 sec/step)\n",
            "INFO:tensorflow:global step 4305: loss = 0.8415 (0.725 sec/step)\n",
            "I0503 01:37:56.979321 140519389960064 learning.py:507] global step 4305: loss = 0.8415 (0.725 sec/step)\n",
            "INFO:tensorflow:global step 4306: loss = 0.7541 (0.828 sec/step)\n",
            "I0503 01:37:57.808923 140519389960064 learning.py:507] global step 4306: loss = 0.7541 (0.828 sec/step)\n",
            "INFO:tensorflow:global step 4307: loss = 0.8536 (0.978 sec/step)\n",
            "I0503 01:37:58.788553 140519389960064 learning.py:507] global step 4307: loss = 0.8536 (0.978 sec/step)\n",
            "INFO:tensorflow:global step 4308: loss = 0.8241 (0.738 sec/step)\n",
            "I0503 01:37:59.528365 140519389960064 learning.py:507] global step 4308: loss = 0.8241 (0.738 sec/step)\n",
            "INFO:tensorflow:global step 4309: loss = 0.7644 (1.004 sec/step)\n",
            "I0503 01:38:00.533826 140519389960064 learning.py:507] global step 4309: loss = 0.7644 (1.004 sec/step)\n",
            "INFO:tensorflow:global step 4310: loss = 0.6166 (0.863 sec/step)\n",
            "I0503 01:38:01.399062 140519389960064 learning.py:507] global step 4310: loss = 0.6166 (0.863 sec/step)\n",
            "INFO:tensorflow:global step 4311: loss = 0.7118 (0.847 sec/step)\n",
            "I0503 01:38:02.248155 140519389960064 learning.py:507] global step 4311: loss = 0.7118 (0.847 sec/step)\n",
            "INFO:tensorflow:global step 4312: loss = 0.6657 (0.674 sec/step)\n",
            "I0503 01:38:02.924355 140519389960064 learning.py:507] global step 4312: loss = 0.6657 (0.674 sec/step)\n",
            "INFO:tensorflow:global step 4313: loss = 1.0043 (0.819 sec/step)\n",
            "I0503 01:38:03.746152 140519389960064 learning.py:507] global step 4313: loss = 1.0043 (0.819 sec/step)\n",
            "INFO:tensorflow:global step 4314: loss = 0.7677 (0.761 sec/step)\n",
            "I0503 01:38:04.513442 140519389960064 learning.py:507] global step 4314: loss = 0.7677 (0.761 sec/step)\n",
            "INFO:tensorflow:global step 4315: loss = 0.7254 (0.896 sec/step)\n",
            "I0503 01:38:05.415891 140519389960064 learning.py:507] global step 4315: loss = 0.7254 (0.896 sec/step)\n",
            "INFO:tensorflow:global step 4316: loss = 0.7478 (0.671 sec/step)\n",
            "I0503 01:38:06.172757 140519389960064 learning.py:507] global step 4316: loss = 0.7478 (0.671 sec/step)\n",
            "INFO:tensorflow:global step 4317: loss = 0.6959 (0.940 sec/step)\n",
            "I0503 01:38:07.156049 140519389960064 learning.py:507] global step 4317: loss = 0.6959 (0.940 sec/step)\n",
            "INFO:tensorflow:global step 4318: loss = 0.7716 (0.878 sec/step)\n",
            "I0503 01:38:08.035623 140519389960064 learning.py:507] global step 4318: loss = 0.7716 (0.878 sec/step)\n",
            "INFO:tensorflow:global step 4319: loss = 0.8807 (0.766 sec/step)\n",
            "I0503 01:38:08.877746 140519389960064 learning.py:507] global step 4319: loss = 0.8807 (0.766 sec/step)\n",
            "INFO:tensorflow:global step 4320: loss = 0.8179 (1.021 sec/step)\n",
            "I0503 01:38:09.948976 140519389960064 learning.py:507] global step 4320: loss = 0.8179 (1.021 sec/step)\n",
            "INFO:tensorflow:global step 4321: loss = 0.9519 (0.628 sec/step)\n",
            "I0503 01:38:10.579183 140519389960064 learning.py:507] global step 4321: loss = 0.9519 (0.628 sec/step)\n",
            "INFO:tensorflow:global step 4322: loss = 1.0464 (0.812 sec/step)\n",
            "I0503 01:38:11.392840 140519389960064 learning.py:507] global step 4322: loss = 1.0464 (0.812 sec/step)\n",
            "INFO:tensorflow:global step 4323: loss = 0.7669 (0.868 sec/step)\n",
            "I0503 01:38:12.262485 140519389960064 learning.py:507] global step 4323: loss = 0.7669 (0.868 sec/step)\n",
            "INFO:tensorflow:global step 4324: loss = 0.9335 (0.925 sec/step)\n",
            "I0503 01:38:13.189287 140519389960064 learning.py:507] global step 4324: loss = 0.9335 (0.925 sec/step)\n",
            "INFO:tensorflow:global step 4325: loss = 0.8621 (0.894 sec/step)\n",
            "I0503 01:38:14.084982 140519389960064 learning.py:507] global step 4325: loss = 0.8621 (0.894 sec/step)\n",
            "INFO:tensorflow:global step 4326: loss = 0.7163 (0.742 sec/step)\n",
            "I0503 01:38:14.829579 140519389960064 learning.py:507] global step 4326: loss = 0.7163 (0.742 sec/step)\n",
            "INFO:tensorflow:global step 4327: loss = 0.7610 (0.924 sec/step)\n",
            "I0503 01:38:15.755684 140519389960064 learning.py:507] global step 4327: loss = 0.7610 (0.924 sec/step)\n",
            "INFO:tensorflow:global step 4328: loss = 0.8680 (0.713 sec/step)\n",
            "I0503 01:38:16.470046 140519389960064 learning.py:507] global step 4328: loss = 0.8680 (0.713 sec/step)\n",
            "INFO:tensorflow:global step 4329: loss = 0.7715 (0.854 sec/step)\n",
            "I0503 01:38:17.326367 140519389960064 learning.py:507] global step 4329: loss = 0.7715 (0.854 sec/step)\n",
            "INFO:tensorflow:global step 4330: loss = 0.8400 (0.884 sec/step)\n",
            "I0503 01:38:18.213114 140519389960064 learning.py:507] global step 4330: loss = 0.8400 (0.884 sec/step)\n",
            "INFO:tensorflow:global step 4331: loss = 0.6491 (0.758 sec/step)\n",
            "I0503 01:38:19.033680 140519389960064 learning.py:507] global step 4331: loss = 0.6491 (0.758 sec/step)\n",
            "INFO:tensorflow:global step 4332: loss = 0.7218 (0.995 sec/step)\n",
            "I0503 01:38:20.045764 140519389960064 learning.py:507] global step 4332: loss = 0.7218 (0.995 sec/step)\n",
            "INFO:tensorflow:global step 4333: loss = 0.8934 (0.759 sec/step)\n",
            "I0503 01:38:20.858130 140519389960064 learning.py:507] global step 4333: loss = 0.8934 (0.759 sec/step)\n",
            "INFO:tensorflow:global step 4334: loss = 0.7784 (0.878 sec/step)\n",
            "I0503 01:38:21.737629 140519389960064 learning.py:507] global step 4334: loss = 0.7784 (0.878 sec/step)\n",
            "INFO:tensorflow:global step 4335: loss = 0.7799 (0.784 sec/step)\n",
            "I0503 01:38:22.554038 140519389960064 learning.py:507] global step 4335: loss = 0.7799 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 4336: loss = 0.7255 (0.884 sec/step)\n",
            "I0503 01:38:23.442667 140519389960064 learning.py:507] global step 4336: loss = 0.7255 (0.884 sec/step)\n",
            "INFO:tensorflow:global step 4337: loss = 0.7295 (0.903 sec/step)\n",
            "I0503 01:38:24.346916 140519389960064 learning.py:507] global step 4337: loss = 0.7295 (0.903 sec/step)\n",
            "INFO:tensorflow:global step 4338: loss = 0.9379 (0.899 sec/step)\n",
            "I0503 01:38:25.247273 140519389960064 learning.py:507] global step 4338: loss = 0.9379 (0.899 sec/step)\n",
            "INFO:tensorflow:global step 4339: loss = 0.7492 (0.730 sec/step)\n",
            "I0503 01:38:25.979136 140519389960064 learning.py:507] global step 4339: loss = 0.7492 (0.730 sec/step)\n",
            "INFO:tensorflow:global step 4340: loss = 0.9294 (0.819 sec/step)\n",
            "I0503 01:38:26.799521 140519389960064 learning.py:507] global step 4340: loss = 0.9294 (0.819 sec/step)\n",
            "INFO:tensorflow:global step 4341: loss = 0.7831 (0.895 sec/step)\n",
            "I0503 01:38:27.695838 140519389960064 learning.py:507] global step 4341: loss = 0.7831 (0.895 sec/step)\n",
            "INFO:tensorflow:global step 4342: loss = 0.7767 (0.805 sec/step)\n",
            "I0503 01:38:28.502501 140519389960064 learning.py:507] global step 4342: loss = 0.7767 (0.805 sec/step)\n",
            "INFO:tensorflow:global step 4343: loss = 0.9211 (0.887 sec/step)\n",
            "I0503 01:38:29.390787 140519389960064 learning.py:507] global step 4343: loss = 0.9211 (0.887 sec/step)\n",
            "INFO:tensorflow:global step 4344: loss = 0.8749 (0.900 sec/step)\n",
            "I0503 01:38:30.292754 140519389960064 learning.py:507] global step 4344: loss = 0.8749 (0.900 sec/step)\n",
            "INFO:tensorflow:global step 4345: loss = 0.7363 (0.731 sec/step)\n",
            "I0503 01:38:31.025364 140519389960064 learning.py:507] global step 4345: loss = 0.7363 (0.731 sec/step)\n",
            "INFO:tensorflow:global step 4346: loss = 0.9652 (0.808 sec/step)\n",
            "I0503 01:38:31.835386 140519389960064 learning.py:507] global step 4346: loss = 0.9652 (0.808 sec/step)\n",
            "INFO:tensorflow:global step 4347: loss = 0.8776 (0.907 sec/step)\n",
            "I0503 01:38:32.743762 140519389960064 learning.py:507] global step 4347: loss = 0.8776 (0.907 sec/step)\n",
            "INFO:tensorflow:global step 4348: loss = 0.8010 (0.789 sec/step)\n",
            "I0503 01:38:33.534528 140519389960064 learning.py:507] global step 4348: loss = 0.8010 (0.789 sec/step)\n",
            "INFO:tensorflow:global step 4349: loss = 0.9169 (0.824 sec/step)\n",
            "I0503 01:38:34.359961 140519389960064 learning.py:507] global step 4349: loss = 0.9169 (0.824 sec/step)\n",
            "INFO:tensorflow:global step 4350: loss = 1.0608 (0.919 sec/step)\n",
            "I0503 01:38:35.280660 140519389960064 learning.py:507] global step 4350: loss = 1.0608 (0.919 sec/step)\n",
            "INFO:tensorflow:global step 4351: loss = 0.9092 (0.984 sec/step)\n",
            "I0503 01:38:36.266292 140519389960064 learning.py:507] global step 4351: loss = 0.9092 (0.984 sec/step)\n",
            "INFO:tensorflow:global step 4352: loss = 0.7505 (0.808 sec/step)\n",
            "I0503 01:38:37.075710 140519389960064 learning.py:507] global step 4352: loss = 0.7505 (0.808 sec/step)\n",
            "INFO:tensorflow:global step 4353: loss = 0.6103 (0.896 sec/step)\n",
            "I0503 01:38:37.973616 140519389960064 learning.py:507] global step 4353: loss = 0.6103 (0.896 sec/step)\n",
            "INFO:tensorflow:global step 4354: loss = 0.8176 (0.860 sec/step)\n",
            "I0503 01:38:38.836764 140519389960064 learning.py:507] global step 4354: loss = 0.8176 (0.860 sec/step)\n",
            "INFO:tensorflow:global step 4355: loss = 1.0774 (0.726 sec/step)\n",
            "I0503 01:38:39.564166 140519389960064 learning.py:507] global step 4355: loss = 1.0774 (0.726 sec/step)\n",
            "INFO:tensorflow:global step 4356: loss = 0.7093 (0.787 sec/step)\n",
            "I0503 01:38:40.353013 140519389960064 learning.py:507] global step 4356: loss = 0.7093 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 4357: loss = 0.8443 (0.764 sec/step)\n",
            "I0503 01:38:41.118283 140519389960064 learning.py:507] global step 4357: loss = 0.8443 (0.764 sec/step)\n",
            "INFO:tensorflow:global step 4358: loss = 0.8163 (0.696 sec/step)\n",
            "I0503 01:38:41.882280 140519389960064 learning.py:507] global step 4358: loss = 0.8163 (0.696 sec/step)\n",
            "INFO:tensorflow:global step 4359: loss = 1.0757 (0.935 sec/step)\n",
            "I0503 01:38:42.823211 140519389960064 learning.py:507] global step 4359: loss = 1.0757 (0.935 sec/step)\n",
            "INFO:tensorflow:global step 4360: loss = 0.8266 (0.858 sec/step)\n",
            "I0503 01:38:43.684468 140519389960064 learning.py:507] global step 4360: loss = 0.8266 (0.858 sec/step)\n",
            "INFO:tensorflow:global step 4361: loss = 0.7847 (0.755 sec/step)\n",
            "I0503 01:38:44.440705 140519389960064 learning.py:507] global step 4361: loss = 0.7847 (0.755 sec/step)\n",
            "INFO:tensorflow:global step 4362: loss = 0.6899 (0.779 sec/step)\n",
            "I0503 01:38:45.221526 140519389960064 learning.py:507] global step 4362: loss = 0.6899 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 4363: loss = 0.7370 (0.917 sec/step)\n",
            "I0503 01:38:46.139537 140519389960064 learning.py:507] global step 4363: loss = 0.7370 (0.917 sec/step)\n",
            "INFO:tensorflow:global step 4364: loss = 0.7936 (0.803 sec/step)\n",
            "I0503 01:38:46.944115 140519389960064 learning.py:507] global step 4364: loss = 0.7936 (0.803 sec/step)\n",
            "INFO:tensorflow:global step 4365: loss = 0.6541 (0.902 sec/step)\n",
            "I0503 01:38:47.847694 140519389960064 learning.py:507] global step 4365: loss = 0.6541 (0.902 sec/step)\n",
            "INFO:tensorflow:global step 4366: loss = 0.7332 (0.824 sec/step)\n",
            "I0503 01:38:48.673816 140519389960064 learning.py:507] global step 4366: loss = 0.7332 (0.824 sec/step)\n",
            "INFO:tensorflow:global step 4367: loss = 0.6895 (0.810 sec/step)\n",
            "I0503 01:38:49.484791 140519389960064 learning.py:507] global step 4367: loss = 0.6895 (0.810 sec/step)\n",
            "INFO:tensorflow:global step 4368: loss = 0.7607 (0.908 sec/step)\n",
            "I0503 01:38:50.394336 140519389960064 learning.py:507] global step 4368: loss = 0.7607 (0.908 sec/step)\n",
            "INFO:tensorflow:global step 4369: loss = 0.7276 (0.840 sec/step)\n",
            "I0503 01:38:51.235549 140519389960064 learning.py:507] global step 4369: loss = 0.7276 (0.840 sec/step)\n",
            "INFO:tensorflow:global step 4370: loss = 0.6807 (0.912 sec/step)\n",
            "I0503 01:38:52.149712 140519389960064 learning.py:507] global step 4370: loss = 0.6807 (0.912 sec/step)\n",
            "INFO:tensorflow:global step 4371: loss = 0.8773 (0.956 sec/step)\n",
            "I0503 01:38:53.107281 140519389960064 learning.py:507] global step 4371: loss = 0.8773 (0.956 sec/step)\n",
            "INFO:tensorflow:global step 4372: loss = 0.6339 (0.636 sec/step)\n",
            "I0503 01:38:53.747288 140519389960064 learning.py:507] global step 4372: loss = 0.6339 (0.636 sec/step)\n",
            "INFO:tensorflow:global step 4373: loss = 0.8233 (0.889 sec/step)\n",
            "I0503 01:38:54.639116 140519389960064 learning.py:507] global step 4373: loss = 0.8233 (0.889 sec/step)\n",
            "INFO:tensorflow:global step 4374: loss = 0.5372 (0.620 sec/step)\n",
            "I0503 01:38:55.264526 140519389960064 learning.py:507] global step 4374: loss = 0.5372 (0.620 sec/step)\n",
            "INFO:tensorflow:global step 4375: loss = 0.7228 (0.867 sec/step)\n",
            "I0503 01:38:56.133367 140519389960064 learning.py:507] global step 4375: loss = 0.7228 (0.867 sec/step)\n",
            "INFO:tensorflow:global step 4376: loss = 0.6230 (0.882 sec/step)\n",
            "I0503 01:38:57.017009 140519389960064 learning.py:507] global step 4376: loss = 0.6230 (0.882 sec/step)\n",
            "INFO:tensorflow:global step 4377: loss = 0.6740 (0.833 sec/step)\n",
            "I0503 01:38:57.851849 140519389960064 learning.py:507] global step 4377: loss = 0.6740 (0.833 sec/step)\n",
            "INFO:tensorflow:global step 4378: loss = 0.5673 (0.863 sec/step)\n",
            "I0503 01:38:58.716867 140519389960064 learning.py:507] global step 4378: loss = 0.5673 (0.863 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 4378.\n",
            "I0503 01:39:00.493689 140515676296960 supervisor.py:1050] Recording summary at step 4378.\n",
            "INFO:tensorflow:global step 4379: loss = 0.6860 (1.791 sec/step)\n",
            "I0503 01:39:00.508939 140519389960064 learning.py:507] global step 4379: loss = 0.6860 (1.791 sec/step)\n",
            "INFO:tensorflow:global step 4380: loss = 0.8390 (0.812 sec/step)\n",
            "I0503 01:39:01.322619 140519389960064 learning.py:507] global step 4380: loss = 0.8390 (0.812 sec/step)\n",
            "INFO:tensorflow:global step 4381: loss = 0.8188 (0.918 sec/step)\n",
            "I0503 01:39:02.242199 140519389960064 learning.py:507] global step 4381: loss = 0.8188 (0.918 sec/step)\n",
            "INFO:tensorflow:global_step/sec: 1.16573\n",
            "I0503 01:39:02.950124 140515684689664 supervisor.py:1099] global_step/sec: 1.16573\n",
            "INFO:tensorflow:global step 4382: loss = 1.1418 (0.758 sec/step)\n",
            "I0503 01:39:03.047719 140519389960064 learning.py:507] global step 4382: loss = 1.1418 (0.758 sec/step)\n",
            "INFO:tensorflow:global step 4383: loss = 0.7971 (0.913 sec/step)\n",
            "I0503 01:39:04.070980 140519389960064 learning.py:507] global step 4383: loss = 0.7971 (0.913 sec/step)\n",
            "INFO:tensorflow:global step 4384: loss = 0.8232 (0.692 sec/step)\n",
            "I0503 01:39:04.832906 140519389960064 learning.py:507] global step 4384: loss = 0.8232 (0.692 sec/step)\n",
            "INFO:tensorflow:global step 4385: loss = 0.7353 (0.964 sec/step)\n",
            "I0503 01:39:05.798904 140519389960064 learning.py:507] global step 4385: loss = 0.7353 (0.964 sec/step)\n",
            "INFO:tensorflow:global step 4386: loss = 0.6373 (0.795 sec/step)\n",
            "I0503 01:39:06.595359 140519389960064 learning.py:507] global step 4386: loss = 0.6373 (0.795 sec/step)\n",
            "INFO:tensorflow:global step 4387: loss = 0.8921 (0.940 sec/step)\n",
            "I0503 01:39:07.536715 140519389960064 learning.py:507] global step 4387: loss = 0.8921 (0.940 sec/step)\n",
            "INFO:tensorflow:global step 4388: loss = 0.6927 (0.812 sec/step)\n",
            "I0503 01:39:08.350538 140519389960064 learning.py:507] global step 4388: loss = 0.6927 (0.812 sec/step)\n",
            "INFO:tensorflow:global step 4389: loss = 0.8726 (0.849 sec/step)\n",
            "I0503 01:39:09.201117 140519389960064 learning.py:507] global step 4389: loss = 0.8726 (0.849 sec/step)\n",
            "INFO:tensorflow:global step 4390: loss = 0.7867 (0.967 sec/step)\n",
            "I0503 01:39:10.169149 140519389960064 learning.py:507] global step 4390: loss = 0.7867 (0.967 sec/step)\n",
            "INFO:tensorflow:global step 4391: loss = 0.7499 (0.821 sec/step)\n",
            "I0503 01:39:10.992202 140519389960064 learning.py:507] global step 4391: loss = 0.7499 (0.821 sec/step)\n",
            "INFO:tensorflow:global step 4392: loss = 0.8716 (0.775 sec/step)\n",
            "I0503 01:39:11.769277 140519389960064 learning.py:507] global step 4392: loss = 0.8716 (0.775 sec/step)\n",
            "INFO:tensorflow:global step 4393: loss = 0.9074 (0.725 sec/step)\n",
            "I0503 01:39:12.497267 140519389960064 learning.py:507] global step 4393: loss = 0.9074 (0.725 sec/step)\n",
            "INFO:tensorflow:global step 4394: loss = 0.7207 (0.818 sec/step)\n",
            "I0503 01:39:13.317182 140519389960064 learning.py:507] global step 4394: loss = 0.7207 (0.818 sec/step)\n",
            "INFO:tensorflow:global step 4395: loss = 0.9206 (0.781 sec/step)\n",
            "I0503 01:39:14.099655 140519389960064 learning.py:507] global step 4395: loss = 0.9206 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 4396: loss = 0.7540 (0.877 sec/step)\n",
            "I0503 01:39:14.977926 140519389960064 learning.py:507] global step 4396: loss = 0.7540 (0.877 sec/step)\n",
            "INFO:tensorflow:global step 4397: loss = 1.1525 (0.734 sec/step)\n",
            "I0503 01:39:15.713231 140519389960064 learning.py:507] global step 4397: loss = 1.1525 (0.734 sec/step)\n",
            "INFO:tensorflow:global step 4398: loss = 0.8283 (0.769 sec/step)\n",
            "I0503 01:39:16.484258 140519389960064 learning.py:507] global step 4398: loss = 0.8283 (0.769 sec/step)\n",
            "INFO:tensorflow:global step 4399: loss = 0.9397 (0.838 sec/step)\n",
            "I0503 01:39:17.323391 140519389960064 learning.py:507] global step 4399: loss = 0.9397 (0.838 sec/step)\n",
            "INFO:tensorflow:global step 4400: loss = 0.8912 (0.787 sec/step)\n",
            "I0503 01:39:18.112412 140519389960064 learning.py:507] global step 4400: loss = 0.8912 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 4401: loss = 0.7741 (0.860 sec/step)\n",
            "I0503 01:39:18.973716 140519389960064 learning.py:507] global step 4401: loss = 0.7741 (0.860 sec/step)\n",
            "INFO:tensorflow:global step 4402: loss = 0.7744 (0.868 sec/step)\n",
            "I0503 01:39:19.843549 140519389960064 learning.py:507] global step 4402: loss = 0.7744 (0.868 sec/step)\n",
            "INFO:tensorflow:global step 4403: loss = 0.8050 (0.761 sec/step)\n",
            "I0503 01:39:20.606322 140519389960064 learning.py:507] global step 4403: loss = 0.8050 (0.761 sec/step)\n",
            "INFO:tensorflow:global step 4404: loss = 0.7828 (0.829 sec/step)\n",
            "I0503 01:39:21.436833 140519389960064 learning.py:507] global step 4404: loss = 0.7828 (0.829 sec/step)\n",
            "INFO:tensorflow:global step 4405: loss = 0.8500 (0.830 sec/step)\n",
            "I0503 01:39:22.269024 140519389960064 learning.py:507] global step 4405: loss = 0.8500 (0.830 sec/step)\n",
            "INFO:tensorflow:global step 4406: loss = 0.7369 (0.736 sec/step)\n",
            "I0503 01:39:23.100839 140519389960064 learning.py:507] global step 4406: loss = 0.7369 (0.736 sec/step)\n",
            "INFO:tensorflow:global step 4407: loss = 0.6773 (0.958 sec/step)\n",
            "I0503 01:39:24.071001 140519389960064 learning.py:507] global step 4407: loss = 0.6773 (0.958 sec/step)\n",
            "INFO:tensorflow:global step 4408: loss = 1.0439 (0.789 sec/step)\n",
            "I0503 01:39:24.861795 140519389960064 learning.py:507] global step 4408: loss = 1.0439 (0.789 sec/step)\n",
            "INFO:tensorflow:global step 4409: loss = 0.8444 (0.852 sec/step)\n",
            "I0503 01:39:25.715789 140519389960064 learning.py:507] global step 4409: loss = 0.8444 (0.852 sec/step)\n",
            "INFO:tensorflow:global step 4410: loss = 0.8542 (0.824 sec/step)\n",
            "I0503 01:39:26.541095 140519389960064 learning.py:507] global step 4410: loss = 0.8542 (0.824 sec/step)\n",
            "INFO:tensorflow:global step 4411: loss = 0.6992 (0.855 sec/step)\n",
            "I0503 01:39:27.397367 140519389960064 learning.py:507] global step 4411: loss = 0.6992 (0.855 sec/step)\n",
            "INFO:tensorflow:global step 4412: loss = 0.6948 (0.819 sec/step)\n",
            "I0503 01:39:28.217868 140519389960064 learning.py:507] global step 4412: loss = 0.6948 (0.819 sec/step)\n",
            "INFO:tensorflow:global step 4413: loss = 0.8831 (0.848 sec/step)\n",
            "I0503 01:39:29.067581 140519389960064 learning.py:507] global step 4413: loss = 0.8831 (0.848 sec/step)\n",
            "INFO:tensorflow:global step 4414: loss = 0.7439 (0.799 sec/step)\n",
            "I0503 01:39:29.868259 140519389960064 learning.py:507] global step 4414: loss = 0.7439 (0.799 sec/step)\n",
            "INFO:tensorflow:global step 4415: loss = 0.6273 (0.926 sec/step)\n",
            "I0503 01:39:30.796079 140519389960064 learning.py:507] global step 4415: loss = 0.6273 (0.926 sec/step)\n",
            "INFO:tensorflow:global step 4416: loss = 0.6272 (0.915 sec/step)\n",
            "I0503 01:39:31.713285 140519389960064 learning.py:507] global step 4416: loss = 0.6272 (0.915 sec/step)\n",
            "INFO:tensorflow:global step 4417: loss = 1.1984 (0.695 sec/step)\n",
            "I0503 01:39:32.422758 140519389960064 learning.py:507] global step 4417: loss = 1.1984 (0.695 sec/step)\n",
            "INFO:tensorflow:global step 4418: loss = 0.7896 (0.804 sec/step)\n",
            "I0503 01:39:33.229004 140519389960064 learning.py:507] global step 4418: loss = 0.7896 (0.804 sec/step)\n",
            "INFO:tensorflow:global step 4419: loss = 0.9205 (0.807 sec/step)\n",
            "I0503 01:39:34.037512 140519389960064 learning.py:507] global step 4419: loss = 0.9205 (0.807 sec/step)\n",
            "INFO:tensorflow:global step 4420: loss = 1.1148 (1.041 sec/step)\n",
            "I0503 01:39:35.079834 140519389960064 learning.py:507] global step 4420: loss = 1.1148 (1.041 sec/step)\n",
            "INFO:tensorflow:global step 4421: loss = 0.9754 (0.815 sec/step)\n",
            "I0503 01:39:35.896593 140519389960064 learning.py:507] global step 4421: loss = 0.9754 (0.815 sec/step)\n",
            "INFO:tensorflow:global step 4422: loss = 0.6822 (0.891 sec/step)\n",
            "I0503 01:39:36.789625 140519389960064 learning.py:507] global step 4422: loss = 0.6822 (0.891 sec/step)\n",
            "INFO:tensorflow:global step 4423: loss = 0.6474 (0.940 sec/step)\n",
            "I0503 01:39:37.731310 140519389960064 learning.py:507] global step 4423: loss = 0.6474 (0.940 sec/step)\n",
            "INFO:tensorflow:global step 4424: loss = 0.8507 (0.853 sec/step)\n",
            "I0503 01:39:38.586084 140519389960064 learning.py:507] global step 4424: loss = 0.8507 (0.853 sec/step)\n",
            "INFO:tensorflow:global step 4425: loss = 0.6541 (0.839 sec/step)\n",
            "I0503 01:39:39.426857 140519389960064 learning.py:507] global step 4425: loss = 0.6541 (0.839 sec/step)\n",
            "INFO:tensorflow:global step 4426: loss = 0.6720 (0.901 sec/step)\n",
            "I0503 01:39:40.333577 140519389960064 learning.py:507] global step 4426: loss = 0.6720 (0.901 sec/step)\n",
            "INFO:tensorflow:global step 4427: loss = 0.8158 (0.862 sec/step)\n",
            "I0503 01:39:41.199272 140519389960064 learning.py:507] global step 4427: loss = 0.8158 (0.862 sec/step)\n",
            "INFO:tensorflow:global step 4428: loss = 0.7608 (0.935 sec/step)\n",
            "I0503 01:39:42.136441 140519389960064 learning.py:507] global step 4428: loss = 0.7608 (0.935 sec/step)\n",
            "INFO:tensorflow:global step 4429: loss = 0.6084 (0.759 sec/step)\n",
            "I0503 01:39:42.896667 140519389960064 learning.py:507] global step 4429: loss = 0.6084 (0.759 sec/step)\n",
            "INFO:tensorflow:global step 4430: loss = 0.6036 (1.783 sec/step)\n",
            "I0503 01:39:44.681284 140519389960064 learning.py:507] global step 4430: loss = 0.6036 (1.783 sec/step)\n",
            "INFO:tensorflow:global step 4431: loss = 0.7568 (0.914 sec/step)\n",
            "I0503 01:39:45.596714 140519389960064 learning.py:507] global step 4431: loss = 0.7568 (0.914 sec/step)\n",
            "INFO:tensorflow:global step 4432: loss = 0.9645 (0.735 sec/step)\n",
            "I0503 01:39:46.387560 140519389960064 learning.py:507] global step 4432: loss = 0.9645 (0.735 sec/step)\n",
            "INFO:tensorflow:global step 4433: loss = 0.8821 (0.944 sec/step)\n",
            "I0503 01:39:47.421044 140519389960064 learning.py:507] global step 4433: loss = 0.8821 (0.944 sec/step)\n",
            "INFO:tensorflow:global step 4434: loss = 0.7869 (0.950 sec/step)\n",
            "I0503 01:39:48.372749 140519389960064 learning.py:507] global step 4434: loss = 0.7869 (0.950 sec/step)\n",
            "INFO:tensorflow:global step 4435: loss = 1.0347 (0.778 sec/step)\n",
            "I0503 01:39:49.282350 140519389960064 learning.py:507] global step 4435: loss = 1.0347 (0.778 sec/step)\n",
            "INFO:tensorflow:global step 4436: loss = 0.7517 (0.961 sec/step)\n",
            "I0503 01:39:50.246191 140519389960064 learning.py:507] global step 4436: loss = 0.7517 (0.961 sec/step)\n",
            "INFO:tensorflow:global step 4437: loss = 0.8025 (0.798 sec/step)\n",
            "I0503 01:39:51.045893 140519389960064 learning.py:507] global step 4437: loss = 0.8025 (0.798 sec/step)\n",
            "INFO:tensorflow:global step 4438: loss = 0.8552 (0.854 sec/step)\n",
            "I0503 01:39:51.901746 140519389960064 learning.py:507] global step 4438: loss = 0.8552 (0.854 sec/step)\n",
            "INFO:tensorflow:global step 4439: loss = 0.7390 (0.867 sec/step)\n",
            "I0503 01:39:52.770708 140519389960064 learning.py:507] global step 4439: loss = 0.7390 (0.867 sec/step)\n",
            "INFO:tensorflow:global step 4440: loss = 0.6240 (0.781 sec/step)\n",
            "I0503 01:39:53.552849 140519389960064 learning.py:507] global step 4440: loss = 0.6240 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 4441: loss = 0.8896 (0.766 sec/step)\n",
            "I0503 01:39:54.320637 140519389960064 learning.py:507] global step 4441: loss = 0.8896 (0.766 sec/step)\n",
            "INFO:tensorflow:global step 4442: loss = 0.6542 (0.854 sec/step)\n",
            "I0503 01:39:55.176346 140519389960064 learning.py:507] global step 4442: loss = 0.6542 (0.854 sec/step)\n",
            "INFO:tensorflow:global step 4443: loss = 0.8142 (0.715 sec/step)\n",
            "I0503 01:39:55.893097 140519389960064 learning.py:507] global step 4443: loss = 0.8142 (0.715 sec/step)\n",
            "INFO:tensorflow:global step 4444: loss = 0.9673 (0.899 sec/step)\n",
            "I0503 01:39:56.793401 140519389960064 learning.py:507] global step 4444: loss = 0.9673 (0.899 sec/step)\n",
            "INFO:tensorflow:global step 4445: loss = 0.7891 (0.852 sec/step)\n",
            "I0503 01:39:57.647341 140519389960064 learning.py:507] global step 4445: loss = 0.7891 (0.852 sec/step)\n",
            "INFO:tensorflow:global step 4446: loss = 0.8957 (0.859 sec/step)\n",
            "I0503 01:39:58.507940 140519389960064 learning.py:507] global step 4446: loss = 0.8957 (0.859 sec/step)\n",
            "INFO:tensorflow:global step 4447: loss = 0.6742 (0.767 sec/step)\n",
            "I0503 01:39:59.276708 140519389960064 learning.py:507] global step 4447: loss = 0.6742 (0.767 sec/step)\n",
            "INFO:tensorflow:global step 4448: loss = 0.8699 (0.881 sec/step)\n",
            "I0503 01:40:00.159615 140519389960064 learning.py:507] global step 4448: loss = 0.8699 (0.881 sec/step)\n",
            "INFO:tensorflow:global step 4449: loss = 0.9208 (0.784 sec/step)\n",
            "I0503 01:40:00.945423 140519389960064 learning.py:507] global step 4449: loss = 0.9208 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 4450: loss = 0.9621 (0.836 sec/step)\n",
            "I0503 01:40:01.782857 140519389960064 learning.py:507] global step 4450: loss = 0.9621 (0.836 sec/step)\n",
            "INFO:tensorflow:global step 4451: loss = 0.6892 (0.741 sec/step)\n",
            "I0503 01:40:02.525055 140519389960064 learning.py:507] global step 4451: loss = 0.6892 (0.741 sec/step)\n",
            "INFO:tensorflow:global step 4452: loss = 0.6848 (0.816 sec/step)\n",
            "I0503 01:40:03.343259 140519389960064 learning.py:507] global step 4452: loss = 0.6848 (0.816 sec/step)\n",
            "INFO:tensorflow:global step 4453: loss = 0.8139 (0.749 sec/step)\n",
            "I0503 01:40:04.093586 140519389960064 learning.py:507] global step 4453: loss = 0.8139 (0.749 sec/step)\n",
            "INFO:tensorflow:global step 4454: loss = 0.7322 (0.790 sec/step)\n",
            "I0503 01:40:04.886622 140519389960064 learning.py:507] global step 4454: loss = 0.7322 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 4455: loss = 1.0752 (0.832 sec/step)\n",
            "I0503 01:40:05.719824 140519389960064 learning.py:507] global step 4455: loss = 1.0752 (0.832 sec/step)\n",
            "INFO:tensorflow:global step 4456: loss = 0.7428 (0.816 sec/step)\n",
            "I0503 01:40:06.537756 140519389960064 learning.py:507] global step 4456: loss = 0.7428 (0.816 sec/step)\n",
            "INFO:tensorflow:global step 4457: loss = 0.7840 (0.738 sec/step)\n",
            "I0503 01:40:07.277107 140519389960064 learning.py:507] global step 4457: loss = 0.7840 (0.738 sec/step)\n",
            "INFO:tensorflow:global step 4458: loss = 0.7525 (0.712 sec/step)\n",
            "I0503 01:40:07.991237 140519389960064 learning.py:507] global step 4458: loss = 0.7525 (0.712 sec/step)\n",
            "INFO:tensorflow:global step 4459: loss = 1.1557 (1.097 sec/step)\n",
            "I0503 01:40:09.091142 140519389960064 learning.py:507] global step 4459: loss = 1.1557 (1.097 sec/step)\n",
            "INFO:tensorflow:global step 4460: loss = 0.6583 (0.967 sec/step)\n",
            "I0503 01:40:10.059345 140519389960064 learning.py:507] global step 4460: loss = 0.6583 (0.967 sec/step)\n",
            "INFO:tensorflow:global step 4461: loss = 0.8697 (0.905 sec/step)\n",
            "I0503 01:40:10.965517 140519389960064 learning.py:507] global step 4461: loss = 0.8697 (0.905 sec/step)\n",
            "INFO:tensorflow:global step 4462: loss = 0.7968 (0.842 sec/step)\n",
            "I0503 01:40:11.809128 140519389960064 learning.py:507] global step 4462: loss = 0.7968 (0.842 sec/step)\n",
            "INFO:tensorflow:global step 4463: loss = 0.7044 (0.977 sec/step)\n",
            "I0503 01:40:12.787456 140519389960064 learning.py:507] global step 4463: loss = 0.7044 (0.977 sec/step)\n",
            "INFO:tensorflow:global step 4464: loss = 1.0076 (0.853 sec/step)\n",
            "I0503 01:40:13.642283 140519389960064 learning.py:507] global step 4464: loss = 1.0076 (0.853 sec/step)\n",
            "INFO:tensorflow:global step 4465: loss = 0.8170 (0.773 sec/step)\n",
            "I0503 01:40:14.416993 140519389960064 learning.py:507] global step 4465: loss = 0.8170 (0.773 sec/step)\n",
            "INFO:tensorflow:global step 4466: loss = 0.8939 (0.809 sec/step)\n",
            "I0503 01:40:15.227942 140519389960064 learning.py:507] global step 4466: loss = 0.8939 (0.809 sec/step)\n",
            "INFO:tensorflow:global step 4467: loss = 1.0139 (0.882 sec/step)\n",
            "I0503 01:40:16.111539 140519389960064 learning.py:507] global step 4467: loss = 1.0139 (0.882 sec/step)\n",
            "INFO:tensorflow:global step 4468: loss = 0.7110 (0.827 sec/step)\n",
            "I0503 01:40:16.940112 140519389960064 learning.py:507] global step 4468: loss = 0.7110 (0.827 sec/step)\n",
            "INFO:tensorflow:global step 4469: loss = 0.8065 (0.878 sec/step)\n",
            "I0503 01:40:17.820107 140519389960064 learning.py:507] global step 4469: loss = 0.8065 (0.878 sec/step)\n",
            "INFO:tensorflow:global step 4470: loss = 0.7147 (0.792 sec/step)\n",
            "I0503 01:40:18.613682 140519389960064 learning.py:507] global step 4470: loss = 0.7147 (0.792 sec/step)\n",
            "INFO:tensorflow:global step 4471: loss = 0.7560 (0.778 sec/step)\n",
            "I0503 01:40:19.394081 140519389960064 learning.py:507] global step 4471: loss = 0.7560 (0.778 sec/step)\n",
            "INFO:tensorflow:global step 4472: loss = 0.7794 (0.781 sec/step)\n",
            "I0503 01:40:20.176520 140519389960064 learning.py:507] global step 4472: loss = 0.7794 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 4473: loss = 0.7977 (0.880 sec/step)\n",
            "I0503 01:40:21.058694 140519389960064 learning.py:507] global step 4473: loss = 0.7977 (0.880 sec/step)\n",
            "INFO:tensorflow:global step 4474: loss = 0.6980 (0.909 sec/step)\n",
            "I0503 01:40:21.968839 140519389960064 learning.py:507] global step 4474: loss = 0.6980 (0.909 sec/step)\n",
            "INFO:tensorflow:global step 4475: loss = 0.9712 (0.866 sec/step)\n",
            "I0503 01:40:22.836899 140519389960064 learning.py:507] global step 4475: loss = 0.9712 (0.866 sec/step)\n",
            "INFO:tensorflow:global step 4476: loss = 0.6655 (0.879 sec/step)\n",
            "I0503 01:40:23.719190 140519389960064 learning.py:507] global step 4476: loss = 0.6655 (0.879 sec/step)\n",
            "INFO:tensorflow:global step 4477: loss = 0.6571 (0.692 sec/step)\n",
            "I0503 01:40:24.412750 140519389960064 learning.py:507] global step 4477: loss = 0.6571 (0.692 sec/step)\n",
            "INFO:tensorflow:global step 4478: loss = 0.6221 (0.829 sec/step)\n",
            "I0503 01:40:25.242995 140519389960064 learning.py:507] global step 4478: loss = 0.6221 (0.829 sec/step)\n",
            "INFO:tensorflow:global step 4479: loss = 0.7639 (0.767 sec/step)\n",
            "I0503 01:40:26.011852 140519389960064 learning.py:507] global step 4479: loss = 0.7639 (0.767 sec/step)\n",
            "INFO:tensorflow:global step 4480: loss = 0.9008 (0.780 sec/step)\n",
            "I0503 01:40:26.862170 140519389960064 learning.py:507] global step 4480: loss = 0.9008 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 4481: loss = 0.8864 (0.940 sec/step)\n",
            "I0503 01:40:27.805559 140519389960064 learning.py:507] global step 4481: loss = 0.8864 (0.940 sec/step)\n",
            "INFO:tensorflow:global step 4482: loss = 0.7927 (0.785 sec/step)\n",
            "I0503 01:40:28.591950 140519389960064 learning.py:507] global step 4482: loss = 0.7927 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 4483: loss = 0.8169 (0.709 sec/step)\n",
            "I0503 01:40:29.345943 140519389960064 learning.py:507] global step 4483: loss = 0.8169 (0.709 sec/step)\n",
            "INFO:tensorflow:global step 4484: loss = 0.7270 (0.888 sec/step)\n",
            "I0503 01:40:30.238501 140519389960064 learning.py:507] global step 4484: loss = 0.7270 (0.888 sec/step)\n",
            "INFO:tensorflow:global step 4485: loss = 0.7964 (0.758 sec/step)\n",
            "I0503 01:40:30.997796 140519389960064 learning.py:507] global step 4485: loss = 0.7964 (0.758 sec/step)\n",
            "INFO:tensorflow:global step 4486: loss = 0.7913 (0.801 sec/step)\n",
            "I0503 01:40:31.861112 140519389960064 learning.py:507] global step 4486: loss = 0.7913 (0.801 sec/step)\n",
            "INFO:tensorflow:global step 4487: loss = 0.8700 (0.898 sec/step)\n",
            "I0503 01:40:32.765329 140519389960064 learning.py:507] global step 4487: loss = 0.8700 (0.898 sec/step)\n",
            "INFO:tensorflow:global step 4488: loss = 1.1885 (0.933 sec/step)\n",
            "I0503 01:40:33.700074 140519389960064 learning.py:507] global step 4488: loss = 1.1885 (0.933 sec/step)\n",
            "INFO:tensorflow:global step 4489: loss = 0.6639 (0.718 sec/step)\n",
            "I0503 01:40:34.419630 140519389960064 learning.py:507] global step 4489: loss = 0.6639 (0.718 sec/step)\n",
            "INFO:tensorflow:global step 4490: loss = 0.6671 (1.236 sec/step)\n",
            "I0503 01:40:35.657407 140519389960064 learning.py:507] global step 4490: loss = 0.6671 (1.236 sec/step)\n",
            "INFO:tensorflow:global step 4491: loss = 0.7577 (0.746 sec/step)\n",
            "I0503 01:40:36.405237 140519389960064 learning.py:507] global step 4491: loss = 0.7577 (0.746 sec/step)\n",
            "INFO:tensorflow:global step 4492: loss = 0.6770 (0.814 sec/step)\n",
            "I0503 01:40:37.220481 140519389960064 learning.py:507] global step 4492: loss = 0.6770 (0.814 sec/step)\n",
            "INFO:tensorflow:global step 4493: loss = 0.6500 (0.807 sec/step)\n",
            "I0503 01:40:38.029175 140519389960064 learning.py:507] global step 4493: loss = 0.6500 (0.807 sec/step)\n",
            "INFO:tensorflow:global step 4494: loss = 0.7370 (0.912 sec/step)\n",
            "I0503 01:40:38.943102 140519389960064 learning.py:507] global step 4494: loss = 0.7370 (0.912 sec/step)\n",
            "INFO:tensorflow:global step 4495: loss = 0.6723 (0.927 sec/step)\n",
            "I0503 01:40:39.872256 140519389960064 learning.py:507] global step 4495: loss = 0.6723 (0.927 sec/step)\n",
            "INFO:tensorflow:global step 4496: loss = 0.9875 (0.713 sec/step)\n",
            "I0503 01:40:40.586732 140519389960064 learning.py:507] global step 4496: loss = 0.9875 (0.713 sec/step)\n",
            "INFO:tensorflow:global step 4497: loss = 0.8222 (0.832 sec/step)\n",
            "I0503 01:40:41.421735 140519389960064 learning.py:507] global step 4497: loss = 0.8222 (0.832 sec/step)\n",
            "INFO:tensorflow:global step 4498: loss = 1.0058 (0.725 sec/step)\n",
            "I0503 01:40:42.148857 140519389960064 learning.py:507] global step 4498: loss = 1.0058 (0.725 sec/step)\n",
            "INFO:tensorflow:global step 4499: loss = 0.9204 (0.725 sec/step)\n",
            "I0503 01:40:42.891178 140519389960064 learning.py:507] global step 4499: loss = 0.9204 (0.725 sec/step)\n",
            "INFO:tensorflow:global step 4500: loss = 0.7317 (0.848 sec/step)\n",
            "I0503 01:40:43.831925 140519389960064 learning.py:507] global step 4500: loss = 0.7317 (0.848 sec/step)\n",
            "INFO:tensorflow:global step 4501: loss = 0.7574 (0.956 sec/step)\n",
            "I0503 01:40:44.789984 140519389960064 learning.py:507] global step 4501: loss = 0.7574 (0.956 sec/step)\n",
            "INFO:tensorflow:global step 4502: loss = 0.5275 (0.764 sec/step)\n",
            "I0503 01:40:45.660439 140519389960064 learning.py:507] global step 4502: loss = 0.5275 (0.764 sec/step)\n",
            "INFO:tensorflow:global step 4503: loss = 0.6350 (0.890 sec/step)\n",
            "I0503 01:40:46.564274 140519389960064 learning.py:507] global step 4503: loss = 0.6350 (0.890 sec/step)\n",
            "INFO:tensorflow:global step 4504: loss = 0.6490 (0.773 sec/step)\n",
            "I0503 01:40:47.339312 140519389960064 learning.py:507] global step 4504: loss = 0.6490 (0.773 sec/step)\n",
            "INFO:tensorflow:global step 4505: loss = 0.6803 (0.814 sec/step)\n",
            "I0503 01:40:48.155109 140519389960064 learning.py:507] global step 4505: loss = 0.6803 (0.814 sec/step)\n",
            "INFO:tensorflow:global step 4506: loss = 0.6492 (0.849 sec/step)\n",
            "I0503 01:40:49.005654 140519389960064 learning.py:507] global step 4506: loss = 0.6492 (0.849 sec/step)\n",
            "INFO:tensorflow:global step 4507: loss = 0.6948 (0.745 sec/step)\n",
            "I0503 01:40:49.754993 140519389960064 learning.py:507] global step 4507: loss = 0.6948 (0.745 sec/step)\n",
            "INFO:tensorflow:global step 4508: loss = 0.6431 (0.842 sec/step)\n",
            "I0503 01:40:50.622633 140519389960064 learning.py:507] global step 4508: loss = 0.6431 (0.842 sec/step)\n",
            "INFO:tensorflow:global step 4509: loss = 0.6297 (0.862 sec/step)\n",
            "I0503 01:40:51.486201 140519389960064 learning.py:507] global step 4509: loss = 0.6297 (0.862 sec/step)\n",
            "INFO:tensorflow:global step 4510: loss = 0.8155 (0.853 sec/step)\n",
            "I0503 01:40:52.341219 140519389960064 learning.py:507] global step 4510: loss = 0.8155 (0.853 sec/step)\n",
            "INFO:tensorflow:global step 4511: loss = 0.7676 (0.814 sec/step)\n",
            "I0503 01:40:53.156447 140519389960064 learning.py:507] global step 4511: loss = 0.7676 (0.814 sec/step)\n",
            "INFO:tensorflow:global step 4512: loss = 0.8405 (0.823 sec/step)\n",
            "I0503 01:40:53.982336 140519389960064 learning.py:507] global step 4512: loss = 0.8405 (0.823 sec/step)\n",
            "INFO:tensorflow:global step 4513: loss = 0.8989 (0.830 sec/step)\n",
            "I0503 01:40:54.813965 140519389960064 learning.py:507] global step 4513: loss = 0.8989 (0.830 sec/step)\n",
            "INFO:tensorflow:global step 4514: loss = 0.7640 (0.714 sec/step)\n",
            "I0503 01:40:55.530034 140519389960064 learning.py:507] global step 4514: loss = 0.7640 (0.714 sec/step)\n",
            "INFO:tensorflow:global step 4515: loss = 0.7248 (0.791 sec/step)\n",
            "I0503 01:40:56.323118 140519389960064 learning.py:507] global step 4515: loss = 0.7248 (0.791 sec/step)\n",
            "INFO:tensorflow:global step 4516: loss = 0.7674 (0.754 sec/step)\n",
            "I0503 01:40:57.079084 140519389960064 learning.py:507] global step 4516: loss = 0.7674 (0.754 sec/step)\n",
            "INFO:tensorflow:global step 4517: loss = 0.6485 (0.857 sec/step)\n",
            "I0503 01:40:57.937432 140519389960064 learning.py:507] global step 4517: loss = 0.6485 (0.857 sec/step)\n",
            "INFO:tensorflow:global step 4518: loss = 1.1137 (0.901 sec/step)\n",
            "I0503 01:40:58.839956 140519389960064 learning.py:507] global step 4518: loss = 1.1137 (0.901 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 4519.\n",
            "I0503 01:41:00.311246 140515676296960 supervisor.py:1050] Recording summary at step 4519.\n",
            "INFO:tensorflow:global step 4519: loss = 0.8892 (1.467 sec/step)\n",
            "I0503 01:41:00.316798 140519389960064 learning.py:507] global step 4519: loss = 0.8892 (1.467 sec/step)\n",
            "INFO:tensorflow:global step 4520: loss = 0.6467 (0.773 sec/step)\n",
            "I0503 01:41:01.092896 140519389960064 learning.py:507] global step 4520: loss = 0.6467 (0.773 sec/step)\n",
            "INFO:tensorflow:global step 4521: loss = 0.8268 (0.802 sec/step)\n",
            "I0503 01:41:01.896499 140519389960064 learning.py:507] global step 4521: loss = 0.8268 (0.802 sec/step)\n",
            "INFO:tensorflow:global step 4522: loss = 0.8037 (0.830 sec/step)\n",
            "I0503 01:41:02.728302 140519389960064 learning.py:507] global step 4522: loss = 0.8037 (0.830 sec/step)\n",
            "INFO:tensorflow:global_step/sec: 1.17567\n",
            "I0503 01:41:02.881667 140515684689664 supervisor.py:1099] global_step/sec: 1.17567\n",
            "INFO:tensorflow:global step 4523: loss = 0.7523 (0.887 sec/step)\n",
            "I0503 01:41:03.617594 140519389960064 learning.py:507] global step 4523: loss = 0.7523 (0.887 sec/step)\n",
            "INFO:tensorflow:global step 4524: loss = 0.6512 (0.799 sec/step)\n",
            "I0503 01:41:04.417951 140519389960064 learning.py:507] global step 4524: loss = 0.6512 (0.799 sec/step)\n",
            "INFO:tensorflow:global step 4525: loss = 0.7864 (0.790 sec/step)\n",
            "I0503 01:41:05.209865 140519389960064 learning.py:507] global step 4525: loss = 0.7864 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 4526: loss = 0.7615 (0.851 sec/step)\n",
            "I0503 01:41:06.062407 140519389960064 learning.py:507] global step 4526: loss = 0.7615 (0.851 sec/step)\n",
            "INFO:tensorflow:global step 4527: loss = 0.6458 (0.865 sec/step)\n",
            "I0503 01:41:06.928810 140519389960064 learning.py:507] global step 4527: loss = 0.6458 (0.865 sec/step)\n",
            "INFO:tensorflow:global step 4528: loss = 0.5960 (0.799 sec/step)\n",
            "I0503 01:41:07.730095 140519389960064 learning.py:507] global step 4528: loss = 0.5960 (0.799 sec/step)\n",
            "INFO:tensorflow:global step 4529: loss = 0.7372 (0.842 sec/step)\n",
            "I0503 01:41:08.573970 140519389960064 learning.py:507] global step 4529: loss = 0.7372 (0.842 sec/step)\n",
            "INFO:tensorflow:global step 4530: loss = 1.0027 (0.743 sec/step)\n",
            "I0503 01:41:09.318555 140519389960064 learning.py:507] global step 4530: loss = 1.0027 (0.743 sec/step)\n",
            "INFO:tensorflow:global step 4531: loss = 0.7723 (0.940 sec/step)\n",
            "I0503 01:41:10.260163 140519389960064 learning.py:507] global step 4531: loss = 0.7723 (0.940 sec/step)\n",
            "INFO:tensorflow:global step 4532: loss = 0.8070 (0.834 sec/step)\n",
            "I0503 01:41:11.095630 140519389960064 learning.py:507] global step 4532: loss = 0.8070 (0.834 sec/step)\n",
            "INFO:tensorflow:global step 4533: loss = 0.8485 (0.773 sec/step)\n",
            "I0503 01:41:11.932176 140519389960064 learning.py:507] global step 4533: loss = 0.8485 (0.773 sec/step)\n",
            "INFO:tensorflow:global step 4534: loss = 0.7656 (0.891 sec/step)\n",
            "I0503 01:41:12.905659 140519389960064 learning.py:507] global step 4534: loss = 0.7656 (0.891 sec/step)\n",
            "INFO:tensorflow:global step 4535: loss = 0.7059 (0.819 sec/step)\n",
            "I0503 01:41:13.725710 140519389960064 learning.py:507] global step 4535: loss = 0.7059 (0.819 sec/step)\n",
            "INFO:tensorflow:global step 4536: loss = 0.7625 (0.920 sec/step)\n",
            "I0503 01:41:14.647550 140519389960064 learning.py:507] global step 4536: loss = 0.7625 (0.920 sec/step)\n",
            "INFO:tensorflow:global step 4537: loss = 0.7440 (0.720 sec/step)\n",
            "I0503 01:41:15.368756 140519389960064 learning.py:507] global step 4537: loss = 0.7440 (0.720 sec/step)\n",
            "INFO:tensorflow:global step 4538: loss = 0.6556 (0.907 sec/step)\n",
            "I0503 01:41:16.277885 140519389960064 learning.py:507] global step 4538: loss = 0.6556 (0.907 sec/step)\n",
            "INFO:tensorflow:global step 4539: loss = 0.6608 (0.901 sec/step)\n",
            "I0503 01:41:17.180437 140519389960064 learning.py:507] global step 4539: loss = 0.6608 (0.901 sec/step)\n",
            "INFO:tensorflow:global step 4540: loss = 0.6616 (0.872 sec/step)\n",
            "I0503 01:41:18.054436 140519389960064 learning.py:507] global step 4540: loss = 0.6616 (0.872 sec/step)\n",
            "INFO:tensorflow:global step 4541: loss = 0.7103 (0.773 sec/step)\n",
            "I0503 01:41:18.829587 140519389960064 learning.py:507] global step 4541: loss = 0.7103 (0.773 sec/step)\n",
            "INFO:tensorflow:global step 4542: loss = 0.7684 (0.813 sec/step)\n",
            "I0503 01:41:19.644793 140519389960064 learning.py:507] global step 4542: loss = 0.7684 (0.813 sec/step)\n",
            "INFO:tensorflow:global step 4543: loss = 0.7765 (0.839 sec/step)\n",
            "I0503 01:41:20.485368 140519389960064 learning.py:507] global step 4543: loss = 0.7765 (0.839 sec/step)\n",
            "INFO:tensorflow:global step 4544: loss = 0.8103 (0.833 sec/step)\n",
            "I0503 01:41:21.319673 140519389960064 learning.py:507] global step 4544: loss = 0.8103 (0.833 sec/step)\n",
            "INFO:tensorflow:global step 4545: loss = 0.6060 (0.891 sec/step)\n",
            "I0503 01:41:22.212297 140519389960064 learning.py:507] global step 4545: loss = 0.6060 (0.891 sec/step)\n",
            "INFO:tensorflow:global step 4546: loss = 0.6639 (0.895 sec/step)\n",
            "I0503 01:41:23.108984 140519389960064 learning.py:507] global step 4546: loss = 0.6639 (0.895 sec/step)\n",
            "INFO:tensorflow:global step 4547: loss = 0.7094 (0.777 sec/step)\n",
            "I0503 01:41:23.888430 140519389960064 learning.py:507] global step 4547: loss = 0.7094 (0.777 sec/step)\n",
            "INFO:tensorflow:global step 4548: loss = 0.6899 (0.895 sec/step)\n",
            "I0503 01:41:24.785181 140519389960064 learning.py:507] global step 4548: loss = 0.6899 (0.895 sec/step)\n",
            "INFO:tensorflow:global step 4549: loss = 0.7018 (0.801 sec/step)\n",
            "I0503 01:41:25.600238 140519389960064 learning.py:507] global step 4549: loss = 0.7018 (0.801 sec/step)\n",
            "INFO:tensorflow:global step 4550: loss = 1.0030 (0.762 sec/step)\n",
            "I0503 01:41:26.379369 140519389960064 learning.py:507] global step 4550: loss = 1.0030 (0.762 sec/step)\n",
            "INFO:tensorflow:global step 4551: loss = 0.7849 (1.073 sec/step)\n",
            "I0503 01:41:27.454999 140519389960064 learning.py:507] global step 4551: loss = 0.7849 (1.073 sec/step)\n",
            "INFO:tensorflow:global step 4552: loss = 0.6535 (0.984 sec/step)\n",
            "I0503 01:41:28.441498 140519389960064 learning.py:507] global step 4552: loss = 0.6535 (0.984 sec/step)\n",
            "INFO:tensorflow:global step 4553: loss = 0.6469 (0.823 sec/step)\n",
            "I0503 01:41:29.266467 140519389960064 learning.py:507] global step 4553: loss = 0.6469 (0.823 sec/step)\n",
            "INFO:tensorflow:global step 4554: loss = 0.6848 (0.773 sec/step)\n",
            "I0503 01:41:30.041145 140519389960064 learning.py:507] global step 4554: loss = 0.6848 (0.773 sec/step)\n",
            "INFO:tensorflow:global step 4555: loss = 0.6903 (0.785 sec/step)\n",
            "I0503 01:41:30.835156 140519389960064 learning.py:507] global step 4555: loss = 0.6903 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 4556: loss = 0.6549 (0.868 sec/step)\n",
            "I0503 01:41:31.707853 140519389960064 learning.py:507] global step 4556: loss = 0.6549 (0.868 sec/step)\n",
            "INFO:tensorflow:global step 4557: loss = 0.8333 (0.900 sec/step)\n",
            "I0503 01:41:32.615661 140519389960064 learning.py:507] global step 4557: loss = 0.8333 (0.900 sec/step)\n",
            "INFO:tensorflow:global step 4558: loss = 0.7157 (0.862 sec/step)\n",
            "I0503 01:41:33.479546 140519389960064 learning.py:507] global step 4558: loss = 0.7157 (0.862 sec/step)\n",
            "INFO:tensorflow:global step 4559: loss = 0.6510 (0.902 sec/step)\n",
            "I0503 01:41:34.383244 140519389960064 learning.py:507] global step 4559: loss = 0.6510 (0.902 sec/step)\n",
            "INFO:tensorflow:global step 4560: loss = 0.7904 (0.729 sec/step)\n",
            "I0503 01:41:35.114004 140519389960064 learning.py:507] global step 4560: loss = 0.7904 (0.729 sec/step)\n",
            "INFO:tensorflow:global step 4561: loss = 0.7549 (0.885 sec/step)\n",
            "I0503 01:41:36.000389 140519389960064 learning.py:507] global step 4561: loss = 0.7549 (0.885 sec/step)\n",
            "INFO:tensorflow:global step 4562: loss = 0.7963 (0.781 sec/step)\n",
            "I0503 01:41:36.783041 140519389960064 learning.py:507] global step 4562: loss = 0.7963 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 4563: loss = 1.0271 (0.851 sec/step)\n",
            "I0503 01:41:37.636790 140519389960064 learning.py:507] global step 4563: loss = 1.0271 (0.851 sec/step)\n",
            "INFO:tensorflow:global step 4564: loss = 0.8671 (0.810 sec/step)\n",
            "I0503 01:41:38.449101 140519389960064 learning.py:507] global step 4564: loss = 0.8671 (0.810 sec/step)\n",
            "INFO:tensorflow:global step 4565: loss = 0.6785 (0.860 sec/step)\n",
            "I0503 01:41:39.310913 140519389960064 learning.py:507] global step 4565: loss = 0.6785 (0.860 sec/step)\n",
            "INFO:tensorflow:global step 4566: loss = 0.7470 (0.650 sec/step)\n",
            "I0503 01:41:39.970502 140519389960064 learning.py:507] global step 4566: loss = 0.7470 (0.650 sec/step)\n",
            "INFO:tensorflow:global step 4567: loss = 0.8564 (0.845 sec/step)\n",
            "I0503 01:41:40.857075 140519389960064 learning.py:507] global step 4567: loss = 0.8564 (0.845 sec/step)\n",
            "INFO:tensorflow:global step 4568: loss = 1.1975 (0.806 sec/step)\n",
            "I0503 01:41:41.664537 140519389960064 learning.py:507] global step 4568: loss = 1.1975 (0.806 sec/step)\n",
            "INFO:tensorflow:global step 4569: loss = 0.9790 (0.857 sec/step)\n",
            "I0503 01:41:42.522720 140519389960064 learning.py:507] global step 4569: loss = 0.9790 (0.857 sec/step)\n",
            "INFO:tensorflow:global step 4570: loss = 0.6614 (0.791 sec/step)\n",
            "I0503 01:41:43.315533 140519389960064 learning.py:507] global step 4570: loss = 0.6614 (0.791 sec/step)\n",
            "INFO:tensorflow:global step 4571: loss = 0.8822 (0.811 sec/step)\n",
            "I0503 01:41:44.127634 140519389960064 learning.py:507] global step 4571: loss = 0.8822 (0.811 sec/step)\n",
            "INFO:tensorflow:global step 4572: loss = 0.7634 (0.884 sec/step)\n",
            "I0503 01:41:45.013032 140519389960064 learning.py:507] global step 4572: loss = 0.7634 (0.884 sec/step)\n",
            "INFO:tensorflow:global step 4573: loss = 0.9202 (0.786 sec/step)\n",
            "I0503 01:41:45.800550 140519389960064 learning.py:507] global step 4573: loss = 0.9202 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 4574: loss = 0.6019 (0.849 sec/step)\n",
            "I0503 01:41:46.650921 140519389960064 learning.py:507] global step 4574: loss = 0.6019 (0.849 sec/step)\n",
            "INFO:tensorflow:global step 4575: loss = 0.7875 (0.823 sec/step)\n",
            "I0503 01:41:47.475753 140519389960064 learning.py:507] global step 4575: loss = 0.7875 (0.823 sec/step)\n",
            "INFO:tensorflow:global step 4576: loss = 0.7728 (0.852 sec/step)\n",
            "I0503 01:41:48.329200 140519389960064 learning.py:507] global step 4576: loss = 0.7728 (0.852 sec/step)\n",
            "INFO:tensorflow:global step 4577: loss = 0.7325 (0.790 sec/step)\n",
            "I0503 01:41:49.120415 140519389960064 learning.py:507] global step 4577: loss = 0.7325 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 4578: loss = 0.8323 (0.893 sec/step)\n",
            "I0503 01:41:50.015576 140519389960064 learning.py:507] global step 4578: loss = 0.8323 (0.893 sec/step)\n",
            "INFO:tensorflow:global step 4579: loss = 0.6520 (0.903 sec/step)\n",
            "I0503 01:41:50.920075 140519389960064 learning.py:507] global step 4579: loss = 0.6520 (0.903 sec/step)\n",
            "INFO:tensorflow:global step 4580: loss = 0.7404 (0.906 sec/step)\n",
            "I0503 01:41:51.828130 140519389960064 learning.py:507] global step 4580: loss = 0.7404 (0.906 sec/step)\n",
            "INFO:tensorflow:global step 4581: loss = 0.6908 (0.835 sec/step)\n",
            "I0503 01:41:52.664354 140519389960064 learning.py:507] global step 4581: loss = 0.6908 (0.835 sec/step)\n",
            "INFO:tensorflow:global step 4582: loss = 0.7354 (0.870 sec/step)\n",
            "I0503 01:41:53.536120 140519389960064 learning.py:507] global step 4582: loss = 0.7354 (0.870 sec/step)\n",
            "INFO:tensorflow:global step 4583: loss = 0.8165 (0.828 sec/step)\n",
            "I0503 01:41:54.365809 140519389960064 learning.py:507] global step 4583: loss = 0.8165 (0.828 sec/step)\n",
            "INFO:tensorflow:global step 4584: loss = 0.7866 (0.777 sec/step)\n",
            "I0503 01:41:55.143886 140519389960064 learning.py:507] global step 4584: loss = 0.7866 (0.777 sec/step)\n",
            "INFO:tensorflow:global step 4585: loss = 0.6015 (0.718 sec/step)\n",
            "I0503 01:41:55.863750 140519389960064 learning.py:507] global step 4585: loss = 0.6015 (0.718 sec/step)\n",
            "INFO:tensorflow:global step 4586: loss = 0.6383 (0.895 sec/step)\n",
            "I0503 01:41:56.760178 140519389960064 learning.py:507] global step 4586: loss = 0.6383 (0.895 sec/step)\n",
            "INFO:tensorflow:global step 4587: loss = 0.8185 (0.680 sec/step)\n",
            "I0503 01:41:57.441599 140519389960064 learning.py:507] global step 4587: loss = 0.8185 (0.680 sec/step)\n",
            "INFO:tensorflow:global step 4588: loss = 0.8715 (0.888 sec/step)\n",
            "I0503 01:41:58.331134 140519389960064 learning.py:507] global step 4588: loss = 0.8715 (0.888 sec/step)\n",
            "INFO:tensorflow:global step 4589: loss = 0.8823 (0.847 sec/step)\n",
            "I0503 01:41:59.179929 140519389960064 learning.py:507] global step 4589: loss = 0.8823 (0.847 sec/step)\n",
            "INFO:tensorflow:global step 4590: loss = 1.0300 (0.775 sec/step)\n",
            "I0503 01:41:59.957551 140519389960064 learning.py:507] global step 4590: loss = 1.0300 (0.775 sec/step)\n",
            "INFO:tensorflow:global step 4591: loss = 0.6729 (0.823 sec/step)\n",
            "I0503 01:42:00.783447 140519389960064 learning.py:507] global step 4591: loss = 0.6729 (0.823 sec/step)\n",
            "INFO:tensorflow:global step 4592: loss = 0.8685 (0.754 sec/step)\n",
            "I0503 01:42:01.539597 140519389960064 learning.py:507] global step 4592: loss = 0.8685 (0.754 sec/step)\n",
            "INFO:tensorflow:global step 4593: loss = 0.8140 (0.765 sec/step)\n",
            "I0503 01:42:02.306597 140519389960064 learning.py:507] global step 4593: loss = 0.8140 (0.765 sec/step)\n",
            "INFO:tensorflow:global step 4594: loss = 0.7357 (0.830 sec/step)\n",
            "I0503 01:42:03.138651 140519389960064 learning.py:507] global step 4594: loss = 0.7357 (0.830 sec/step)\n",
            "INFO:tensorflow:global step 4595: loss = 0.8491 (0.940 sec/step)\n",
            "I0503 01:42:04.080372 140519389960064 learning.py:507] global step 4595: loss = 0.8491 (0.940 sec/step)\n",
            "INFO:tensorflow:global step 4596: loss = 0.6686 (0.860 sec/step)\n",
            "I0503 01:42:04.941910 140519389960064 learning.py:507] global step 4596: loss = 0.6686 (0.860 sec/step)\n",
            "INFO:tensorflow:global step 4597: loss = 0.8547 (0.837 sec/step)\n",
            "I0503 01:42:05.780530 140519389960064 learning.py:507] global step 4597: loss = 0.8547 (0.837 sec/step)\n",
            "INFO:tensorflow:global step 4598: loss = 0.8848 (0.836 sec/step)\n",
            "I0503 01:42:06.618497 140519389960064 learning.py:507] global step 4598: loss = 0.8848 (0.836 sec/step)\n",
            "INFO:tensorflow:global step 4599: loss = 0.7993 (0.816 sec/step)\n",
            "I0503 01:42:07.435705 140519389960064 learning.py:507] global step 4599: loss = 0.7993 (0.816 sec/step)\n",
            "INFO:tensorflow:global step 4600: loss = 0.9531 (0.649 sec/step)\n",
            "I0503 01:42:08.102711 140519389960064 learning.py:507] global step 4600: loss = 0.9531 (0.649 sec/step)\n",
            "INFO:tensorflow:global step 4601: loss = 0.9989 (0.913 sec/step)\n",
            "I0503 01:42:09.017505 140519389960064 learning.py:507] global step 4601: loss = 0.9989 (0.913 sec/step)\n",
            "INFO:tensorflow:global step 4602: loss = 0.6854 (0.907 sec/step)\n",
            "I0503 01:42:09.926226 140519389960064 learning.py:507] global step 4602: loss = 0.6854 (0.907 sec/step)\n",
            "INFO:tensorflow:global step 4603: loss = 1.1831 (0.856 sec/step)\n",
            "I0503 01:42:10.783352 140519389960064 learning.py:507] global step 4603: loss = 1.1831 (0.856 sec/step)\n",
            "INFO:tensorflow:global step 4604: loss = 0.7735 (0.757 sec/step)\n",
            "I0503 01:42:11.541967 140519389960064 learning.py:507] global step 4604: loss = 0.7735 (0.757 sec/step)\n",
            "INFO:tensorflow:global step 4605: loss = 0.5721 (0.883 sec/step)\n",
            "I0503 01:42:12.426173 140519389960064 learning.py:507] global step 4605: loss = 0.5721 (0.883 sec/step)\n",
            "INFO:tensorflow:global step 4606: loss = 0.6722 (0.888 sec/step)\n",
            "I0503 01:42:13.315828 140519389960064 learning.py:507] global step 4606: loss = 0.6722 (0.888 sec/step)\n",
            "INFO:tensorflow:global step 4607: loss = 0.8360 (0.893 sec/step)\n",
            "I0503 01:42:14.211071 140519389960064 learning.py:507] global step 4607: loss = 0.8360 (0.893 sec/step)\n",
            "INFO:tensorflow:global step 4608: loss = 0.8992 (0.895 sec/step)\n",
            "I0503 01:42:15.108231 140519389960064 learning.py:507] global step 4608: loss = 0.8992 (0.895 sec/step)\n",
            "INFO:tensorflow:global step 4609: loss = 0.7406 (0.708 sec/step)\n",
            "I0503 01:42:15.941372 140519389960064 learning.py:507] global step 4609: loss = 0.7406 (0.708 sec/step)\n",
            "INFO:tensorflow:global step 4610: loss = 0.7755 (0.933 sec/step)\n",
            "I0503 01:42:16.949642 140519389960064 learning.py:507] global step 4610: loss = 0.7755 (0.933 sec/step)\n",
            "INFO:tensorflow:global step 4611: loss = 1.0008 (0.927 sec/step)\n",
            "I0503 01:42:17.878894 140519389960064 learning.py:507] global step 4611: loss = 1.0008 (0.927 sec/step)\n",
            "INFO:tensorflow:global step 4612: loss = 0.5673 (0.776 sec/step)\n",
            "I0503 01:42:18.726866 140519389960064 learning.py:507] global step 4612: loss = 0.5673 (0.776 sec/step)\n",
            "INFO:tensorflow:global step 4613: loss = 1.0231 (0.920 sec/step)\n",
            "I0503 01:42:19.652613 140519389960064 learning.py:507] global step 4613: loss = 1.0231 (0.920 sec/step)\n",
            "INFO:tensorflow:global step 4614: loss = 0.5840 (0.853 sec/step)\n",
            "I0503 01:42:20.507072 140519389960064 learning.py:507] global step 4614: loss = 0.5840 (0.853 sec/step)\n",
            "INFO:tensorflow:global step 4615: loss = 0.5839 (0.927 sec/step)\n",
            "I0503 01:42:21.435598 140519389960064 learning.py:507] global step 4615: loss = 0.5839 (0.927 sec/step)\n",
            "INFO:tensorflow:global step 4616: loss = 0.7266 (0.785 sec/step)\n",
            "I0503 01:42:22.268306 140519389960064 learning.py:507] global step 4616: loss = 0.7266 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 4617: loss = 0.7202 (0.877 sec/step)\n",
            "I0503 01:42:23.148011 140519389960064 learning.py:507] global step 4617: loss = 0.7202 (0.877 sec/step)\n",
            "INFO:tensorflow:global step 4618: loss = 0.6512 (0.908 sec/step)\n",
            "I0503 01:42:24.058078 140519389960064 learning.py:507] global step 4618: loss = 0.6512 (0.908 sec/step)\n",
            "INFO:tensorflow:global step 4619: loss = 0.8336 (0.714 sec/step)\n",
            "I0503 01:42:24.816102 140519389960064 learning.py:507] global step 4619: loss = 0.8336 (0.714 sec/step)\n",
            "INFO:tensorflow:global step 4620: loss = 0.5808 (0.675 sec/step)\n",
            "I0503 01:42:25.594787 140519389960064 learning.py:507] global step 4620: loss = 0.5808 (0.675 sec/step)\n",
            "INFO:tensorflow:global step 4621: loss = 1.0207 (0.926 sec/step)\n",
            "I0503 01:42:26.522511 140519389960064 learning.py:507] global step 4621: loss = 1.0207 (0.926 sec/step)\n",
            "INFO:tensorflow:global step 4622: loss = 0.9613 (0.858 sec/step)\n",
            "I0503 01:42:27.431086 140519389960064 learning.py:507] global step 4622: loss = 0.9613 (0.858 sec/step)\n",
            "INFO:tensorflow:global step 4623: loss = 0.7330 (0.877 sec/step)\n",
            "I0503 01:42:28.310225 140519389960064 learning.py:507] global step 4623: loss = 0.7330 (0.877 sec/step)\n",
            "INFO:tensorflow:global step 4624: loss = 0.7875 (0.797 sec/step)\n",
            "I0503 01:42:29.109105 140519389960064 learning.py:507] global step 4624: loss = 0.7875 (0.797 sec/step)\n",
            "INFO:tensorflow:global step 4625: loss = 0.6587 (0.774 sec/step)\n",
            "I0503 01:42:29.972549 140519389960064 learning.py:507] global step 4625: loss = 0.6587 (0.774 sec/step)\n",
            "INFO:tensorflow:global step 4626: loss = 0.7663 (0.844 sec/step)\n",
            "I0503 01:42:30.819147 140519389960064 learning.py:507] global step 4626: loss = 0.7663 (0.844 sec/step)\n",
            "INFO:tensorflow:global step 4627: loss = 0.7079 (0.839 sec/step)\n",
            "I0503 01:42:31.674345 140519389960064 learning.py:507] global step 4627: loss = 0.7079 (0.839 sec/step)\n",
            "INFO:tensorflow:global step 4628: loss = 0.9210 (0.924 sec/step)\n",
            "I0503 01:42:32.600199 140519389960064 learning.py:507] global step 4628: loss = 0.9210 (0.924 sec/step)\n",
            "INFO:tensorflow:global step 4629: loss = 0.8253 (0.827 sec/step)\n",
            "I0503 01:42:33.428454 140519389960064 learning.py:507] global step 4629: loss = 0.8253 (0.827 sec/step)\n",
            "INFO:tensorflow:global step 4630: loss = 1.1741 (0.766 sec/step)\n",
            "I0503 01:42:34.196599 140519389960064 learning.py:507] global step 4630: loss = 1.1741 (0.766 sec/step)\n",
            "INFO:tensorflow:global step 4631: loss = 0.6749 (0.936 sec/step)\n",
            "I0503 01:42:35.134788 140519389960064 learning.py:507] global step 4631: loss = 0.6749 (0.936 sec/step)\n",
            "INFO:tensorflow:global step 4632: loss = 0.7311 (0.793 sec/step)\n",
            "I0503 01:42:35.929947 140519389960064 learning.py:507] global step 4632: loss = 0.7311 (0.793 sec/step)\n",
            "INFO:tensorflow:global step 4633: loss = 0.6697 (0.938 sec/step)\n",
            "I0503 01:42:36.869353 140519389960064 learning.py:507] global step 4633: loss = 0.6697 (0.938 sec/step)\n",
            "INFO:tensorflow:global step 4634: loss = 0.5241 (0.899 sec/step)\n",
            "I0503 01:42:37.770021 140519389960064 learning.py:507] global step 4634: loss = 0.5241 (0.899 sec/step)\n",
            "INFO:tensorflow:global step 4635: loss = 0.8036 (0.679 sec/step)\n",
            "I0503 01:42:38.451230 140519389960064 learning.py:507] global step 4635: loss = 0.8036 (0.679 sec/step)\n",
            "INFO:tensorflow:global step 4636: loss = 0.5586 (1.988 sec/step)\n",
            "I0503 01:42:40.441127 140519389960064 learning.py:507] global step 4636: loss = 0.5586 (1.988 sec/step)\n",
            "INFO:tensorflow:global step 4637: loss = 0.6459 (0.860 sec/step)\n",
            "I0503 01:42:41.303121 140519389960064 learning.py:507] global step 4637: loss = 0.6459 (0.860 sec/step)\n",
            "INFO:tensorflow:global step 4638: loss = 0.7553 (0.791 sec/step)\n",
            "I0503 01:42:42.095741 140519389960064 learning.py:507] global step 4638: loss = 0.7553 (0.791 sec/step)\n",
            "INFO:tensorflow:global step 4639: loss = 0.7702 (1.396 sec/step)\n",
            "I0503 01:42:43.493983 140519389960064 learning.py:507] global step 4639: loss = 0.7702 (1.396 sec/step)\n",
            "INFO:tensorflow:global step 4640: loss = 0.6536 (0.977 sec/step)\n",
            "I0503 01:42:44.473051 140519389960064 learning.py:507] global step 4640: loss = 0.6536 (0.977 sec/step)\n",
            "INFO:tensorflow:global step 4641: loss = 0.7818 (0.749 sec/step)\n",
            "I0503 01:42:45.305156 140519389960064 learning.py:507] global step 4641: loss = 0.7818 (0.749 sec/step)\n",
            "INFO:tensorflow:global step 4642: loss = 0.6407 (0.925 sec/step)\n",
            "I0503 01:42:46.233763 140519389960064 learning.py:507] global step 4642: loss = 0.6407 (0.925 sec/step)\n",
            "INFO:tensorflow:global step 4643: loss = 0.7255 (0.854 sec/step)\n",
            "I0503 01:42:47.089510 140519389960064 learning.py:507] global step 4643: loss = 0.7255 (0.854 sec/step)\n",
            "INFO:tensorflow:global step 4644: loss = 0.7681 (0.859 sec/step)\n",
            "I0503 01:42:47.950200 140519389960064 learning.py:507] global step 4644: loss = 0.7681 (0.859 sec/step)\n",
            "INFO:tensorflow:global step 4645: loss = 0.6181 (0.821 sec/step)\n",
            "I0503 01:42:48.772615 140519389960064 learning.py:507] global step 4645: loss = 0.6181 (0.821 sec/step)\n",
            "INFO:tensorflow:global step 4646: loss = 0.6513 (0.893 sec/step)\n",
            "I0503 01:42:49.667635 140519389960064 learning.py:507] global step 4646: loss = 0.6513 (0.893 sec/step)\n",
            "INFO:tensorflow:global step 4647: loss = 1.0686 (0.889 sec/step)\n",
            "I0503 01:42:50.558589 140519389960064 learning.py:507] global step 4647: loss = 1.0686 (0.889 sec/step)\n",
            "INFO:tensorflow:global step 4648: loss = 0.5922 (0.915 sec/step)\n",
            "I0503 01:42:51.475478 140519389960064 learning.py:507] global step 4648: loss = 0.5922 (0.915 sec/step)\n",
            "INFO:tensorflow:global step 4649: loss = 0.7989 (0.746 sec/step)\n",
            "I0503 01:42:52.224467 140519389960064 learning.py:507] global step 4649: loss = 0.7989 (0.746 sec/step)\n",
            "INFO:tensorflow:global step 4650: loss = 0.6909 (0.795 sec/step)\n",
            "I0503 01:42:53.021309 140519389960064 learning.py:507] global step 4650: loss = 0.6909 (0.795 sec/step)\n",
            "INFO:tensorflow:global step 4651: loss = 0.5278 (0.817 sec/step)\n",
            "I0503 01:42:53.840011 140519389960064 learning.py:507] global step 4651: loss = 0.5278 (0.817 sec/step)\n",
            "INFO:tensorflow:global step 4652: loss = 0.7483 (0.839 sec/step)\n",
            "I0503 01:42:54.683458 140519389960064 learning.py:507] global step 4652: loss = 0.7483 (0.839 sec/step)\n",
            "INFO:tensorflow:global step 4653: loss = 0.7795 (0.868 sec/step)\n",
            "I0503 01:42:55.553588 140519389960064 learning.py:507] global step 4653: loss = 0.7795 (0.868 sec/step)\n",
            "INFO:tensorflow:global step 4654: loss = 0.8791 (0.740 sec/step)\n",
            "I0503 01:42:56.294825 140519389960064 learning.py:507] global step 4654: loss = 0.8791 (0.740 sec/step)\n",
            "INFO:tensorflow:global step 4655: loss = 0.6969 (0.765 sec/step)\n",
            "I0503 01:42:57.061133 140519389960064 learning.py:507] global step 4655: loss = 0.6969 (0.765 sec/step)\n",
            "INFO:tensorflow:global step 4656: loss = 0.7530 (0.756 sec/step)\n",
            "I0503 01:42:57.818948 140519389960064 learning.py:507] global step 4656: loss = 0.7530 (0.756 sec/step)\n",
            "INFO:tensorflow:global step 4657: loss = 0.7611 (0.862 sec/step)\n",
            "I0503 01:42:58.682616 140519389960064 learning.py:507] global step 4657: loss = 0.7611 (0.862 sec/step)\n",
            "INFO:tensorflow:global step 4658: loss = 0.6386 (0.937 sec/step)\n",
            "I0503 01:42:59.888248 140519389960064 learning.py:507] global step 4658: loss = 0.6386 (0.937 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 4658.\n",
            "I0503 01:43:00.427707 140515676296960 supervisor.py:1050] Recording summary at step 4658.\n",
            "INFO:tensorflow:global step 4659: loss = 0.8323 (0.851 sec/step)\n",
            "I0503 01:43:00.818674 140519389960064 learning.py:507] global step 4659: loss = 0.8323 (0.851 sec/step)\n",
            "INFO:tensorflow:global step 4660: loss = 0.7740 (0.833 sec/step)\n",
            "I0503 01:43:01.652953 140519389960064 learning.py:507] global step 4660: loss = 0.7740 (0.833 sec/step)\n",
            "INFO:tensorflow:global step 4661: loss = 0.8297 (0.902 sec/step)\n",
            "I0503 01:43:02.557049 140519389960064 learning.py:507] global step 4661: loss = 0.8297 (0.902 sec/step)\n",
            "INFO:tensorflow:global_step/sec: 1.15813\n",
            "I0503 01:43:02.902438 140515684689664 supervisor.py:1099] global_step/sec: 1.15813\n",
            "INFO:tensorflow:global step 4662: loss = 0.7159 (0.756 sec/step)\n",
            "I0503 01:43:03.315069 140519389960064 learning.py:507] global step 4662: loss = 0.7159 (0.756 sec/step)\n",
            "INFO:tensorflow:global step 4663: loss = 0.7502 (0.737 sec/step)\n",
            "I0503 01:43:04.053885 140519389960064 learning.py:507] global step 4663: loss = 0.7502 (0.737 sec/step)\n",
            "INFO:tensorflow:global step 4664: loss = 0.6936 (0.758 sec/step)\n",
            "I0503 01:43:04.813322 140519389960064 learning.py:507] global step 4664: loss = 0.6936 (0.758 sec/step)\n",
            "INFO:tensorflow:global step 4665: loss = 1.2334 (0.686 sec/step)\n",
            "I0503 01:43:05.501029 140519389960064 learning.py:507] global step 4665: loss = 1.2334 (0.686 sec/step)\n",
            "INFO:tensorflow:global step 4666: loss = 0.7587 (1.143 sec/step)\n",
            "I0503 01:43:06.645462 140519389960064 learning.py:507] global step 4666: loss = 0.7587 (1.143 sec/step)\n",
            "INFO:tensorflow:global step 4667: loss = 0.7448 (0.883 sec/step)\n",
            "I0503 01:43:07.530673 140519389960064 learning.py:507] global step 4667: loss = 0.7448 (0.883 sec/step)\n",
            "INFO:tensorflow:global step 4668: loss = 0.7802 (0.785 sec/step)\n",
            "I0503 01:43:08.317274 140519389960064 learning.py:507] global step 4668: loss = 0.7802 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 4669: loss = 0.6728 (0.899 sec/step)\n",
            "I0503 01:43:09.217764 140519389960064 learning.py:507] global step 4669: loss = 0.6728 (0.899 sec/step)\n",
            "INFO:tensorflow:global step 4670: loss = 0.7529 (0.820 sec/step)\n",
            "I0503 01:43:10.039856 140519389960064 learning.py:507] global step 4670: loss = 0.7529 (0.820 sec/step)\n",
            "INFO:tensorflow:global step 4671: loss = 0.8577 (0.931 sec/step)\n",
            "I0503 01:43:10.972029 140519389960064 learning.py:507] global step 4671: loss = 0.8577 (0.931 sec/step)\n",
            "INFO:tensorflow:global step 4672: loss = 0.6510 (0.749 sec/step)\n",
            "I0503 01:43:11.722104 140519389960064 learning.py:507] global step 4672: loss = 0.6510 (0.749 sec/step)\n",
            "INFO:tensorflow:global step 4673: loss = 0.7784 (0.990 sec/step)\n",
            "I0503 01:43:12.714224 140519389960064 learning.py:507] global step 4673: loss = 0.7784 (0.990 sec/step)\n",
            "INFO:tensorflow:global step 4674: loss = 0.8020 (0.702 sec/step)\n",
            "I0503 01:43:13.418273 140519389960064 learning.py:507] global step 4674: loss = 0.8020 (0.702 sec/step)\n",
            "INFO:tensorflow:global step 4675: loss = 0.7490 (1.040 sec/step)\n",
            "I0503 01:43:14.460597 140519389960064 learning.py:507] global step 4675: loss = 0.7490 (1.040 sec/step)\n",
            "INFO:tensorflow:global step 4676: loss = 0.7019 (0.873 sec/step)\n",
            "I0503 01:43:15.334881 140519389960064 learning.py:507] global step 4676: loss = 0.7019 (0.873 sec/step)\n",
            "INFO:tensorflow:global step 4677: loss = 0.7084 (0.733 sec/step)\n",
            "I0503 01:43:16.072206 140519389960064 learning.py:507] global step 4677: loss = 0.7084 (0.733 sec/step)\n",
            "INFO:tensorflow:global step 4678: loss = 0.5974 (0.761 sec/step)\n",
            "I0503 01:43:16.877476 140519389960064 learning.py:507] global step 4678: loss = 0.5974 (0.761 sec/step)\n",
            "INFO:tensorflow:global step 4679: loss = 0.6852 (0.952 sec/step)\n",
            "I0503 01:43:17.830715 140519389960064 learning.py:507] global step 4679: loss = 0.6852 (0.952 sec/step)\n",
            "INFO:tensorflow:global step 4680: loss = 0.7082 (0.905 sec/step)\n",
            "I0503 01:43:18.737525 140519389960064 learning.py:507] global step 4680: loss = 0.7082 (0.905 sec/step)\n",
            "INFO:tensorflow:global step 4681: loss = 0.9792 (0.647 sec/step)\n",
            "I0503 01:43:19.393412 140519389960064 learning.py:507] global step 4681: loss = 0.9792 (0.647 sec/step)\n",
            "INFO:tensorflow:global step 4682: loss = 0.8492 (0.634 sec/step)\n",
            "I0503 01:43:20.031069 140519389960064 learning.py:507] global step 4682: loss = 0.8492 (0.634 sec/step)\n",
            "INFO:tensorflow:global step 4683: loss = 0.6614 (0.806 sec/step)\n",
            "I0503 01:43:20.838348 140519389960064 learning.py:507] global step 4683: loss = 0.6614 (0.806 sec/step)\n",
            "INFO:tensorflow:global step 4684: loss = 1.0150 (0.860 sec/step)\n",
            "I0503 01:43:21.700200 140519389960064 learning.py:507] global step 4684: loss = 1.0150 (0.860 sec/step)\n",
            "INFO:tensorflow:global step 4685: loss = 0.6474 (0.925 sec/step)\n",
            "I0503 01:43:22.626976 140519389960064 learning.py:507] global step 4685: loss = 0.6474 (0.925 sec/step)\n",
            "INFO:tensorflow:global step 4686: loss = 0.6826 (0.766 sec/step)\n",
            "I0503 01:43:23.394562 140519389960064 learning.py:507] global step 4686: loss = 0.6826 (0.766 sec/step)\n",
            "INFO:tensorflow:global step 4687: loss = 0.9411 (1.004 sec/step)\n",
            "I0503 01:43:24.400179 140519389960064 learning.py:507] global step 4687: loss = 0.9411 (1.004 sec/step)\n",
            "INFO:tensorflow:global step 4688: loss = 0.9656 (0.988 sec/step)\n",
            "I0503 01:43:25.389633 140519389960064 learning.py:507] global step 4688: loss = 0.9656 (0.988 sec/step)\n",
            "INFO:tensorflow:global step 4689: loss = 1.0799 (0.729 sec/step)\n",
            "I0503 01:43:26.155555 140519389960064 learning.py:507] global step 4689: loss = 1.0799 (0.729 sec/step)\n",
            "INFO:tensorflow:global step 4690: loss = 0.8072 (1.129 sec/step)\n",
            "I0503 01:43:27.301629 140519389960064 learning.py:507] global step 4690: loss = 0.8072 (1.129 sec/step)\n",
            "INFO:tensorflow:global step 4691: loss = 0.5708 (0.743 sec/step)\n",
            "I0503 01:43:28.113062 140519389960064 learning.py:507] global step 4691: loss = 0.5708 (0.743 sec/step)\n",
            "INFO:tensorflow:global step 4692: loss = 0.9208 (0.748 sec/step)\n",
            "I0503 01:43:28.968659 140519389960064 learning.py:507] global step 4692: loss = 0.9208 (0.748 sec/step)\n",
            "INFO:tensorflow:global step 4693: loss = 0.8304 (1.174 sec/step)\n",
            "I0503 01:43:30.145528 140519389960064 learning.py:507] global step 4693: loss = 0.8304 (1.174 sec/step)\n",
            "INFO:tensorflow:global step 4694: loss = 0.5262 (0.859 sec/step)\n",
            "I0503 01:43:31.006319 140519389960064 learning.py:507] global step 4694: loss = 0.5262 (0.859 sec/step)\n",
            "INFO:tensorflow:global step 4695: loss = 0.8590 (0.759 sec/step)\n",
            "I0503 01:43:31.805927 140519389960064 learning.py:507] global step 4695: loss = 0.8590 (0.759 sec/step)\n",
            "INFO:tensorflow:global step 4696: loss = 0.7425 (1.061 sec/step)\n",
            "I0503 01:43:32.868288 140519389960064 learning.py:507] global step 4696: loss = 0.7425 (1.061 sec/step)\n",
            "INFO:tensorflow:global step 4697: loss = 0.6315 (0.922 sec/step)\n",
            "I0503 01:43:33.791460 140519389960064 learning.py:507] global step 4697: loss = 0.6315 (0.922 sec/step)\n",
            "INFO:tensorflow:global step 4698: loss = 0.8026 (0.931 sec/step)\n",
            "I0503 01:43:34.724751 140519389960064 learning.py:507] global step 4698: loss = 0.8026 (0.931 sec/step)\n",
            "INFO:tensorflow:global step 4699: loss = 0.8327 (0.833 sec/step)\n",
            "I0503 01:43:35.559267 140519389960064 learning.py:507] global step 4699: loss = 0.8327 (0.833 sec/step)\n",
            "INFO:tensorflow:global step 4700: loss = 0.8508 (0.846 sec/step)\n",
            "I0503 01:43:36.406980 140519389960064 learning.py:507] global step 4700: loss = 0.8508 (0.846 sec/step)\n",
            "INFO:tensorflow:global step 4701: loss = 0.7564 (0.834 sec/step)\n",
            "I0503 01:43:37.243031 140519389960064 learning.py:507] global step 4701: loss = 0.7564 (0.834 sec/step)\n",
            "INFO:tensorflow:global step 4702: loss = 0.5639 (0.866 sec/step)\n",
            "I0503 01:43:38.110967 140519389960064 learning.py:507] global step 4702: loss = 0.5639 (0.866 sec/step)\n",
            "INFO:tensorflow:global step 4703: loss = 0.7936 (0.868 sec/step)\n",
            "I0503 01:43:38.980484 140519389960064 learning.py:507] global step 4703: loss = 0.7936 (0.868 sec/step)\n",
            "INFO:tensorflow:global step 4704: loss = 0.6948 (0.912 sec/step)\n",
            "I0503 01:43:39.893853 140519389960064 learning.py:507] global step 4704: loss = 0.6948 (0.912 sec/step)\n",
            "INFO:tensorflow:global step 4705: loss = 0.5834 (0.683 sec/step)\n",
            "I0503 01:43:40.579793 140519389960064 learning.py:507] global step 4705: loss = 0.5834 (0.683 sec/step)\n",
            "INFO:tensorflow:global step 4706: loss = 0.7285 (0.858 sec/step)\n",
            "I0503 01:43:41.440072 140519389960064 learning.py:507] global step 4706: loss = 0.7285 (0.858 sec/step)\n",
            "INFO:tensorflow:global step 4707: loss = 0.9675 (0.891 sec/step)\n",
            "I0503 01:43:42.333136 140519389960064 learning.py:507] global step 4707: loss = 0.9675 (0.891 sec/step)\n",
            "INFO:tensorflow:global step 4708: loss = 0.9139 (0.909 sec/step)\n",
            "I0503 01:43:43.243786 140519389960064 learning.py:507] global step 4708: loss = 0.9139 (0.909 sec/step)\n",
            "INFO:tensorflow:global step 4709: loss = 0.8329 (0.842 sec/step)\n",
            "I0503 01:43:44.087700 140519389960064 learning.py:507] global step 4709: loss = 0.8329 (0.842 sec/step)\n",
            "INFO:tensorflow:global step 4710: loss = 0.9136 (0.909 sec/step)\n",
            "I0503 01:43:44.998653 140519389960064 learning.py:507] global step 4710: loss = 0.9136 (0.909 sec/step)\n",
            "INFO:tensorflow:global step 4711: loss = 0.7716 (0.835 sec/step)\n",
            "I0503 01:43:45.857528 140519389960064 learning.py:507] global step 4711: loss = 0.7716 (0.835 sec/step)\n",
            "INFO:tensorflow:global step 4712: loss = 0.8109 (0.993 sec/step)\n",
            "I0503 01:43:46.942925 140519389960064 learning.py:507] global step 4712: loss = 0.8109 (0.993 sec/step)\n",
            "INFO:tensorflow:global step 4713: loss = 0.7798 (0.854 sec/step)\n",
            "I0503 01:43:47.798843 140519389960064 learning.py:507] global step 4713: loss = 0.7798 (0.854 sec/step)\n",
            "INFO:tensorflow:global step 4714: loss = 0.7609 (0.812 sec/step)\n",
            "I0503 01:43:48.612835 140519389960064 learning.py:507] global step 4714: loss = 0.7609 (0.812 sec/step)\n",
            "INFO:tensorflow:global step 4715: loss = 0.7636 (0.687 sec/step)\n",
            "I0503 01:43:49.301962 140519389960064 learning.py:507] global step 4715: loss = 0.7636 (0.687 sec/step)\n",
            "INFO:tensorflow:global step 4716: loss = 0.4935 (1.172 sec/step)\n",
            "I0503 01:43:50.475784 140519389960064 learning.py:507] global step 4716: loss = 0.4935 (1.172 sec/step)\n",
            "INFO:tensorflow:global step 4717: loss = 0.6767 (0.916 sec/step)\n",
            "I0503 01:43:51.393044 140519389960064 learning.py:507] global step 4717: loss = 0.6767 (0.916 sec/step)\n",
            "INFO:tensorflow:global step 4718: loss = 0.7054 (0.687 sec/step)\n",
            "I0503 01:43:52.121334 140519389960064 learning.py:507] global step 4718: loss = 0.7054 (0.687 sec/step)\n",
            "INFO:tensorflow:global step 4719: loss = 0.8609 (0.981 sec/step)\n",
            "I0503 01:43:53.104739 140519389960064 learning.py:507] global step 4719: loss = 0.8609 (0.981 sec/step)\n",
            "INFO:tensorflow:global step 4720: loss = 0.7596 (0.951 sec/step)\n",
            "I0503 01:43:54.058129 140519389960064 learning.py:507] global step 4720: loss = 0.7596 (0.951 sec/step)\n",
            "INFO:tensorflow:global step 4721: loss = 0.8864 (0.732 sec/step)\n",
            "I0503 01:43:54.824033 140519389960064 learning.py:507] global step 4721: loss = 0.8864 (0.732 sec/step)\n",
            "INFO:tensorflow:global step 4722: loss = 0.8266 (0.927 sec/step)\n",
            "I0503 01:43:55.774469 140519389960064 learning.py:507] global step 4722: loss = 0.8266 (0.927 sec/step)\n",
            "INFO:tensorflow:global step 4723: loss = 0.6811 (0.899 sec/step)\n",
            "I0503 01:43:56.674957 140519389960064 learning.py:507] global step 4723: loss = 0.6811 (0.899 sec/step)\n",
            "INFO:tensorflow:global step 4724: loss = 0.8108 (0.863 sec/step)\n",
            "I0503 01:43:57.539520 140519389960064 learning.py:507] global step 4724: loss = 0.8108 (0.863 sec/step)\n",
            "INFO:tensorflow:global step 4725: loss = 0.7565 (0.836 sec/step)\n",
            "I0503 01:43:58.377102 140519389960064 learning.py:507] global step 4725: loss = 0.7565 (0.836 sec/step)\n",
            "INFO:tensorflow:global step 4726: loss = 1.0532 (0.859 sec/step)\n",
            "I0503 01:43:59.237888 140519389960064 learning.py:507] global step 4726: loss = 1.0532 (0.859 sec/step)\n",
            "INFO:tensorflow:global step 4727: loss = 0.7154 (0.847 sec/step)\n",
            "I0503 01:44:00.086289 140519389960064 learning.py:507] global step 4727: loss = 0.7154 (0.847 sec/step)\n",
            "INFO:tensorflow:global step 4728: loss = 0.9080 (0.796 sec/step)\n",
            "I0503 01:44:00.884486 140519389960064 learning.py:507] global step 4728: loss = 0.9080 (0.796 sec/step)\n",
            "INFO:tensorflow:global step 4729: loss = 0.6372 (0.802 sec/step)\n",
            "I0503 01:44:01.688484 140519389960064 learning.py:507] global step 4729: loss = 0.6372 (0.802 sec/step)\n",
            "INFO:tensorflow:global step 4730: loss = 0.7131 (0.896 sec/step)\n",
            "I0503 01:44:02.585623 140519389960064 learning.py:507] global step 4730: loss = 0.7131 (0.896 sec/step)\n",
            "INFO:tensorflow:global step 4731: loss = 1.0302 (0.822 sec/step)\n",
            "I0503 01:44:03.409816 140519389960064 learning.py:507] global step 4731: loss = 1.0302 (0.822 sec/step)\n",
            "INFO:tensorflow:global step 4732: loss = 0.7724 (0.763 sec/step)\n",
            "I0503 01:44:04.208410 140519389960064 learning.py:507] global step 4732: loss = 0.7724 (0.763 sec/step)\n",
            "INFO:tensorflow:global step 4733: loss = 0.9314 (0.749 sec/step)\n",
            "I0503 01:44:04.959632 140519389960064 learning.py:507] global step 4733: loss = 0.9314 (0.749 sec/step)\n",
            "INFO:tensorflow:global step 4734: loss = 0.7579 (0.788 sec/step)\n",
            "I0503 01:44:05.748893 140519389960064 learning.py:507] global step 4734: loss = 0.7579 (0.788 sec/step)\n",
            "INFO:tensorflow:global step 4735: loss = 0.5769 (0.855 sec/step)\n",
            "I0503 01:44:06.606215 140519389960064 learning.py:507] global step 4735: loss = 0.5769 (0.855 sec/step)\n",
            "INFO:tensorflow:global step 4736: loss = 0.8620 (0.931 sec/step)\n",
            "I0503 01:44:07.539113 140519389960064 learning.py:507] global step 4736: loss = 0.8620 (0.931 sec/step)\n",
            "INFO:tensorflow:global step 4737: loss = 0.7525 (0.874 sec/step)\n",
            "I0503 01:44:08.414506 140519389960064 learning.py:507] global step 4737: loss = 0.7525 (0.874 sec/step)\n",
            "INFO:tensorflow:global step 4738: loss = 0.7729 (0.792 sec/step)\n",
            "I0503 01:44:09.208386 140519389960064 learning.py:507] global step 4738: loss = 0.7729 (0.792 sec/step)\n",
            "INFO:tensorflow:global step 4739: loss = 0.6969 (0.771 sec/step)\n",
            "I0503 01:44:09.980864 140519389960064 learning.py:507] global step 4739: loss = 0.6969 (0.771 sec/step)\n",
            "INFO:tensorflow:global step 4740: loss = 0.7707 (0.848 sec/step)\n",
            "I0503 01:44:10.830740 140519389960064 learning.py:507] global step 4740: loss = 0.7707 (0.848 sec/step)\n",
            "INFO:tensorflow:global step 4741: loss = 0.9016 (0.933 sec/step)\n",
            "I0503 01:44:11.765881 140519389960064 learning.py:507] global step 4741: loss = 0.9016 (0.933 sec/step)\n",
            "INFO:tensorflow:global step 4742: loss = 0.7721 (0.856 sec/step)\n",
            "I0503 01:44:12.623985 140519389960064 learning.py:507] global step 4742: loss = 0.7721 (0.856 sec/step)\n",
            "INFO:tensorflow:global step 4743: loss = 0.4894 (0.963 sec/step)\n",
            "I0503 01:44:13.588982 140519389960064 learning.py:507] global step 4743: loss = 0.4894 (0.963 sec/step)\n",
            "INFO:tensorflow:global step 4744: loss = 0.8637 (0.823 sec/step)\n",
            "I0503 01:44:14.414175 140519389960064 learning.py:507] global step 4744: loss = 0.8637 (0.823 sec/step)\n",
            "INFO:tensorflow:global step 4745: loss = 0.6620 (0.767 sec/step)\n",
            "I0503 01:44:15.183255 140519389960064 learning.py:507] global step 4745: loss = 0.6620 (0.767 sec/step)\n",
            "INFO:tensorflow:global step 4746: loss = 0.9977 (0.806 sec/step)\n",
            "I0503 01:44:15.991056 140519389960064 learning.py:507] global step 4746: loss = 0.9977 (0.806 sec/step)\n",
            "INFO:tensorflow:global step 4747: loss = 1.0680 (0.815 sec/step)\n",
            "I0503 01:44:16.807991 140519389960064 learning.py:507] global step 4747: loss = 1.0680 (0.815 sec/step)\n",
            "INFO:tensorflow:global step 4748: loss = 1.0127 (0.808 sec/step)\n",
            "I0503 01:44:17.617402 140519389960064 learning.py:507] global step 4748: loss = 1.0127 (0.808 sec/step)\n",
            "INFO:tensorflow:global step 4749: loss = 0.7700 (0.791 sec/step)\n",
            "I0503 01:44:18.409562 140519389960064 learning.py:507] global step 4749: loss = 0.7700 (0.791 sec/step)\n",
            "INFO:tensorflow:global step 4750: loss = 0.7886 (0.794 sec/step)\n",
            "I0503 01:44:19.204814 140519389960064 learning.py:507] global step 4750: loss = 0.7886 (0.794 sec/step)\n",
            "INFO:tensorflow:global step 4751: loss = 0.7332 (0.857 sec/step)\n",
            "I0503 01:44:20.064582 140519389960064 learning.py:507] global step 4751: loss = 0.7332 (0.857 sec/step)\n",
            "INFO:tensorflow:global step 4752: loss = 0.7460 (0.888 sec/step)\n",
            "I0503 01:44:20.954504 140519389960064 learning.py:507] global step 4752: loss = 0.7460 (0.888 sec/step)\n",
            "INFO:tensorflow:global step 4753: loss = 0.8351 (0.904 sec/step)\n",
            "I0503 01:44:21.860350 140519389960064 learning.py:507] global step 4753: loss = 0.8351 (0.904 sec/step)\n",
            "INFO:tensorflow:global step 4754: loss = 0.7101 (0.855 sec/step)\n",
            "I0503 01:44:22.717308 140519389960064 learning.py:507] global step 4754: loss = 0.7101 (0.855 sec/step)\n",
            "INFO:tensorflow:global step 4755: loss = 0.8068 (0.899 sec/step)\n",
            "I0503 01:44:23.617717 140519389960064 learning.py:507] global step 4755: loss = 0.8068 (0.899 sec/step)\n",
            "INFO:tensorflow:global step 4756: loss = 0.6321 (0.821 sec/step)\n",
            "I0503 01:44:24.440172 140519389960064 learning.py:507] global step 4756: loss = 0.6321 (0.821 sec/step)\n",
            "INFO:tensorflow:global step 4757: loss = 0.9221 (0.901 sec/step)\n",
            "I0503 01:44:25.342749 140519389960064 learning.py:507] global step 4757: loss = 0.9221 (0.901 sec/step)\n",
            "INFO:tensorflow:global step 4758: loss = 0.8144 (0.811 sec/step)\n",
            "I0503 01:44:26.156139 140519389960064 learning.py:507] global step 4758: loss = 0.8144 (0.811 sec/step)\n",
            "INFO:tensorflow:global step 4759: loss = 0.7329 (0.878 sec/step)\n",
            "I0503 01:44:27.037009 140519389960064 learning.py:507] global step 4759: loss = 0.7329 (0.878 sec/step)\n",
            "INFO:tensorflow:global step 4760: loss = 0.7068 (0.862 sec/step)\n",
            "I0503 01:44:27.900443 140519389960064 learning.py:507] global step 4760: loss = 0.7068 (0.862 sec/step)\n",
            "INFO:tensorflow:global step 4761: loss = 0.6279 (0.868 sec/step)\n",
            "I0503 01:44:28.770406 140519389960064 learning.py:507] global step 4761: loss = 0.6279 (0.868 sec/step)\n",
            "INFO:tensorflow:global step 4762: loss = 0.7320 (0.823 sec/step)\n",
            "I0503 01:44:29.594821 140519389960064 learning.py:507] global step 4762: loss = 0.7320 (0.823 sec/step)\n",
            "INFO:tensorflow:global step 4763: loss = 0.6880 (0.749 sec/step)\n",
            "I0503 01:44:30.345995 140519389960064 learning.py:507] global step 4763: loss = 0.6880 (0.749 sec/step)\n",
            "INFO:tensorflow:global step 4764: loss = 0.8962 (0.745 sec/step)\n",
            "I0503 01:44:31.093284 140519389960064 learning.py:507] global step 4764: loss = 0.8962 (0.745 sec/step)\n",
            "INFO:tensorflow:global step 4765: loss = 0.6372 (0.880 sec/step)\n",
            "I0503 01:44:31.974627 140519389960064 learning.py:507] global step 4765: loss = 0.6372 (0.880 sec/step)\n",
            "INFO:tensorflow:global step 4766: loss = 1.0416 (0.766 sec/step)\n",
            "I0503 01:44:32.742467 140519389960064 learning.py:507] global step 4766: loss = 1.0416 (0.766 sec/step)\n",
            "INFO:tensorflow:global step 4767: loss = 0.6563 (0.756 sec/step)\n",
            "I0503 01:44:33.500188 140519389960064 learning.py:507] global step 4767: loss = 0.6563 (0.756 sec/step)\n",
            "INFO:tensorflow:global step 4768: loss = 0.7807 (0.881 sec/step)\n",
            "I0503 01:44:34.382378 140519389960064 learning.py:507] global step 4768: loss = 0.7807 (0.881 sec/step)\n",
            "INFO:tensorflow:global step 4769: loss = 0.7819 (0.872 sec/step)\n",
            "I0503 01:44:35.255440 140519389960064 learning.py:507] global step 4769: loss = 0.7819 (0.872 sec/step)\n",
            "INFO:tensorflow:global step 4770: loss = 0.7660 (0.805 sec/step)\n",
            "I0503 01:44:36.062216 140519389960064 learning.py:507] global step 4770: loss = 0.7660 (0.805 sec/step)\n",
            "INFO:tensorflow:global step 4771: loss = 0.6767 (0.855 sec/step)\n",
            "I0503 01:44:36.918431 140519389960064 learning.py:507] global step 4771: loss = 0.6767 (0.855 sec/step)\n",
            "INFO:tensorflow:global step 4772: loss = 0.5492 (0.755 sec/step)\n",
            "I0503 01:44:37.674565 140519389960064 learning.py:507] global step 4772: loss = 0.5492 (0.755 sec/step)\n",
            "INFO:tensorflow:global step 4773: loss = 0.7325 (0.841 sec/step)\n",
            "I0503 01:44:38.516860 140519389960064 learning.py:507] global step 4773: loss = 0.7325 (0.841 sec/step)\n",
            "INFO:tensorflow:global step 4774: loss = 0.7641 (0.764 sec/step)\n",
            "I0503 01:44:39.282402 140519389960064 learning.py:507] global step 4774: loss = 0.7641 (0.764 sec/step)\n",
            "INFO:tensorflow:global step 4775: loss = 0.8474 (0.922 sec/step)\n",
            "I0503 01:44:40.206010 140519389960064 learning.py:507] global step 4775: loss = 0.8474 (0.922 sec/step)\n",
            "INFO:tensorflow:global step 4776: loss = 0.7800 (0.897 sec/step)\n",
            "I0503 01:44:41.104835 140519389960064 learning.py:507] global step 4776: loss = 0.7800 (0.897 sec/step)\n",
            "INFO:tensorflow:global step 4777: loss = 0.9648 (0.721 sec/step)\n",
            "I0503 01:44:41.827452 140519389960064 learning.py:507] global step 4777: loss = 0.9648 (0.721 sec/step)\n",
            "INFO:tensorflow:global step 4778: loss = 0.9412 (0.797 sec/step)\n",
            "I0503 01:44:42.625675 140519389960064 learning.py:507] global step 4778: loss = 0.9412 (0.797 sec/step)\n",
            "INFO:tensorflow:global step 4779: loss = 0.8698 (0.868 sec/step)\n",
            "I0503 01:44:43.495728 140519389960064 learning.py:507] global step 4779: loss = 0.8698 (0.868 sec/step)\n",
            "INFO:tensorflow:global step 4780: loss = 0.7817 (0.798 sec/step)\n",
            "I0503 01:44:44.295085 140519389960064 learning.py:507] global step 4780: loss = 0.7817 (0.798 sec/step)\n",
            "INFO:tensorflow:global step 4781: loss = 0.6321 (0.866 sec/step)\n",
            "I0503 01:44:45.162278 140519389960064 learning.py:507] global step 4781: loss = 0.6321 (0.866 sec/step)\n",
            "INFO:tensorflow:global step 4782: loss = 0.8973 (0.772 sec/step)\n",
            "I0503 01:44:45.936382 140519389960064 learning.py:507] global step 4782: loss = 0.8973 (0.772 sec/step)\n",
            "INFO:tensorflow:global step 4783: loss = 0.5890 (0.797 sec/step)\n",
            "I0503 01:44:46.735709 140519389960064 learning.py:507] global step 4783: loss = 0.5890 (0.797 sec/step)\n",
            "INFO:tensorflow:global step 4784: loss = 0.8706 (0.862 sec/step)\n",
            "I0503 01:44:47.599481 140519389960064 learning.py:507] global step 4784: loss = 0.8706 (0.862 sec/step)\n",
            "INFO:tensorflow:global step 4785: loss = 0.7530 (0.872 sec/step)\n",
            "I0503 01:44:48.473191 140519389960064 learning.py:507] global step 4785: loss = 0.7530 (0.872 sec/step)\n",
            "INFO:tensorflow:global step 4786: loss = 0.9434 (0.913 sec/step)\n",
            "I0503 01:44:49.387507 140519389960064 learning.py:507] global step 4786: loss = 0.9434 (0.913 sec/step)\n",
            "INFO:tensorflow:global step 4787: loss = 0.5553 (0.852 sec/step)\n",
            "I0503 01:44:50.241284 140519389960064 learning.py:507] global step 4787: loss = 0.5553 (0.852 sec/step)\n",
            "INFO:tensorflow:global step 4788: loss = 0.7869 (0.790 sec/step)\n",
            "I0503 01:44:51.032547 140519389960064 learning.py:507] global step 4788: loss = 0.7869 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 4789: loss = 0.7189 (0.833 sec/step)\n",
            "I0503 01:44:51.867017 140519389960064 learning.py:507] global step 4789: loss = 0.7189 (0.833 sec/step)\n",
            "INFO:tensorflow:global step 4790: loss = 0.6804 (0.750 sec/step)\n",
            "I0503 01:44:52.637433 140519389960064 learning.py:507] global step 4790: loss = 0.6804 (0.750 sec/step)\n",
            "INFO:tensorflow:global step 4791: loss = 0.8173 (0.837 sec/step)\n",
            "I0503 01:44:53.488516 140519389960064 learning.py:507] global step 4791: loss = 0.8173 (0.837 sec/step)\n",
            "INFO:tensorflow:global step 4792: loss = 0.9446 (0.893 sec/step)\n",
            "I0503 01:44:54.383001 140519389960064 learning.py:507] global step 4792: loss = 0.9446 (0.893 sec/step)\n",
            "INFO:tensorflow:global step 4793: loss = 0.7708 (0.848 sec/step)\n",
            "I0503 01:44:55.232844 140519389960064 learning.py:507] global step 4793: loss = 0.7708 (0.848 sec/step)\n",
            "INFO:tensorflow:global step 4794: loss = 0.7878 (0.740 sec/step)\n",
            "I0503 01:44:55.974630 140519389960064 learning.py:507] global step 4794: loss = 0.7878 (0.740 sec/step)\n",
            "INFO:tensorflow:global step 4795: loss = 1.0867 (0.879 sec/step)\n",
            "I0503 01:44:56.854727 140519389960064 learning.py:507] global step 4795: loss = 1.0867 (0.879 sec/step)\n",
            "INFO:tensorflow:global step 4796: loss = 0.8401 (0.831 sec/step)\n",
            "I0503 01:44:57.687579 140519389960064 learning.py:507] global step 4796: loss = 0.8401 (0.831 sec/step)\n",
            "INFO:tensorflow:global step 4797: loss = 0.7702 (0.825 sec/step)\n",
            "I0503 01:44:58.514892 140519389960064 learning.py:507] global step 4797: loss = 0.7702 (0.825 sec/step)\n",
            "INFO:tensorflow:global step 4798: loss = 0.8398 (1.169 sec/step)\n",
            "I0503 01:44:59.775485 140519389960064 learning.py:507] global step 4798: loss = 0.8398 (1.169 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 4798.\n",
            "I0503 01:45:00.431647 140515676296960 supervisor.py:1050] Recording summary at step 4798.\n",
            "INFO:tensorflow:global step 4799: loss = 0.7324 (1.000 sec/step)\n",
            "I0503 01:45:00.836730 140519389960064 learning.py:507] global step 4799: loss = 0.7324 (1.000 sec/step)\n",
            "INFO:tensorflow:global step 4800: loss = 0.5455 (0.797 sec/step)\n",
            "I0503 01:45:01.635567 140519389960064 learning.py:507] global step 4800: loss = 0.5455 (0.797 sec/step)\n",
            "INFO:tensorflow:global step 4801: loss = 0.6413 (0.834 sec/step)\n",
            "I0503 01:45:02.471190 140519389960064 learning.py:507] global step 4801: loss = 0.6413 (0.834 sec/step)\n",
            "INFO:tensorflow:global_step/sec: 1.16672\n",
            "I0503 01:45:02.896905 140515684689664 supervisor.py:1099] global_step/sec: 1.16672\n",
            "INFO:tensorflow:global step 4802: loss = 0.7389 (0.838 sec/step)\n",
            "I0503 01:45:03.310843 140519389960064 learning.py:507] global step 4802: loss = 0.7389 (0.838 sec/step)\n",
            "INFO:tensorflow:global step 4803: loss = 0.6792 (0.940 sec/step)\n",
            "I0503 01:45:04.252694 140519389960064 learning.py:507] global step 4803: loss = 0.6792 (0.940 sec/step)\n",
            "INFO:tensorflow:global step 4804: loss = 0.7312 (0.796 sec/step)\n",
            "I0503 01:45:05.049971 140519389960064 learning.py:507] global step 4804: loss = 0.7312 (0.796 sec/step)\n",
            "INFO:tensorflow:global step 4805: loss = 0.7338 (0.790 sec/step)\n",
            "I0503 01:45:05.841460 140519389960064 learning.py:507] global step 4805: loss = 0.7338 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 4806: loss = 0.6339 (0.948 sec/step)\n",
            "I0503 01:45:06.791425 140519389960064 learning.py:507] global step 4806: loss = 0.6339 (0.948 sec/step)\n",
            "INFO:tensorflow:global step 4807: loss = 1.0765 (0.757 sec/step)\n",
            "I0503 01:45:07.549972 140519389960064 learning.py:507] global step 4807: loss = 1.0765 (0.757 sec/step)\n",
            "INFO:tensorflow:global step 4808: loss = 0.7293 (0.827 sec/step)\n",
            "I0503 01:45:08.379159 140519389960064 learning.py:507] global step 4808: loss = 0.7293 (0.827 sec/step)\n",
            "INFO:tensorflow:global step 4809: loss = 0.7800 (0.941 sec/step)\n",
            "I0503 01:45:09.322227 140519389960064 learning.py:507] global step 4809: loss = 0.7800 (0.941 sec/step)\n",
            "INFO:tensorflow:global step 4810: loss = 0.8442 (0.827 sec/step)\n",
            "I0503 01:45:10.150582 140519389960064 learning.py:507] global step 4810: loss = 0.8442 (0.827 sec/step)\n",
            "INFO:tensorflow:global step 4811: loss = 0.6752 (0.811 sec/step)\n",
            "I0503 01:45:10.963703 140519389960064 learning.py:507] global step 4811: loss = 0.6752 (0.811 sec/step)\n",
            "INFO:tensorflow:global step 4812: loss = 1.0140 (0.829 sec/step)\n",
            "I0503 01:45:11.794666 140519389960064 learning.py:507] global step 4812: loss = 1.0140 (0.829 sec/step)\n",
            "INFO:tensorflow:global step 4813: loss = 0.6960 (0.864 sec/step)\n",
            "I0503 01:45:12.659899 140519389960064 learning.py:507] global step 4813: loss = 0.6960 (0.864 sec/step)\n",
            "INFO:tensorflow:global step 4814: loss = 0.6755 (0.842 sec/step)\n",
            "I0503 01:45:13.503574 140519389960064 learning.py:507] global step 4814: loss = 0.6755 (0.842 sec/step)\n",
            "INFO:tensorflow:global step 4815: loss = 0.8890 (0.811 sec/step)\n",
            "I0503 01:45:14.316558 140519389960064 learning.py:507] global step 4815: loss = 0.8890 (0.811 sec/step)\n",
            "INFO:tensorflow:global step 4816: loss = 0.5611 (0.831 sec/step)\n",
            "I0503 01:45:15.148836 140519389960064 learning.py:507] global step 4816: loss = 0.5611 (0.831 sec/step)\n",
            "INFO:tensorflow:global step 4817: loss = 1.0251 (0.817 sec/step)\n",
            "I0503 01:45:15.967696 140519389960064 learning.py:507] global step 4817: loss = 1.0251 (0.817 sec/step)\n",
            "INFO:tensorflow:global step 4818: loss = 0.8096 (0.764 sec/step)\n",
            "I0503 01:45:16.732728 140519389960064 learning.py:507] global step 4818: loss = 0.8096 (0.764 sec/step)\n",
            "INFO:tensorflow:global step 4819: loss = 0.7672 (0.861 sec/step)\n",
            "I0503 01:45:17.594989 140519389960064 learning.py:507] global step 4819: loss = 0.7672 (0.861 sec/step)\n",
            "INFO:tensorflow:global step 4820: loss = 0.6046 (0.816 sec/step)\n",
            "I0503 01:45:18.412263 140519389960064 learning.py:507] global step 4820: loss = 0.6046 (0.816 sec/step)\n",
            "INFO:tensorflow:global step 4821: loss = 0.6526 (0.731 sec/step)\n",
            "I0503 01:45:19.145038 140519389960064 learning.py:507] global step 4821: loss = 0.6526 (0.731 sec/step)\n",
            "INFO:tensorflow:global step 4822: loss = 0.9146 (0.927 sec/step)\n",
            "I0503 01:45:20.074149 140519389960064 learning.py:507] global step 4822: loss = 0.9146 (0.927 sec/step)\n",
            "INFO:tensorflow:global step 4823: loss = 0.8158 (0.775 sec/step)\n",
            "I0503 01:45:20.852270 140519389960064 learning.py:507] global step 4823: loss = 0.8158 (0.775 sec/step)\n",
            "INFO:tensorflow:global step 4824: loss = 0.6934 (0.790 sec/step)\n",
            "I0503 01:45:21.644813 140519389960064 learning.py:507] global step 4824: loss = 0.6934 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 4825: loss = 0.7105 (0.908 sec/step)\n",
            "I0503 01:45:22.554363 140519389960064 learning.py:507] global step 4825: loss = 0.7105 (0.908 sec/step)\n",
            "INFO:tensorflow:global step 4826: loss = 0.9313 (0.854 sec/step)\n",
            "I0503 01:45:23.410309 140519389960064 learning.py:507] global step 4826: loss = 0.9313 (0.854 sec/step)\n",
            "INFO:tensorflow:global step 4827: loss = 0.8291 (0.777 sec/step)\n",
            "I0503 01:45:24.189652 140519389960064 learning.py:507] global step 4827: loss = 0.8291 (0.777 sec/step)\n",
            "INFO:tensorflow:global step 4828: loss = 0.9224 (0.883 sec/step)\n",
            "I0503 01:45:25.074729 140519389960064 learning.py:507] global step 4828: loss = 0.9224 (0.883 sec/step)\n",
            "INFO:tensorflow:global step 4829: loss = 0.8332 (0.723 sec/step)\n",
            "I0503 01:45:25.799001 140519389960064 learning.py:507] global step 4829: loss = 0.8332 (0.723 sec/step)\n",
            "INFO:tensorflow:global step 4830: loss = 0.6783 (0.838 sec/step)\n",
            "I0503 01:45:26.638680 140519389960064 learning.py:507] global step 4830: loss = 0.6783 (0.838 sec/step)\n",
            "INFO:tensorflow:global step 4831: loss = 0.6127 (0.860 sec/step)\n",
            "I0503 01:45:27.500571 140519389960064 learning.py:507] global step 4831: loss = 0.6127 (0.860 sec/step)\n",
            "INFO:tensorflow:global step 4832: loss = 1.0558 (0.782 sec/step)\n",
            "I0503 01:45:28.283872 140519389960064 learning.py:507] global step 4832: loss = 1.0558 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 4833: loss = 1.0086 (0.824 sec/step)\n",
            "I0503 01:45:29.109197 140519389960064 learning.py:507] global step 4833: loss = 1.0086 (0.824 sec/step)\n",
            "INFO:tensorflow:global step 4834: loss = 0.7197 (0.826 sec/step)\n",
            "I0503 01:45:29.937184 140519389960064 learning.py:507] global step 4834: loss = 0.7197 (0.826 sec/step)\n",
            "INFO:tensorflow:global step 4835: loss = 0.6805 (0.926 sec/step)\n",
            "I0503 01:45:30.864996 140519389960064 learning.py:507] global step 4835: loss = 0.6805 (0.926 sec/step)\n",
            "INFO:tensorflow:global step 4836: loss = 0.6955 (0.852 sec/step)\n",
            "I0503 01:45:31.719166 140519389960064 learning.py:507] global step 4836: loss = 0.6955 (0.852 sec/step)\n",
            "INFO:tensorflow:global step 4837: loss = 0.6997 (0.790 sec/step)\n",
            "I0503 01:45:32.510552 140519389960064 learning.py:507] global step 4837: loss = 0.6997 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 4838: loss = 0.7356 (0.772 sec/step)\n",
            "I0503 01:45:33.283956 140519389960064 learning.py:507] global step 4838: loss = 0.7356 (0.772 sec/step)\n",
            "INFO:tensorflow:global step 4839: loss = 0.8976 (0.963 sec/step)\n",
            "I0503 01:45:34.248569 140519389960064 learning.py:507] global step 4839: loss = 0.8976 (0.963 sec/step)\n",
            "INFO:tensorflow:global step 4840: loss = 0.8341 (0.769 sec/step)\n",
            "I0503 01:45:35.081516 140519389960064 learning.py:507] global step 4840: loss = 0.8341 (0.769 sec/step)\n",
            "INFO:tensorflow:global step 4841: loss = 0.6884 (0.882 sec/step)\n",
            "I0503 01:45:36.018754 140519389960064 learning.py:507] global step 4841: loss = 0.6884 (0.882 sec/step)\n",
            "INFO:tensorflow:global step 4842: loss = 0.7906 (0.969 sec/step)\n",
            "I0503 01:45:36.989275 140519389960064 learning.py:507] global step 4842: loss = 0.7906 (0.969 sec/step)\n",
            "INFO:tensorflow:global step 4843: loss = 1.1051 (0.852 sec/step)\n",
            "I0503 01:45:37.843019 140519389960064 learning.py:507] global step 4843: loss = 1.1051 (0.852 sec/step)\n",
            "INFO:tensorflow:global step 4844: loss = 0.9822 (0.764 sec/step)\n",
            "I0503 01:45:38.608813 140519389960064 learning.py:507] global step 4844: loss = 0.9822 (0.764 sec/step)\n",
            "INFO:tensorflow:global step 4845: loss = 0.7070 (0.944 sec/step)\n",
            "I0503 01:45:39.554981 140519389960064 learning.py:507] global step 4845: loss = 0.7070 (0.944 sec/step)\n",
            "INFO:tensorflow:global step 4846: loss = 0.9139 (0.827 sec/step)\n",
            "I0503 01:45:40.422204 140519389960064 learning.py:507] global step 4846: loss = 0.9139 (0.827 sec/step)\n",
            "INFO:tensorflow:global step 4847: loss = 0.6805 (0.896 sec/step)\n",
            "I0503 01:45:41.336097 140519389960064 learning.py:507] global step 4847: loss = 0.6805 (0.896 sec/step)\n",
            "INFO:tensorflow:global step 4848: loss = 0.7687 (0.747 sec/step)\n",
            "I0503 01:45:42.141684 140519389960064 learning.py:507] global step 4848: loss = 0.7687 (0.747 sec/step)\n",
            "INFO:tensorflow:global step 4849: loss = 0.8067 (0.893 sec/step)\n",
            "I0503 01:45:43.036174 140519389960064 learning.py:507] global step 4849: loss = 0.8067 (0.893 sec/step)\n",
            "INFO:tensorflow:global step 4850: loss = 0.7258 (0.856 sec/step)\n",
            "I0503 01:45:43.894327 140519389960064 learning.py:507] global step 4850: loss = 0.7258 (0.856 sec/step)\n",
            "INFO:tensorflow:global step 4851: loss = 0.7041 (0.955 sec/step)\n",
            "I0503 01:45:44.850740 140519389960064 learning.py:507] global step 4851: loss = 0.7041 (0.955 sec/step)\n",
            "INFO:tensorflow:global step 4852: loss = 0.6073 (0.815 sec/step)\n",
            "I0503 01:45:45.667606 140519389960064 learning.py:507] global step 4852: loss = 0.6073 (0.815 sec/step)\n",
            "INFO:tensorflow:global step 4853: loss = 0.6006 (0.861 sec/step)\n",
            "I0503 01:45:46.530708 140519389960064 learning.py:507] global step 4853: loss = 0.6006 (0.861 sec/step)\n",
            "INFO:tensorflow:global step 4854: loss = 0.7557 (0.753 sec/step)\n",
            "I0503 01:45:47.299409 140519389960064 learning.py:507] global step 4854: loss = 0.7557 (0.753 sec/step)\n",
            "INFO:tensorflow:global step 4855: loss = 0.7192 (0.926 sec/step)\n",
            "I0503 01:45:48.227445 140519389960064 learning.py:507] global step 4855: loss = 0.7192 (0.926 sec/step)\n",
            "INFO:tensorflow:global step 4856: loss = 0.7126 (0.954 sec/step)\n",
            "I0503 01:45:49.183199 140519389960064 learning.py:507] global step 4856: loss = 0.7126 (0.954 sec/step)\n",
            "INFO:tensorflow:global step 4857: loss = 0.6646 (0.843 sec/step)\n",
            "I0503 01:45:50.027425 140519389960064 learning.py:507] global step 4857: loss = 0.6646 (0.843 sec/step)\n",
            "INFO:tensorflow:global step 4858: loss = 0.7478 (0.740 sec/step)\n",
            "I0503 01:45:50.835037 140519389960064 learning.py:507] global step 4858: loss = 0.7478 (0.740 sec/step)\n",
            "INFO:tensorflow:global step 4859: loss = 0.8904 (0.892 sec/step)\n",
            "I0503 01:45:51.730261 140519389960064 learning.py:507] global step 4859: loss = 0.8904 (0.892 sec/step)\n",
            "INFO:tensorflow:global step 4860: loss = 0.8095 (0.841 sec/step)\n",
            "I0503 01:45:52.572604 140519389960064 learning.py:507] global step 4860: loss = 0.8095 (0.841 sec/step)\n",
            "INFO:tensorflow:global step 4861: loss = 0.8507 (0.799 sec/step)\n",
            "I0503 01:45:53.373031 140519389960064 learning.py:507] global step 4861: loss = 0.8507 (0.799 sec/step)\n",
            "INFO:tensorflow:global step 4862: loss = 1.2588 (0.926 sec/step)\n",
            "I0503 01:45:54.300922 140519389960064 learning.py:507] global step 4862: loss = 1.2588 (0.926 sec/step)\n",
            "INFO:tensorflow:global step 4863: loss = 0.7841 (0.805 sec/step)\n",
            "I0503 01:45:55.107365 140519389960064 learning.py:507] global step 4863: loss = 0.7841 (0.805 sec/step)\n",
            "INFO:tensorflow:global step 4864: loss = 0.7256 (0.910 sec/step)\n",
            "I0503 01:45:56.020992 140519389960064 learning.py:507] global step 4864: loss = 0.7256 (0.910 sec/step)\n",
            "INFO:tensorflow:global step 4865: loss = 0.6655 (0.811 sec/step)\n",
            "I0503 01:45:56.834075 140519389960064 learning.py:507] global step 4865: loss = 0.6655 (0.811 sec/step)\n",
            "INFO:tensorflow:global step 4866: loss = 0.9802 (0.906 sec/step)\n",
            "I0503 01:45:57.741525 140519389960064 learning.py:507] global step 4866: loss = 0.9802 (0.906 sec/step)\n",
            "INFO:tensorflow:global step 4867: loss = 0.7065 (0.819 sec/step)\n",
            "I0503 01:45:58.564179 140519389960064 learning.py:507] global step 4867: loss = 0.7065 (0.819 sec/step)\n",
            "INFO:tensorflow:global step 4868: loss = 0.6763 (0.839 sec/step)\n",
            "I0503 01:45:59.404545 140519389960064 learning.py:507] global step 4868: loss = 0.6763 (0.839 sec/step)\n",
            "INFO:tensorflow:global step 4869: loss = 0.7531 (0.845 sec/step)\n",
            "I0503 01:46:00.251917 140519389960064 learning.py:507] global step 4869: loss = 0.7531 (0.845 sec/step)\n",
            "INFO:tensorflow:global step 4870: loss = 0.8372 (0.822 sec/step)\n",
            "I0503 01:46:01.075541 140519389960064 learning.py:507] global step 4870: loss = 0.8372 (0.822 sec/step)\n",
            "INFO:tensorflow:global step 4871: loss = 0.7457 (0.892 sec/step)\n",
            "I0503 01:46:01.969026 140519389960064 learning.py:507] global step 4871: loss = 0.7457 (0.892 sec/step)\n",
            "INFO:tensorflow:global step 4872: loss = 0.5724 (0.849 sec/step)\n",
            "I0503 01:46:02.820272 140519389960064 learning.py:507] global step 4872: loss = 0.5724 (0.849 sec/step)\n",
            "INFO:tensorflow:global step 4873: loss = 0.6639 (0.847 sec/step)\n",
            "I0503 01:46:03.669207 140519389960064 learning.py:507] global step 4873: loss = 0.6639 (0.847 sec/step)\n",
            "INFO:tensorflow:global step 4874: loss = 0.8850 (0.866 sec/step)\n",
            "I0503 01:46:04.536879 140519389960064 learning.py:507] global step 4874: loss = 0.8850 (0.866 sec/step)\n",
            "INFO:tensorflow:global step 4875: loss = 0.9311 (0.893 sec/step)\n",
            "I0503 01:46:05.431602 140519389960064 learning.py:507] global step 4875: loss = 0.9311 (0.893 sec/step)\n",
            "INFO:tensorflow:global step 4876: loss = 0.7795 (0.782 sec/step)\n",
            "I0503 01:46:06.214654 140519389960064 learning.py:507] global step 4876: loss = 0.7795 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 4877: loss = 0.7431 (0.796 sec/step)\n",
            "I0503 01:46:07.012096 140519389960064 learning.py:507] global step 4877: loss = 0.7431 (0.796 sec/step)\n",
            "INFO:tensorflow:global step 4878: loss = 0.7546 (0.841 sec/step)\n",
            "I0503 01:46:07.854946 140519389960064 learning.py:507] global step 4878: loss = 0.7546 (0.841 sec/step)\n",
            "INFO:tensorflow:global step 4879: loss = 0.6288 (0.882 sec/step)\n",
            "I0503 01:46:08.738671 140519389960064 learning.py:507] global step 4879: loss = 0.6288 (0.882 sec/step)\n",
            "INFO:tensorflow:global step 4880: loss = 0.6771 (0.859 sec/step)\n",
            "I0503 01:46:09.599790 140519389960064 learning.py:507] global step 4880: loss = 0.6771 (0.859 sec/step)\n",
            "INFO:tensorflow:global step 4881: loss = 0.7345 (0.865 sec/step)\n",
            "I0503 01:46:10.467866 140519389960064 learning.py:507] global step 4881: loss = 0.7345 (0.865 sec/step)\n",
            "INFO:tensorflow:global step 4882: loss = 0.7942 (0.796 sec/step)\n",
            "I0503 01:46:11.265799 140519389960064 learning.py:507] global step 4882: loss = 0.7942 (0.796 sec/step)\n",
            "INFO:tensorflow:global step 4883: loss = 0.7859 (0.894 sec/step)\n",
            "I0503 01:46:12.161670 140519389960064 learning.py:507] global step 4883: loss = 0.7859 (0.894 sec/step)\n",
            "INFO:tensorflow:global step 4884: loss = 0.7523 (0.813 sec/step)\n",
            "I0503 01:46:12.976378 140519389960064 learning.py:507] global step 4884: loss = 0.7523 (0.813 sec/step)\n",
            "INFO:tensorflow:global step 4885: loss = 0.7007 (0.881 sec/step)\n",
            "I0503 01:46:13.858846 140519389960064 learning.py:507] global step 4885: loss = 0.7007 (0.881 sec/step)\n",
            "INFO:tensorflow:global step 4886: loss = 0.6208 (0.897 sec/step)\n",
            "I0503 01:46:14.756926 140519389960064 learning.py:507] global step 4886: loss = 0.6208 (0.897 sec/step)\n",
            "INFO:tensorflow:global step 4887: loss = 0.6967 (0.769 sec/step)\n",
            "I0503 01:46:15.527256 140519389960064 learning.py:507] global step 4887: loss = 0.6967 (0.769 sec/step)\n",
            "INFO:tensorflow:global step 4888: loss = 0.8871 (0.743 sec/step)\n",
            "I0503 01:46:16.278003 140519389960064 learning.py:507] global step 4888: loss = 0.8871 (0.743 sec/step)\n",
            "INFO:tensorflow:global step 4889: loss = 0.8769 (0.844 sec/step)\n",
            "I0503 01:46:17.123476 140519389960064 learning.py:507] global step 4889: loss = 0.8769 (0.844 sec/step)\n",
            "INFO:tensorflow:global step 4890: loss = 0.8596 (0.769 sec/step)\n",
            "I0503 01:46:17.893949 140519389960064 learning.py:507] global step 4890: loss = 0.8596 (0.769 sec/step)\n",
            "INFO:tensorflow:global step 4891: loss = 1.4468 (0.814 sec/step)\n",
            "I0503 01:46:18.709635 140519389960064 learning.py:507] global step 4891: loss = 1.4468 (0.814 sec/step)\n",
            "INFO:tensorflow:global step 4892: loss = 0.6953 (0.801 sec/step)\n",
            "I0503 01:46:19.514515 140519389960064 learning.py:507] global step 4892: loss = 0.6953 (0.801 sec/step)\n",
            "INFO:tensorflow:global step 4893: loss = 0.6643 (0.805 sec/step)\n",
            "I0503 01:46:20.321151 140519389960064 learning.py:507] global step 4893: loss = 0.6643 (0.805 sec/step)\n",
            "INFO:tensorflow:global step 4894: loss = 0.7788 (0.866 sec/step)\n",
            "I0503 01:46:21.189529 140519389960064 learning.py:507] global step 4894: loss = 0.7788 (0.866 sec/step)\n",
            "INFO:tensorflow:global step 4895: loss = 0.6284 (0.765 sec/step)\n",
            "I0503 01:46:21.956595 140519389960064 learning.py:507] global step 4895: loss = 0.6284 (0.765 sec/step)\n",
            "INFO:tensorflow:global step 4896: loss = 0.6573 (0.663 sec/step)\n",
            "I0503 01:46:22.621311 140519389960064 learning.py:507] global step 4896: loss = 0.6573 (0.663 sec/step)\n",
            "INFO:tensorflow:global step 4897: loss = 0.6322 (0.863 sec/step)\n",
            "I0503 01:46:23.485976 140519389960064 learning.py:507] global step 4897: loss = 0.6322 (0.863 sec/step)\n",
            "INFO:tensorflow:global step 4898: loss = 0.8108 (0.918 sec/step)\n",
            "I0503 01:46:24.405564 140519389960064 learning.py:507] global step 4898: loss = 0.8108 (0.918 sec/step)\n",
            "INFO:tensorflow:global step 4899: loss = 0.8702 (0.607 sec/step)\n",
            "I0503 01:46:25.013849 140519389960064 learning.py:507] global step 4899: loss = 0.8702 (0.607 sec/step)\n",
            "INFO:tensorflow:global step 4900: loss = 0.7388 (0.849 sec/step)\n",
            "I0503 01:46:25.864624 140519389960064 learning.py:507] global step 4900: loss = 0.7388 (0.849 sec/step)\n",
            "INFO:tensorflow:global step 4901: loss = 0.7766 (0.807 sec/step)\n",
            "I0503 01:46:26.673039 140519389960064 learning.py:507] global step 4901: loss = 0.7766 (0.807 sec/step)\n",
            "INFO:tensorflow:global step 4902: loss = 0.6845 (0.887 sec/step)\n",
            "I0503 01:46:27.561895 140519389960064 learning.py:507] global step 4902: loss = 0.6845 (0.887 sec/step)\n",
            "INFO:tensorflow:global step 4903: loss = 0.8774 (0.756 sec/step)\n",
            "I0503 01:46:28.319331 140519389960064 learning.py:507] global step 4903: loss = 0.8774 (0.756 sec/step)\n",
            "INFO:tensorflow:global step 4904: loss = 0.8007 (0.671 sec/step)\n",
            "I0503 01:46:29.067939 140519389960064 learning.py:507] global step 4904: loss = 0.8007 (0.671 sec/step)\n",
            "INFO:tensorflow:global step 4905: loss = 0.8266 (1.057 sec/step)\n",
            "I0503 01:46:30.191696 140519389960064 learning.py:507] global step 4905: loss = 0.8266 (1.057 sec/step)\n",
            "INFO:tensorflow:global step 4906: loss = 0.5848 (0.868 sec/step)\n",
            "I0503 01:46:31.061315 140519389960064 learning.py:507] global step 4906: loss = 0.5848 (0.868 sec/step)\n",
            "INFO:tensorflow:global step 4907: loss = 0.7731 (0.742 sec/step)\n",
            "I0503 01:46:31.805475 140519389960064 learning.py:507] global step 4907: loss = 0.7731 (0.742 sec/step)\n",
            "INFO:tensorflow:global step 4908: loss = 0.7666 (1.212 sec/step)\n",
            "I0503 01:46:33.019032 140519389960064 learning.py:507] global step 4908: loss = 0.7666 (1.212 sec/step)\n",
            "INFO:tensorflow:global step 4909: loss = 0.7579 (0.908 sec/step)\n",
            "I0503 01:46:33.928492 140519389960064 learning.py:507] global step 4909: loss = 0.7579 (0.908 sec/step)\n",
            "INFO:tensorflow:global step 4910: loss = 0.6469 (0.805 sec/step)\n",
            "I0503 01:46:34.735688 140519389960064 learning.py:507] global step 4910: loss = 0.6469 (0.805 sec/step)\n",
            "INFO:tensorflow:global step 4911: loss = 0.6590 (0.907 sec/step)\n",
            "I0503 01:46:35.644122 140519389960064 learning.py:507] global step 4911: loss = 0.6590 (0.907 sec/step)\n",
            "INFO:tensorflow:global step 4912: loss = 1.2374 (0.793 sec/step)\n",
            "I0503 01:46:36.443975 140519389960064 learning.py:507] global step 4912: loss = 1.2374 (0.793 sec/step)\n",
            "INFO:tensorflow:global step 4913: loss = 0.6195 (0.850 sec/step)\n",
            "I0503 01:46:37.295511 140519389960064 learning.py:507] global step 4913: loss = 0.6195 (0.850 sec/step)\n",
            "INFO:tensorflow:global step 4914: loss = 0.7753 (0.903 sec/step)\n",
            "I0503 01:46:38.200730 140519389960064 learning.py:507] global step 4914: loss = 0.7753 (0.903 sec/step)\n",
            "INFO:tensorflow:global step 4915: loss = 0.8349 (0.780 sec/step)\n",
            "I0503 01:46:38.982283 140519389960064 learning.py:507] global step 4915: loss = 0.8349 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 4916: loss = 0.5517 (0.786 sec/step)\n",
            "I0503 01:46:39.854838 140519389960064 learning.py:507] global step 4916: loss = 0.5517 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 4917: loss = 0.7030 (0.866 sec/step)\n",
            "I0503 01:46:40.780478 140519389960064 learning.py:507] global step 4917: loss = 0.7030 (0.866 sec/step)\n",
            "INFO:tensorflow:global step 4918: loss = 0.8868 (0.831 sec/step)\n",
            "I0503 01:46:41.613826 140519389960064 learning.py:507] global step 4918: loss = 0.8868 (0.831 sec/step)\n",
            "INFO:tensorflow:global step 4919: loss = 0.8213 (0.788 sec/step)\n",
            "I0503 01:46:42.403182 140519389960064 learning.py:507] global step 4919: loss = 0.8213 (0.788 sec/step)\n",
            "INFO:tensorflow:global step 4920: loss = 0.6892 (0.877 sec/step)\n",
            "I0503 01:46:43.282375 140519389960064 learning.py:507] global step 4920: loss = 0.6892 (0.877 sec/step)\n",
            "INFO:tensorflow:global step 4921: loss = 0.7135 (0.896 sec/step)\n",
            "I0503 01:46:44.180112 140519389960064 learning.py:507] global step 4921: loss = 0.7135 (0.896 sec/step)\n",
            "INFO:tensorflow:global step 4922: loss = 0.6634 (0.851 sec/step)\n",
            "I0503 01:46:45.032562 140519389960064 learning.py:507] global step 4922: loss = 0.6634 (0.851 sec/step)\n",
            "INFO:tensorflow:global step 4923: loss = 0.7353 (0.774 sec/step)\n",
            "I0503 01:46:45.808637 140519389960064 learning.py:507] global step 4923: loss = 0.7353 (0.774 sec/step)\n",
            "INFO:tensorflow:global step 4924: loss = 0.6811 (0.679 sec/step)\n",
            "I0503 01:46:46.570359 140519389960064 learning.py:507] global step 4924: loss = 0.6811 (0.679 sec/step)\n",
            "INFO:tensorflow:global step 4925: loss = 0.7126 (0.702 sec/step)\n",
            "I0503 01:46:47.274844 140519389960064 learning.py:507] global step 4925: loss = 0.7126 (0.702 sec/step)\n",
            "INFO:tensorflow:global step 4926: loss = 0.7528 (1.000 sec/step)\n",
            "I0503 01:46:48.276993 140519389960064 learning.py:507] global step 4926: loss = 0.7528 (1.000 sec/step)\n",
            "INFO:tensorflow:global step 4927: loss = 0.6429 (0.710 sec/step)\n",
            "I0503 01:46:48.989052 140519389960064 learning.py:507] global step 4927: loss = 0.6429 (0.710 sec/step)\n",
            "INFO:tensorflow:global step 4928: loss = 0.6074 (1.602 sec/step)\n",
            "I0503 01:46:50.593524 140519389960064 learning.py:507] global step 4928: loss = 0.6074 (1.602 sec/step)\n",
            "INFO:tensorflow:global step 4929: loss = 0.8762 (0.826 sec/step)\n",
            "I0503 01:46:51.421066 140519389960064 learning.py:507] global step 4929: loss = 0.8762 (0.826 sec/step)\n",
            "INFO:tensorflow:global step 4930: loss = 0.7311 (0.906 sec/step)\n",
            "I0503 01:46:52.330024 140519389960064 learning.py:507] global step 4930: loss = 0.7311 (0.906 sec/step)\n",
            "INFO:tensorflow:global step 4931: loss = 0.7425 (0.846 sec/step)\n",
            "I0503 01:46:53.184853 140519389960064 learning.py:507] global step 4931: loss = 0.7425 (0.846 sec/step)\n",
            "INFO:tensorflow:global step 4932: loss = 0.7422 (0.884 sec/step)\n",
            "I0503 01:46:54.070107 140519389960064 learning.py:507] global step 4932: loss = 0.7422 (0.884 sec/step)\n",
            "INFO:tensorflow:global step 4933: loss = 0.9319 (0.810 sec/step)\n",
            "I0503 01:46:54.930050 140519389960064 learning.py:507] global step 4933: loss = 0.9319 (0.810 sec/step)\n",
            "INFO:tensorflow:global step 4934: loss = 0.9406 (1.037 sec/step)\n",
            "I0503 01:46:55.981656 140519389960064 learning.py:507] global step 4934: loss = 0.9406 (1.037 sec/step)\n",
            "INFO:tensorflow:global step 4935: loss = 0.9763 (0.697 sec/step)\n",
            "I0503 01:46:56.738273 140519389960064 learning.py:507] global step 4935: loss = 0.9763 (0.697 sec/step)\n",
            "INFO:tensorflow:global step 4936: loss = 0.7710 (0.843 sec/step)\n",
            "I0503 01:46:57.665489 140519389960064 learning.py:507] global step 4936: loss = 0.7710 (0.843 sec/step)\n",
            "INFO:tensorflow:global step 4937: loss = 0.7721 (0.780 sec/step)\n",
            "I0503 01:46:58.487550 140519389960064 learning.py:507] global step 4937: loss = 0.7721 (0.780 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path train/model.ckpt\n",
            "I0503 01:46:58.859175 140515693082368 supervisor.py:1117] Saving checkpoint to path train/model.ckpt\n",
            "INFO:tensorflow:global step 4938: loss = 0.6449 (1.780 sec/step)\n",
            "I0503 01:47:00.296261 140519389960064 learning.py:507] global step 4938: loss = 0.6449 (1.780 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 4939.\n",
            "I0503 01:47:01.329815 140515676296960 supervisor.py:1050] Recording summary at step 4939.\n",
            "INFO:tensorflow:global step 4939: loss = 0.6543 (0.981 sec/step)\n",
            "I0503 01:47:01.336937 140519389960064 learning.py:507] global step 4939: loss = 0.6543 (0.981 sec/step)\n",
            "INFO:tensorflow:global step 4940: loss = 0.8718 (1.323 sec/step)\n",
            "I0503 01:47:02.852743 140519389960064 learning.py:507] global step 4940: loss = 0.8718 (1.323 sec/step)\n",
            "INFO:tensorflow:global step 4941: loss = 0.6800 (0.890 sec/step)\n",
            "I0503 01:47:03.933330 140519389960064 learning.py:507] global step 4941: loss = 0.6800 (0.890 sec/step)\n",
            "INFO:tensorflow:global step 4942: loss = 0.8158 (0.742 sec/step)\n",
            "I0503 01:47:04.706929 140519389960064 learning.py:507] global step 4942: loss = 0.8158 (0.742 sec/step)\n",
            "INFO:tensorflow:global step 4943: loss = 0.9380 (0.879 sec/step)\n",
            "I0503 01:47:05.598562 140519389960064 learning.py:507] global step 4943: loss = 0.9380 (0.879 sec/step)\n",
            "INFO:tensorflow:global step 4944: loss = 0.7211 (0.768 sec/step)\n",
            "I0503 01:47:06.468984 140519389960064 learning.py:507] global step 4944: loss = 0.7211 (0.768 sec/step)\n",
            "INFO:tensorflow:global step 4945: loss = 0.7215 (0.668 sec/step)\n",
            "I0503 01:47:07.198704 140519389960064 learning.py:507] global step 4945: loss = 0.7215 (0.668 sec/step)\n",
            "INFO:tensorflow:global step 4946: loss = 0.8465 (0.998 sec/step)\n",
            "I0503 01:47:08.199000 140519389960064 learning.py:507] global step 4946: loss = 0.8465 (0.998 sec/step)\n",
            "INFO:tensorflow:global step 4947: loss = 0.5973 (0.757 sec/step)\n",
            "I0503 01:47:08.957802 140519389960064 learning.py:507] global step 4947: loss = 0.5973 (0.757 sec/step)\n",
            "INFO:tensorflow:global step 4948: loss = 1.0015 (0.843 sec/step)\n",
            "I0503 01:47:09.802680 140519389960064 learning.py:507] global step 4948: loss = 1.0015 (0.843 sec/step)\n",
            "INFO:tensorflow:global step 4949: loss = 0.6589 (0.806 sec/step)\n",
            "I0503 01:47:10.610847 140519389960064 learning.py:507] global step 4949: loss = 0.6589 (0.806 sec/step)\n",
            "INFO:tensorflow:global step 4950: loss = 0.6146 (0.885 sec/step)\n",
            "I0503 01:47:11.497559 140519389960064 learning.py:507] global step 4950: loss = 0.6146 (0.885 sec/step)\n",
            "INFO:tensorflow:global step 4951: loss = 0.6658 (0.820 sec/step)\n",
            "I0503 01:47:12.319902 140519389960064 learning.py:507] global step 4951: loss = 0.6658 (0.820 sec/step)\n",
            "INFO:tensorflow:global step 4952: loss = 0.6713 (0.841 sec/step)\n",
            "I0503 01:47:13.162518 140519389960064 learning.py:507] global step 4952: loss = 0.6713 (0.841 sec/step)\n",
            "INFO:tensorflow:global step 4953: loss = 0.9498 (0.850 sec/step)\n",
            "I0503 01:47:14.013980 140519389960064 learning.py:507] global step 4953: loss = 0.9498 (0.850 sec/step)\n",
            "INFO:tensorflow:global step 4954: loss = 0.8256 (0.934 sec/step)\n",
            "I0503 01:47:14.949727 140519389960064 learning.py:507] global step 4954: loss = 0.8256 (0.934 sec/step)\n",
            "INFO:tensorflow:global step 4955: loss = 0.7739 (0.841 sec/step)\n",
            "I0503 01:47:15.792087 140519389960064 learning.py:507] global step 4955: loss = 0.7739 (0.841 sec/step)\n",
            "INFO:tensorflow:global step 4956: loss = 0.7543 (0.650 sec/step)\n",
            "I0503 01:47:16.487951 140519389960064 learning.py:507] global step 4956: loss = 0.7543 (0.650 sec/step)\n",
            "INFO:tensorflow:global step 4957: loss = 0.9201 (0.831 sec/step)\n",
            "I0503 01:47:17.322543 140519389960064 learning.py:507] global step 4957: loss = 0.9201 (0.831 sec/step)\n",
            "INFO:tensorflow:global step 4958: loss = 1.0283 (0.758 sec/step)\n",
            "I0503 01:47:18.082697 140519389960064 learning.py:507] global step 4958: loss = 1.0283 (0.758 sec/step)\n",
            "INFO:tensorflow:global step 4959: loss = 0.8104 (0.821 sec/step)\n",
            "I0503 01:47:18.905405 140519389960064 learning.py:507] global step 4959: loss = 0.8104 (0.821 sec/step)\n",
            "INFO:tensorflow:global step 4960: loss = 0.8634 (0.737 sec/step)\n",
            "I0503 01:47:19.802218 140519389960064 learning.py:507] global step 4960: loss = 0.8634 (0.737 sec/step)\n",
            "INFO:tensorflow:global step 4961: loss = 0.9659 (0.802 sec/step)\n",
            "I0503 01:47:20.614749 140519389960064 learning.py:507] global step 4961: loss = 0.9659 (0.802 sec/step)\n",
            "INFO:tensorflow:global step 4962: loss = 0.7071 (0.929 sec/step)\n",
            "I0503 01:47:21.547115 140519389960064 learning.py:507] global step 4962: loss = 0.7071 (0.929 sec/step)\n",
            "INFO:tensorflow:global step 4963: loss = 0.7745 (0.829 sec/step)\n",
            "I0503 01:47:22.377745 140519389960064 learning.py:507] global step 4963: loss = 0.7745 (0.829 sec/step)\n",
            "INFO:tensorflow:global step 4964: loss = 0.7571 (0.644 sec/step)\n",
            "I0503 01:47:23.023248 140519389960064 learning.py:507] global step 4964: loss = 0.7571 (0.644 sec/step)\n",
            "INFO:tensorflow:global step 4965: loss = 0.8852 (0.959 sec/step)\n",
            "I0503 01:47:23.984589 140519389960064 learning.py:507] global step 4965: loss = 0.8852 (0.959 sec/step)\n",
            "INFO:tensorflow:global step 4966: loss = 0.6010 (1.022 sec/step)\n",
            "I0503 01:47:25.008822 140519389960064 learning.py:507] global step 4966: loss = 0.6010 (1.022 sec/step)\n",
            "INFO:tensorflow:global step 4967: loss = 0.7314 (0.849 sec/step)\n",
            "I0503 01:47:25.859695 140519389960064 learning.py:507] global step 4967: loss = 0.7314 (0.849 sec/step)\n",
            "INFO:tensorflow:global step 4968: loss = 0.7542 (0.834 sec/step)\n",
            "I0503 01:47:26.695624 140519389960064 learning.py:507] global step 4968: loss = 0.7542 (0.834 sec/step)\n",
            "INFO:tensorflow:global step 4969: loss = 0.8473 (0.710 sec/step)\n",
            "I0503 01:47:27.407099 140519389960064 learning.py:507] global step 4969: loss = 0.8473 (0.710 sec/step)\n",
            "INFO:tensorflow:global step 4970: loss = 0.9597 (0.863 sec/step)\n",
            "I0503 01:47:28.271934 140519389960064 learning.py:507] global step 4970: loss = 0.9597 (0.863 sec/step)\n",
            "INFO:tensorflow:global step 4971: loss = 1.0900 (0.831 sec/step)\n",
            "I0503 01:47:29.104152 140519389960064 learning.py:507] global step 4971: loss = 1.0900 (0.831 sec/step)\n",
            "INFO:tensorflow:global step 4972: loss = 0.7887 (0.933 sec/step)\n",
            "I0503 01:47:30.038420 140519389960064 learning.py:507] global step 4972: loss = 0.7887 (0.933 sec/step)\n",
            "INFO:tensorflow:global step 4973: loss = 0.5980 (0.884 sec/step)\n",
            "I0503 01:47:30.924978 140519389960064 learning.py:507] global step 4973: loss = 0.5980 (0.884 sec/step)\n",
            "INFO:tensorflow:global step 4974: loss = 0.6605 (0.708 sec/step)\n",
            "I0503 01:47:31.634940 140519389960064 learning.py:507] global step 4974: loss = 0.6605 (0.708 sec/step)\n",
            "INFO:tensorflow:global step 4975: loss = 0.7247 (0.748 sec/step)\n",
            "I0503 01:47:32.384837 140519389960064 learning.py:507] global step 4975: loss = 0.7247 (0.748 sec/step)\n",
            "INFO:tensorflow:global step 4976: loss = 0.6870 (0.777 sec/step)\n",
            "I0503 01:47:33.162952 140519389960064 learning.py:507] global step 4976: loss = 0.6870 (0.777 sec/step)\n",
            "INFO:tensorflow:global step 4977: loss = 1.0345 (0.872 sec/step)\n",
            "I0503 01:47:34.037798 140519389960064 learning.py:507] global step 4977: loss = 1.0345 (0.872 sec/step)\n",
            "INFO:tensorflow:global step 4978: loss = 0.6883 (0.796 sec/step)\n",
            "I0503 01:47:34.835712 140519389960064 learning.py:507] global step 4978: loss = 0.6883 (0.796 sec/step)\n",
            "INFO:tensorflow:global step 4979: loss = 0.7590 (0.932 sec/step)\n",
            "I0503 01:47:35.769047 140519389960064 learning.py:507] global step 4979: loss = 0.7590 (0.932 sec/step)\n",
            "INFO:tensorflow:global step 4980: loss = 0.8616 (0.740 sec/step)\n",
            "I0503 01:47:36.510939 140519389960064 learning.py:507] global step 4980: loss = 0.8616 (0.740 sec/step)\n",
            "INFO:tensorflow:global step 4981: loss = 0.8518 (0.740 sec/step)\n",
            "I0503 01:47:37.252878 140519389960064 learning.py:507] global step 4981: loss = 0.8518 (0.740 sec/step)\n",
            "INFO:tensorflow:global step 4982: loss = 0.6607 (0.927 sec/step)\n",
            "I0503 01:47:38.181468 140519389960064 learning.py:507] global step 4982: loss = 0.6607 (0.927 sec/step)\n",
            "INFO:tensorflow:global step 4983: loss = 0.5831 (0.831 sec/step)\n",
            "I0503 01:47:39.013925 140519389960064 learning.py:507] global step 4983: loss = 0.5831 (0.831 sec/step)\n",
            "INFO:tensorflow:global step 4984: loss = 0.6524 (1.000 sec/step)\n",
            "I0503 01:47:40.015345 140519389960064 learning.py:507] global step 4984: loss = 0.6524 (1.000 sec/step)\n",
            "INFO:tensorflow:global step 4985: loss = 1.0067 (0.971 sec/step)\n",
            "I0503 01:47:40.987844 140519389960064 learning.py:507] global step 4985: loss = 1.0067 (0.971 sec/step)\n",
            "INFO:tensorflow:global step 4986: loss = 0.7479 (0.647 sec/step)\n",
            "I0503 01:47:41.746532 140519389960064 learning.py:507] global step 4986: loss = 0.7479 (0.647 sec/step)\n",
            "INFO:tensorflow:global step 4987: loss = 0.6599 (0.952 sec/step)\n",
            "I0503 01:47:42.701496 140519389960064 learning.py:507] global step 4987: loss = 0.6599 (0.952 sec/step)\n",
            "INFO:tensorflow:global step 4988: loss = 0.8100 (0.821 sec/step)\n",
            "I0503 01:47:43.523829 140519389960064 learning.py:507] global step 4988: loss = 0.8100 (0.821 sec/step)\n",
            "INFO:tensorflow:global step 4989: loss = 0.8537 (0.803 sec/step)\n",
            "I0503 01:47:44.328494 140519389960064 learning.py:507] global step 4989: loss = 0.8537 (0.803 sec/step)\n",
            "INFO:tensorflow:global step 4990: loss = 0.5927 (0.862 sec/step)\n",
            "I0503 01:47:45.192132 140519389960064 learning.py:507] global step 4990: loss = 0.5927 (0.862 sec/step)\n",
            "INFO:tensorflow:global step 4991: loss = 0.7149 (0.878 sec/step)\n",
            "I0503 01:47:46.071877 140519389960064 learning.py:507] global step 4991: loss = 0.7149 (0.878 sec/step)\n",
            "INFO:tensorflow:global step 4992: loss = 0.5556 (0.727 sec/step)\n",
            "I0503 01:47:46.882941 140519389960064 learning.py:507] global step 4992: loss = 0.5556 (0.727 sec/step)\n",
            "INFO:tensorflow:global step 4993: loss = 0.8970 (0.916 sec/step)\n",
            "I0503 01:47:47.868322 140519389960064 learning.py:507] global step 4993: loss = 0.8970 (0.916 sec/step)\n",
            "INFO:tensorflow:global step 4994: loss = 0.7165 (0.818 sec/step)\n",
            "I0503 01:47:48.687711 140519389960064 learning.py:507] global step 4994: loss = 0.7165 (0.818 sec/step)\n",
            "INFO:tensorflow:global step 4995: loss = 1.0256 (0.809 sec/step)\n",
            "I0503 01:47:49.631472 140519389960064 learning.py:507] global step 4995: loss = 1.0256 (0.809 sec/step)\n",
            "INFO:tensorflow:global step 4996: loss = 0.9640 (0.706 sec/step)\n",
            "I0503 01:47:50.339624 140519389960064 learning.py:507] global step 4996: loss = 0.9640 (0.706 sec/step)\n",
            "INFO:tensorflow:global step 4997: loss = 0.7630 (0.828 sec/step)\n",
            "I0503 01:47:51.169642 140519389960064 learning.py:507] global step 4997: loss = 0.7630 (0.828 sec/step)\n",
            "INFO:tensorflow:global step 4998: loss = 0.6450 (0.911 sec/step)\n",
            "I0503 01:47:52.082494 140519389960064 learning.py:507] global step 4998: loss = 0.6450 (0.911 sec/step)\n",
            "INFO:tensorflow:global step 4999: loss = 0.6709 (0.692 sec/step)\n",
            "I0503 01:47:52.775907 140519389960064 learning.py:507] global step 4999: loss = 0.6709 (0.692 sec/step)\n",
            "INFO:tensorflow:global step 5000: loss = 0.6550 (0.887 sec/step)\n",
            "I0503 01:47:53.664688 140519389960064 learning.py:507] global step 5000: loss = 0.6550 (0.887 sec/step)\n",
            "INFO:tensorflow:global step 5001: loss = 0.7599 (0.759 sec/step)\n",
            "I0503 01:47:54.430934 140519389960064 learning.py:507] global step 5001: loss = 0.7599 (0.759 sec/step)\n",
            "INFO:tensorflow:global step 5002: loss = 0.8196 (0.816 sec/step)\n",
            "I0503 01:47:55.248360 140519389960064 learning.py:507] global step 5002: loss = 0.8196 (0.816 sec/step)\n",
            "INFO:tensorflow:global step 5003: loss = 0.8059 (0.735 sec/step)\n",
            "I0503 01:47:55.994378 140519389960064 learning.py:507] global step 5003: loss = 0.8059 (0.735 sec/step)\n",
            "INFO:tensorflow:global step 5004: loss = 0.6470 (0.890 sec/step)\n",
            "I0503 01:47:56.885998 140519389960064 learning.py:507] global step 5004: loss = 0.6470 (0.890 sec/step)\n",
            "INFO:tensorflow:global step 5005: loss = 0.5063 (0.885 sec/step)\n",
            "I0503 01:47:57.772524 140519389960064 learning.py:507] global step 5005: loss = 0.5063 (0.885 sec/step)\n",
            "INFO:tensorflow:global step 5006: loss = 0.8518 (0.944 sec/step)\n",
            "I0503 01:47:58.718343 140519389960064 learning.py:507] global step 5006: loss = 0.8518 (0.944 sec/step)\n",
            "INFO:tensorflow:global step 5007: loss = 0.9819 (0.829 sec/step)\n",
            "I0503 01:47:59.548481 140519389960064 learning.py:507] global step 5007: loss = 0.9819 (0.829 sec/step)\n",
            "INFO:tensorflow:global step 5008: loss = 0.6101 (0.812 sec/step)\n",
            "I0503 01:48:00.362431 140519389960064 learning.py:507] global step 5008: loss = 0.6101 (0.812 sec/step)\n",
            "INFO:tensorflow:global step 5009: loss = 0.7106 (0.798 sec/step)\n",
            "I0503 01:48:01.162125 140519389960064 learning.py:507] global step 5009: loss = 0.7106 (0.798 sec/step)\n",
            "INFO:tensorflow:global step 5010: loss = 0.7868 (0.824 sec/step)\n",
            "I0503 01:48:01.987896 140519389960064 learning.py:507] global step 5010: loss = 0.7868 (0.824 sec/step)\n",
            "INFO:tensorflow:global step 5011: loss = 0.7648 (0.777 sec/step)\n",
            "I0503 01:48:02.767113 140519389960064 learning.py:507] global step 5011: loss = 0.7648 (0.777 sec/step)\n",
            "INFO:tensorflow:global step 5012: loss = 0.6796 (0.731 sec/step)\n",
            "I0503 01:48:03.500225 140519389960064 learning.py:507] global step 5012: loss = 0.6796 (0.731 sec/step)\n",
            "INFO:tensorflow:global step 5013: loss = 0.7290 (1.027 sec/step)\n",
            "I0503 01:48:04.529311 140519389960064 learning.py:507] global step 5013: loss = 0.7290 (1.027 sec/step)\n",
            "INFO:tensorflow:global step 5014: loss = 0.8300 (0.711 sec/step)\n",
            "I0503 01:48:05.253429 140519389960064 learning.py:507] global step 5014: loss = 0.8300 (0.711 sec/step)\n",
            "INFO:tensorflow:global step 5015: loss = 0.5625 (0.996 sec/step)\n",
            "I0503 01:48:06.257821 140519389960064 learning.py:507] global step 5015: loss = 0.5625 (0.996 sec/step)\n",
            "INFO:tensorflow:global step 5016: loss = 0.8237 (0.849 sec/step)\n",
            "I0503 01:48:07.109228 140519389960064 learning.py:507] global step 5016: loss = 0.8237 (0.849 sec/step)\n",
            "INFO:tensorflow:global step 5017: loss = 0.8124 (0.769 sec/step)\n",
            "I0503 01:48:07.879789 140519389960064 learning.py:507] global step 5017: loss = 0.8124 (0.769 sec/step)\n",
            "INFO:tensorflow:global step 5018: loss = 0.6394 (1.627 sec/step)\n",
            "I0503 01:48:09.515401 140519389960064 learning.py:507] global step 5018: loss = 0.6394 (1.627 sec/step)\n",
            "INFO:tensorflow:global step 5019: loss = 0.7879 (0.950 sec/step)\n",
            "I0503 01:48:10.466399 140519389960064 learning.py:507] global step 5019: loss = 0.7879 (0.950 sec/step)\n",
            "INFO:tensorflow:global step 5020: loss = 0.8599 (0.861 sec/step)\n",
            "I0503 01:48:11.329203 140519389960064 learning.py:507] global step 5020: loss = 0.8599 (0.861 sec/step)\n",
            "INFO:tensorflow:global step 5021: loss = 0.6649 (0.824 sec/step)\n",
            "I0503 01:48:12.154415 140519389960064 learning.py:507] global step 5021: loss = 0.6649 (0.824 sec/step)\n",
            "INFO:tensorflow:global step 5022: loss = 0.7675 (0.712 sec/step)\n",
            "I0503 01:48:12.869789 140519389960064 learning.py:507] global step 5022: loss = 0.7675 (0.712 sec/step)\n",
            "INFO:tensorflow:global step 5023: loss = 0.6914 (0.770 sec/step)\n",
            "I0503 01:48:13.641758 140519389960064 learning.py:507] global step 5023: loss = 0.6914 (0.770 sec/step)\n",
            "INFO:tensorflow:global step 5024: loss = 0.5537 (0.887 sec/step)\n",
            "I0503 01:48:14.590066 140519389960064 learning.py:507] global step 5024: loss = 0.5537 (0.887 sec/step)\n",
            "INFO:tensorflow:global step 5025: loss = 0.6896 (1.215 sec/step)\n",
            "I0503 01:48:15.808548 140519389960064 learning.py:507] global step 5025: loss = 0.6896 (1.215 sec/step)\n",
            "INFO:tensorflow:global step 5026: loss = 0.9978 (0.719 sec/step)\n",
            "I0503 01:48:16.529504 140519389960064 learning.py:507] global step 5026: loss = 0.9978 (0.719 sec/step)\n",
            "INFO:tensorflow:global step 5027: loss = 0.7474 (1.241 sec/step)\n",
            "I0503 01:48:17.771718 140519389960064 learning.py:507] global step 5027: loss = 0.7474 (1.241 sec/step)\n",
            "INFO:tensorflow:global step 5028: loss = 0.7562 (0.744 sec/step)\n",
            "I0503 01:48:18.518391 140519389960064 learning.py:507] global step 5028: loss = 0.7562 (0.744 sec/step)\n",
            "INFO:tensorflow:global step 5029: loss = 0.6094 (0.808 sec/step)\n",
            "I0503 01:48:19.328697 140519389960064 learning.py:507] global step 5029: loss = 0.6094 (0.808 sec/step)\n",
            "INFO:tensorflow:global step 5030: loss = 0.6637 (1.016 sec/step)\n",
            "I0503 01:48:20.347604 140519389960064 learning.py:507] global step 5030: loss = 0.6637 (1.016 sec/step)\n",
            "INFO:tensorflow:global step 5031: loss = 0.7608 (0.830 sec/step)\n",
            "I0503 01:48:21.179395 140519389960064 learning.py:507] global step 5031: loss = 0.7608 (0.830 sec/step)\n",
            "INFO:tensorflow:global step 5032: loss = 0.6629 (0.832 sec/step)\n",
            "I0503 01:48:22.013657 140519389960064 learning.py:507] global step 5032: loss = 0.6629 (0.832 sec/step)\n",
            "INFO:tensorflow:global step 5033: loss = 0.6897 (0.824 sec/step)\n",
            "I0503 01:48:22.890129 140519389960064 learning.py:507] global step 5033: loss = 0.6897 (0.824 sec/step)\n",
            "INFO:tensorflow:global step 5034: loss = 0.7394 (0.827 sec/step)\n",
            "I0503 01:48:23.728410 140519389960064 learning.py:507] global step 5034: loss = 0.7394 (0.827 sec/step)\n",
            "INFO:tensorflow:global step 5035: loss = 0.8153 (0.901 sec/step)\n",
            "I0503 01:48:24.635415 140519389960064 learning.py:507] global step 5035: loss = 0.8153 (0.901 sec/step)\n",
            "INFO:tensorflow:global step 5036: loss = 0.9018 (0.853 sec/step)\n",
            "I0503 01:48:25.489481 140519389960064 learning.py:507] global step 5036: loss = 0.9018 (0.853 sec/step)\n",
            "INFO:tensorflow:global step 5037: loss = 0.8168 (0.584 sec/step)\n",
            "I0503 01:48:26.074791 140519389960064 learning.py:507] global step 5037: loss = 0.8168 (0.584 sec/step)\n",
            "INFO:tensorflow:global step 5038: loss = 0.7657 (0.806 sec/step)\n",
            "I0503 01:48:26.882447 140519389960064 learning.py:507] global step 5038: loss = 0.7657 (0.806 sec/step)\n",
            "INFO:tensorflow:global step 5039: loss = 0.7926 (0.913 sec/step)\n",
            "I0503 01:48:27.797326 140519389960064 learning.py:507] global step 5039: loss = 0.7926 (0.913 sec/step)\n",
            "INFO:tensorflow:global step 5040: loss = 0.7650 (0.789 sec/step)\n",
            "I0503 01:48:28.588095 140519389960064 learning.py:507] global step 5040: loss = 0.7650 (0.789 sec/step)\n",
            "INFO:tensorflow:global step 5041: loss = 0.6162 (0.793 sec/step)\n",
            "I0503 01:48:29.382543 140519389960064 learning.py:507] global step 5041: loss = 0.6162 (0.793 sec/step)\n",
            "INFO:tensorflow:global step 5042: loss = 0.7685 (0.828 sec/step)\n",
            "I0503 01:48:30.212507 140519389960064 learning.py:507] global step 5042: loss = 0.7685 (0.828 sec/step)\n",
            "INFO:tensorflow:global step 5043: loss = 0.7589 (0.880 sec/step)\n",
            "I0503 01:48:31.095570 140519389960064 learning.py:507] global step 5043: loss = 0.7589 (0.880 sec/step)\n",
            "INFO:tensorflow:global step 5044: loss = 0.7232 (0.823 sec/step)\n",
            "I0503 01:48:31.919656 140519389960064 learning.py:507] global step 5044: loss = 0.7232 (0.823 sec/step)\n",
            "INFO:tensorflow:global step 5045: loss = 0.7646 (0.868 sec/step)\n",
            "I0503 01:48:32.789206 140519389960064 learning.py:507] global step 5045: loss = 0.7646 (0.868 sec/step)\n",
            "INFO:tensorflow:global step 5046: loss = 0.6751 (0.835 sec/step)\n",
            "I0503 01:48:33.625947 140519389960064 learning.py:507] global step 5046: loss = 0.6751 (0.835 sec/step)\n",
            "INFO:tensorflow:global step 5047: loss = 0.8472 (0.747 sec/step)\n",
            "I0503 01:48:34.374250 140519389960064 learning.py:507] global step 5047: loss = 0.8472 (0.747 sec/step)\n",
            "INFO:tensorflow:global step 5048: loss = 0.6843 (0.720 sec/step)\n",
            "I0503 01:48:35.158961 140519389960064 learning.py:507] global step 5048: loss = 0.6843 (0.720 sec/step)\n",
            "INFO:tensorflow:global step 5049: loss = 1.0854 (0.734 sec/step)\n",
            "I0503 01:48:35.900560 140519389960064 learning.py:507] global step 5049: loss = 1.0854 (0.734 sec/step)\n",
            "INFO:tensorflow:global step 5050: loss = 0.9812 (0.814 sec/step)\n",
            "I0503 01:48:36.716387 140519389960064 learning.py:507] global step 5050: loss = 0.9812 (0.814 sec/step)\n",
            "INFO:tensorflow:global step 5051: loss = 0.6885 (0.798 sec/step)\n",
            "I0503 01:48:37.516166 140519389960064 learning.py:507] global step 5051: loss = 0.6885 (0.798 sec/step)\n",
            "INFO:tensorflow:global step 5052: loss = 0.7482 (0.774 sec/step)\n",
            "I0503 01:48:38.291727 140519389960064 learning.py:507] global step 5052: loss = 0.7482 (0.774 sec/step)\n",
            "INFO:tensorflow:global step 5053: loss = 0.6734 (0.814 sec/step)\n",
            "I0503 01:48:39.106902 140519389960064 learning.py:507] global step 5053: loss = 0.6734 (0.814 sec/step)\n",
            "INFO:tensorflow:global step 5054: loss = 0.7127 (0.871 sec/step)\n",
            "I0503 01:48:39.979516 140519389960064 learning.py:507] global step 5054: loss = 0.7127 (0.871 sec/step)\n",
            "INFO:tensorflow:global step 5055: loss = 0.7638 (0.784 sec/step)\n",
            "I0503 01:48:40.765169 140519389960064 learning.py:507] global step 5055: loss = 0.7638 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 5056: loss = 0.7845 (0.684 sec/step)\n",
            "I0503 01:48:41.451118 140519389960064 learning.py:507] global step 5056: loss = 0.7845 (0.684 sec/step)\n",
            "INFO:tensorflow:global step 5057: loss = 1.0724 (0.887 sec/step)\n",
            "I0503 01:48:42.340162 140519389960064 learning.py:507] global step 5057: loss = 1.0724 (0.887 sec/step)\n",
            "INFO:tensorflow:global step 5058: loss = 1.1311 (0.733 sec/step)\n",
            "I0503 01:48:43.074589 140519389960064 learning.py:507] global step 5058: loss = 1.1311 (0.733 sec/step)\n",
            "INFO:tensorflow:global step 5059: loss = 0.6876 (0.889 sec/step)\n",
            "I0503 01:48:43.965191 140519389960064 learning.py:507] global step 5059: loss = 0.6876 (0.889 sec/step)\n",
            "INFO:tensorflow:global step 5060: loss = 0.6700 (0.894 sec/step)\n",
            "I0503 01:48:44.860606 140519389960064 learning.py:507] global step 5060: loss = 0.6700 (0.894 sec/step)\n",
            "INFO:tensorflow:global step 5061: loss = 0.8369 (0.720 sec/step)\n",
            "I0503 01:48:45.588004 140519389960064 learning.py:507] global step 5061: loss = 0.8369 (0.720 sec/step)\n",
            "INFO:tensorflow:global step 5062: loss = 0.7854 (0.554 sec/step)\n",
            "I0503 01:48:46.217972 140519389960064 learning.py:507] global step 5062: loss = 0.7854 (0.554 sec/step)\n",
            "INFO:tensorflow:global step 5063: loss = 0.9085 (0.707 sec/step)\n",
            "I0503 01:48:46.999548 140519389960064 learning.py:507] global step 5063: loss = 0.9085 (0.707 sec/step)\n",
            "INFO:tensorflow:global step 5064: loss = 0.7501 (0.754 sec/step)\n",
            "I0503 01:48:47.759643 140519389960064 learning.py:507] global step 5064: loss = 0.7501 (0.754 sec/step)\n",
            "INFO:tensorflow:global step 5065: loss = 0.9627 (0.822 sec/step)\n",
            "I0503 01:48:48.583625 140519389960064 learning.py:507] global step 5065: loss = 0.9627 (0.822 sec/step)\n",
            "INFO:tensorflow:global step 5066: loss = 0.6830 (0.756 sec/step)\n",
            "I0503 01:48:49.340976 140519389960064 learning.py:507] global step 5066: loss = 0.6830 (0.756 sec/step)\n",
            "INFO:tensorflow:global step 5067: loss = 0.7521 (0.755 sec/step)\n",
            "I0503 01:48:50.129864 140519389960064 learning.py:507] global step 5067: loss = 0.7521 (0.755 sec/step)\n",
            "INFO:tensorflow:global step 5068: loss = 0.7136 (0.974 sec/step)\n",
            "I0503 01:48:51.107635 140519389960064 learning.py:507] global step 5068: loss = 0.7136 (0.974 sec/step)\n",
            "INFO:tensorflow:global step 5069: loss = 0.7483 (0.791 sec/step)\n",
            "I0503 01:48:51.927946 140519389960064 learning.py:507] global step 5069: loss = 0.7483 (0.791 sec/step)\n",
            "INFO:tensorflow:global step 5070: loss = 0.7044 (0.901 sec/step)\n",
            "I0503 01:48:52.835280 140519389960064 learning.py:507] global step 5070: loss = 0.7044 (0.901 sec/step)\n",
            "INFO:tensorflow:global step 5071: loss = 0.6738 (0.917 sec/step)\n",
            "I0503 01:48:53.754262 140519389960064 learning.py:507] global step 5071: loss = 0.6738 (0.917 sec/step)\n",
            "INFO:tensorflow:global step 5072: loss = 0.7103 (0.769 sec/step)\n",
            "I0503 01:48:54.601862 140519389960064 learning.py:507] global step 5072: loss = 0.7103 (0.769 sec/step)\n",
            "INFO:tensorflow:global step 5073: loss = 0.7523 (0.751 sec/step)\n",
            "I0503 01:48:55.355717 140519389960064 learning.py:507] global step 5073: loss = 0.7523 (0.751 sec/step)\n",
            "INFO:tensorflow:global step 5074: loss = 0.5828 (0.942 sec/step)\n",
            "I0503 01:48:56.299456 140519389960064 learning.py:507] global step 5074: loss = 0.5828 (0.942 sec/step)\n",
            "INFO:tensorflow:global step 5075: loss = 0.6844 (0.853 sec/step)\n",
            "I0503 01:48:57.153958 140519389960064 learning.py:507] global step 5075: loss = 0.6844 (0.853 sec/step)\n",
            "INFO:tensorflow:global step 5076: loss = 0.8540 (0.884 sec/step)\n",
            "I0503 01:48:58.039363 140519389960064 learning.py:507] global step 5076: loss = 0.8540 (0.884 sec/step)\n",
            "INFO:tensorflow:global step 5077: loss = 0.5488 (0.830 sec/step)\n",
            "I0503 01:48:59.026202 140519389960064 learning.py:507] global step 5077: loss = 0.5488 (0.830 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 5077.\n",
            "I0503 01:49:00.206706 140515676296960 supervisor.py:1050] Recording summary at step 5077.\n",
            "INFO:tensorflow:global step 5078: loss = 0.7395 (1.522 sec/step)\n",
            "I0503 01:49:00.555411 140519389960064 learning.py:507] global step 5078: loss = 0.7395 (1.522 sec/step)\n",
            "INFO:tensorflow:global step 5079: loss = 0.6978 (0.969 sec/step)\n",
            "I0503 01:49:01.525751 140519389960064 learning.py:507] global step 5079: loss = 0.6978 (0.969 sec/step)\n",
            "INFO:tensorflow:global step 5080: loss = 0.6147 (0.831 sec/step)\n",
            "I0503 01:49:02.358445 140519389960064 learning.py:507] global step 5080: loss = 0.6147 (0.831 sec/step)\n",
            "INFO:tensorflow:global step 5081: loss = 0.6705 (0.767 sec/step)\n",
            "I0503 01:49:03.144177 140519389960064 learning.py:507] global step 5081: loss = 0.6705 (0.767 sec/step)\n",
            "INFO:tensorflow:global step 5082: loss = 0.8243 (0.789 sec/step)\n",
            "I0503 01:49:03.934862 140519389960064 learning.py:507] global step 5082: loss = 0.8243 (0.789 sec/step)\n",
            "INFO:tensorflow:global step 5083: loss = 0.7757 (0.629 sec/step)\n",
            "I0503 01:49:04.662885 140519389960064 learning.py:507] global step 5083: loss = 0.7757 (0.629 sec/step)\n",
            "INFO:tensorflow:global step 5084: loss = 0.6368 (0.883 sec/step)\n",
            "I0503 01:49:05.548650 140519389960064 learning.py:507] global step 5084: loss = 0.6368 (0.883 sec/step)\n",
            "INFO:tensorflow:global step 5085: loss = 0.7163 (0.802 sec/step)\n",
            "I0503 01:49:06.395645 140519389960064 learning.py:507] global step 5085: loss = 0.7163 (0.802 sec/step)\n",
            "INFO:tensorflow:global step 5086: loss = 0.7505 (0.923 sec/step)\n",
            "I0503 01:49:07.358861 140519389960064 learning.py:507] global step 5086: loss = 0.7505 (0.923 sec/step)\n",
            "INFO:tensorflow:global step 5087: loss = 0.8005 (0.944 sec/step)\n",
            "I0503 01:49:08.304950 140519389960064 learning.py:507] global step 5087: loss = 0.8005 (0.944 sec/step)\n",
            "INFO:tensorflow:global step 5088: loss = 0.8253 (0.749 sec/step)\n",
            "I0503 01:49:09.055937 140519389960064 learning.py:507] global step 5088: loss = 0.8253 (0.749 sec/step)\n",
            "INFO:tensorflow:global step 5089: loss = 0.8003 (0.851 sec/step)\n",
            "I0503 01:49:09.908675 140519389960064 learning.py:507] global step 5089: loss = 0.8003 (0.851 sec/step)\n",
            "INFO:tensorflow:global step 5090: loss = 0.7384 (0.933 sec/step)\n",
            "I0503 01:49:10.843725 140519389960064 learning.py:507] global step 5090: loss = 0.7384 (0.933 sec/step)\n",
            "INFO:tensorflow:global step 5091: loss = 0.8362 (0.979 sec/step)\n",
            "I0503 01:49:11.824737 140519389960064 learning.py:507] global step 5091: loss = 0.8362 (0.979 sec/step)\n",
            "INFO:tensorflow:global step 5092: loss = 1.0895 (0.848 sec/step)\n",
            "I0503 01:49:12.674522 140519389960064 learning.py:507] global step 5092: loss = 1.0895 (0.848 sec/step)\n",
            "INFO:tensorflow:global step 5093: loss = 0.8218 (0.922 sec/step)\n",
            "I0503 01:49:13.598324 140519389960064 learning.py:507] global step 5093: loss = 0.8218 (0.922 sec/step)\n",
            "INFO:tensorflow:global step 5094: loss = 0.6380 (0.874 sec/step)\n",
            "I0503 01:49:14.473715 140519389960064 learning.py:507] global step 5094: loss = 0.6380 (0.874 sec/step)\n",
            "INFO:tensorflow:global step 5095: loss = 0.6849 (0.842 sec/step)\n",
            "I0503 01:49:15.316991 140519389960064 learning.py:507] global step 5095: loss = 0.6849 (0.842 sec/step)\n",
            "INFO:tensorflow:global step 5096: loss = 0.8128 (0.761 sec/step)\n",
            "I0503 01:49:16.080125 140519389960064 learning.py:507] global step 5096: loss = 0.8128 (0.761 sec/step)\n",
            "INFO:tensorflow:global step 5097: loss = 0.7255 (1.064 sec/step)\n",
            "I0503 01:49:17.146167 140519389960064 learning.py:507] global step 5097: loss = 0.7255 (1.064 sec/step)\n",
            "INFO:tensorflow:global step 5098: loss = 0.6800 (0.918 sec/step)\n",
            "I0503 01:49:18.065782 140519389960064 learning.py:507] global step 5098: loss = 0.6800 (0.918 sec/step)\n",
            "INFO:tensorflow:global step 5099: loss = 0.6862 (0.860 sec/step)\n",
            "I0503 01:49:18.927228 140519389960064 learning.py:507] global step 5099: loss = 0.6862 (0.860 sec/step)\n",
            "INFO:tensorflow:global step 5100: loss = 0.8222 (0.898 sec/step)\n",
            "I0503 01:49:19.827435 140519389960064 learning.py:507] global step 5100: loss = 0.8222 (0.898 sec/step)\n",
            "INFO:tensorflow:global step 5101: loss = 0.6117 (0.837 sec/step)\n",
            "I0503 01:49:20.665684 140519389960064 learning.py:507] global step 5101: loss = 0.6117 (0.837 sec/step)\n",
            "INFO:tensorflow:global step 5102: loss = 0.7690 (0.783 sec/step)\n",
            "I0503 01:49:21.543437 140519389960064 learning.py:507] global step 5102: loss = 0.7690 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 5103: loss = 0.7472 (0.935 sec/step)\n",
            "I0503 01:49:22.497169 140519389960064 learning.py:507] global step 5103: loss = 0.7472 (0.935 sec/step)\n",
            "INFO:tensorflow:global step 5104: loss = 0.8400 (0.811 sec/step)\n",
            "I0503 01:49:23.309694 140519389960064 learning.py:507] global step 5104: loss = 0.8400 (0.811 sec/step)\n",
            "INFO:tensorflow:global step 5105: loss = 0.8562 (0.765 sec/step)\n",
            "I0503 01:49:24.076858 140519389960064 learning.py:507] global step 5105: loss = 0.8562 (0.765 sec/step)\n",
            "INFO:tensorflow:global step 5106: loss = 0.7644 (0.881 sec/step)\n",
            "I0503 01:49:24.960625 140519389960064 learning.py:507] global step 5106: loss = 0.7644 (0.881 sec/step)\n",
            "INFO:tensorflow:global step 5107: loss = 0.7883 (0.762 sec/step)\n",
            "I0503 01:49:25.724032 140519389960064 learning.py:507] global step 5107: loss = 0.7883 (0.762 sec/step)\n",
            "INFO:tensorflow:global step 5108: loss = 0.7320 (0.743 sec/step)\n",
            "I0503 01:49:26.529145 140519389960064 learning.py:507] global step 5108: loss = 0.7320 (0.743 sec/step)\n",
            "INFO:tensorflow:global step 5109: loss = 0.7667 (0.774 sec/step)\n",
            "I0503 01:49:27.305253 140519389960064 learning.py:507] global step 5109: loss = 0.7667 (0.774 sec/step)\n",
            "INFO:tensorflow:global step 5110: loss = 0.8037 (1.279 sec/step)\n",
            "I0503 01:49:28.586725 140519389960064 learning.py:507] global step 5110: loss = 0.8037 (1.279 sec/step)\n",
            "INFO:tensorflow:global step 5111: loss = 0.7644 (0.769 sec/step)\n",
            "I0503 01:49:29.364137 140519389960064 learning.py:507] global step 5111: loss = 0.7644 (0.769 sec/step)\n",
            "INFO:tensorflow:global step 5112: loss = 0.6918 (0.897 sec/step)\n",
            "I0503 01:49:30.267693 140519389960064 learning.py:507] global step 5112: loss = 0.6918 (0.897 sec/step)\n",
            "INFO:tensorflow:global step 5113: loss = 0.7242 (0.857 sec/step)\n",
            "I0503 01:49:31.126639 140519389960064 learning.py:507] global step 5113: loss = 0.7242 (0.857 sec/step)\n",
            "INFO:tensorflow:global step 5114: loss = 0.6547 (0.852 sec/step)\n",
            "I0503 01:49:31.984197 140519389960064 learning.py:507] global step 5114: loss = 0.6547 (0.852 sec/step)\n",
            "INFO:tensorflow:global step 5115: loss = 0.9001 (0.712 sec/step)\n",
            "I0503 01:49:32.697797 140519389960064 learning.py:507] global step 5115: loss = 0.9001 (0.712 sec/step)\n",
            "INFO:tensorflow:global step 5116: loss = 0.7006 (0.978 sec/step)\n",
            "I0503 01:49:33.677513 140519389960064 learning.py:507] global step 5116: loss = 0.7006 (0.978 sec/step)\n",
            "INFO:tensorflow:global step 5117: loss = 0.6274 (0.686 sec/step)\n",
            "I0503 01:49:34.365512 140519389960064 learning.py:507] global step 5117: loss = 0.6274 (0.686 sec/step)\n",
            "INFO:tensorflow:global step 5118: loss = 0.7085 (0.728 sec/step)\n",
            "I0503 01:49:35.116056 140519389960064 learning.py:507] global step 5118: loss = 0.7085 (0.728 sec/step)\n",
            "INFO:tensorflow:global step 5119: loss = 0.7180 (0.926 sec/step)\n",
            "I0503 01:49:36.043490 140519389960064 learning.py:507] global step 5119: loss = 0.7180 (0.926 sec/step)\n",
            "INFO:tensorflow:global step 5120: loss = 0.6173 (0.890 sec/step)\n",
            "I0503 01:49:36.935107 140519389960064 learning.py:507] global step 5120: loss = 0.6173 (0.890 sec/step)\n",
            "INFO:tensorflow:global step 5121: loss = 0.7119 (0.919 sec/step)\n",
            "I0503 01:49:37.856378 140519389960064 learning.py:507] global step 5121: loss = 0.7119 (0.919 sec/step)\n",
            "INFO:tensorflow:global step 5122: loss = 0.8633 (0.706 sec/step)\n",
            "I0503 01:49:38.564887 140519389960064 learning.py:507] global step 5122: loss = 0.8633 (0.706 sec/step)\n",
            "INFO:tensorflow:global step 5123: loss = 0.7919 (1.040 sec/step)\n",
            "I0503 01:49:39.606254 140519389960064 learning.py:507] global step 5123: loss = 0.7919 (1.040 sec/step)\n",
            "INFO:tensorflow:global step 5124: loss = 0.8661 (0.745 sec/step)\n",
            "I0503 01:49:40.356940 140519389960064 learning.py:507] global step 5124: loss = 0.8661 (0.745 sec/step)\n",
            "INFO:tensorflow:global step 5125: loss = 0.5993 (0.670 sec/step)\n",
            "I0503 01:49:41.031664 140519389960064 learning.py:507] global step 5125: loss = 0.5993 (0.670 sec/step)\n",
            "INFO:tensorflow:global step 5126: loss = 0.7074 (0.797 sec/step)\n",
            "I0503 01:49:41.830446 140519389960064 learning.py:507] global step 5126: loss = 0.7074 (0.797 sec/step)\n",
            "INFO:tensorflow:global step 5127: loss = 0.7793 (0.875 sec/step)\n",
            "I0503 01:49:42.706869 140519389960064 learning.py:507] global step 5127: loss = 0.7793 (0.875 sec/step)\n",
            "INFO:tensorflow:global step 5128: loss = 0.9222 (0.896 sec/step)\n",
            "I0503 01:49:43.604592 140519389960064 learning.py:507] global step 5128: loss = 0.9222 (0.896 sec/step)\n",
            "INFO:tensorflow:global step 5129: loss = 0.8661 (0.847 sec/step)\n",
            "I0503 01:49:44.455860 140519389960064 learning.py:507] global step 5129: loss = 0.8661 (0.847 sec/step)\n",
            "INFO:tensorflow:global step 5130: loss = 0.8346 (0.787 sec/step)\n",
            "I0503 01:49:45.244193 140519389960064 learning.py:507] global step 5130: loss = 0.8346 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 5131: loss = 0.7703 (0.802 sec/step)\n",
            "I0503 01:49:46.048121 140519389960064 learning.py:507] global step 5131: loss = 0.7703 (0.802 sec/step)\n",
            "INFO:tensorflow:global step 5132: loss = 0.9403 (0.825 sec/step)\n",
            "I0503 01:49:46.874996 140519389960064 learning.py:507] global step 5132: loss = 0.9403 (0.825 sec/step)\n",
            "INFO:tensorflow:global step 5133: loss = 0.7397 (0.867 sec/step)\n",
            "I0503 01:49:47.743916 140519389960064 learning.py:507] global step 5133: loss = 0.7397 (0.867 sec/step)\n",
            "INFO:tensorflow:global step 5134: loss = 0.7327 (0.761 sec/step)\n",
            "I0503 01:49:48.506852 140519389960064 learning.py:507] global step 5134: loss = 0.7327 (0.761 sec/step)\n",
            "INFO:tensorflow:global step 5135: loss = 0.8532 (0.739 sec/step)\n",
            "I0503 01:49:49.246973 140519389960064 learning.py:507] global step 5135: loss = 0.8532 (0.739 sec/step)\n",
            "INFO:tensorflow:global step 5136: loss = 0.6975 (0.818 sec/step)\n",
            "I0503 01:49:50.066174 140519389960064 learning.py:507] global step 5136: loss = 0.6975 (0.818 sec/step)\n",
            "INFO:tensorflow:global step 5137: loss = 0.7581 (0.885 sec/step)\n",
            "I0503 01:49:50.953105 140519389960064 learning.py:507] global step 5137: loss = 0.7581 (0.885 sec/step)\n",
            "INFO:tensorflow:global step 5138: loss = 0.7678 (0.834 sec/step)\n",
            "I0503 01:49:51.788502 140519389960064 learning.py:507] global step 5138: loss = 0.7678 (0.834 sec/step)\n",
            "INFO:tensorflow:global step 5139: loss = 0.6666 (0.866 sec/step)\n",
            "I0503 01:49:52.656971 140519389960064 learning.py:507] global step 5139: loss = 0.6666 (0.866 sec/step)\n",
            "INFO:tensorflow:global step 5140: loss = 0.6093 (0.886 sec/step)\n",
            "I0503 01:49:53.544612 140519389960064 learning.py:507] global step 5140: loss = 0.6093 (0.886 sec/step)\n",
            "INFO:tensorflow:global step 5141: loss = 0.7716 (0.816 sec/step)\n",
            "I0503 01:49:54.363112 140519389960064 learning.py:507] global step 5141: loss = 0.7716 (0.816 sec/step)\n",
            "INFO:tensorflow:global step 5142: loss = 0.9692 (0.895 sec/step)\n",
            "I0503 01:49:55.260045 140519389960064 learning.py:507] global step 5142: loss = 0.9692 (0.895 sec/step)\n",
            "INFO:tensorflow:global step 5143: loss = 0.7772 (0.759 sec/step)\n",
            "I0503 01:49:56.020221 140519389960064 learning.py:507] global step 5143: loss = 0.7772 (0.759 sec/step)\n",
            "INFO:tensorflow:global step 5144: loss = 0.7571 (0.883 sec/step)\n",
            "I0503 01:49:56.904404 140519389960064 learning.py:507] global step 5144: loss = 0.7571 (0.883 sec/step)\n",
            "INFO:tensorflow:global step 5145: loss = 0.6736 (0.920 sec/step)\n",
            "I0503 01:49:57.827716 140519389960064 learning.py:507] global step 5145: loss = 0.6736 (0.920 sec/step)\n",
            "INFO:tensorflow:global step 5146: loss = 0.6447 (0.846 sec/step)\n",
            "I0503 01:49:58.675613 140519389960064 learning.py:507] global step 5146: loss = 0.6447 (0.846 sec/step)\n",
            "INFO:tensorflow:global step 5147: loss = 0.7449 (0.766 sec/step)\n",
            "I0503 01:49:59.443426 140519389960064 learning.py:507] global step 5147: loss = 0.7449 (0.766 sec/step)\n",
            "INFO:tensorflow:global step 5148: loss = 0.7011 (0.858 sec/step)\n",
            "I0503 01:50:00.303210 140519389960064 learning.py:507] global step 5148: loss = 0.7011 (0.858 sec/step)\n",
            "INFO:tensorflow:global step 5149: loss = 0.6961 (0.804 sec/step)\n",
            "I0503 01:50:01.109135 140519389960064 learning.py:507] global step 5149: loss = 0.6961 (0.804 sec/step)\n",
            "INFO:tensorflow:global step 5150: loss = 0.9373 (0.872 sec/step)\n",
            "I0503 01:50:01.982658 140519389960064 learning.py:507] global step 5150: loss = 0.9373 (0.872 sec/step)\n",
            "INFO:tensorflow:global step 5151: loss = 0.8428 (0.875 sec/step)\n",
            "I0503 01:50:02.859033 140519389960064 learning.py:507] global step 5151: loss = 0.8428 (0.875 sec/step)\n",
            "INFO:tensorflow:global step 5152: loss = 0.8957 (0.842 sec/step)\n",
            "I0503 01:50:03.702885 140519389960064 learning.py:507] global step 5152: loss = 0.8957 (0.842 sec/step)\n",
            "INFO:tensorflow:global step 5153: loss = 0.5977 (0.925 sec/step)\n",
            "I0503 01:50:04.629665 140519389960064 learning.py:507] global step 5153: loss = 0.5977 (0.925 sec/step)\n",
            "INFO:tensorflow:global step 5154: loss = 0.5390 (0.769 sec/step)\n",
            "I0503 01:50:05.400468 140519389960064 learning.py:507] global step 5154: loss = 0.5390 (0.769 sec/step)\n",
            "INFO:tensorflow:global step 5155: loss = 0.7286 (0.908 sec/step)\n",
            "I0503 01:50:06.310599 140519389960064 learning.py:507] global step 5155: loss = 0.7286 (0.908 sec/step)\n",
            "INFO:tensorflow:global step 5156: loss = 0.7224 (0.694 sec/step)\n",
            "I0503 01:50:07.006064 140519389960064 learning.py:507] global step 5156: loss = 0.7224 (0.694 sec/step)\n",
            "INFO:tensorflow:global step 5157: loss = 0.8183 (0.803 sec/step)\n",
            "I0503 01:50:07.810367 140519389960064 learning.py:507] global step 5157: loss = 0.8183 (0.803 sec/step)\n",
            "INFO:tensorflow:global step 5158: loss = 0.8069 (1.206 sec/step)\n",
            "I0503 01:50:09.018032 140519389960064 learning.py:507] global step 5158: loss = 0.8069 (1.206 sec/step)\n",
            "INFO:tensorflow:global step 5159: loss = 0.6353 (0.802 sec/step)\n",
            "I0503 01:50:09.864994 140519389960064 learning.py:507] global step 5159: loss = 0.6353 (0.802 sec/step)\n",
            "INFO:tensorflow:global step 5160: loss = 0.7688 (0.774 sec/step)\n",
            "I0503 01:50:10.646149 140519389960064 learning.py:507] global step 5160: loss = 0.7688 (0.774 sec/step)\n",
            "INFO:tensorflow:global step 5161: loss = 0.5474 (0.951 sec/step)\n",
            "I0503 01:50:11.599131 140519389960064 learning.py:507] global step 5161: loss = 0.5474 (0.951 sec/step)\n",
            "INFO:tensorflow:global step 5162: loss = 0.7413 (0.912 sec/step)\n",
            "I0503 01:50:12.512936 140519389960064 learning.py:507] global step 5162: loss = 0.7413 (0.912 sec/step)\n",
            "INFO:tensorflow:global step 5163: loss = 0.6541 (0.959 sec/step)\n",
            "I0503 01:50:13.473086 140519389960064 learning.py:507] global step 5163: loss = 0.6541 (0.959 sec/step)\n",
            "INFO:tensorflow:global step 5164: loss = 0.7599 (0.898 sec/step)\n",
            "I0503 01:50:14.372507 140519389960064 learning.py:507] global step 5164: loss = 0.7599 (0.898 sec/step)\n",
            "INFO:tensorflow:global step 5165: loss = 0.7303 (0.876 sec/step)\n",
            "I0503 01:50:15.249823 140519389960064 learning.py:507] global step 5165: loss = 0.7303 (0.876 sec/step)\n",
            "INFO:tensorflow:global step 5166: loss = 0.6664 (0.788 sec/step)\n",
            "I0503 01:50:16.115586 140519389960064 learning.py:507] global step 5166: loss = 0.6664 (0.788 sec/step)\n",
            "INFO:tensorflow:global step 5167: loss = 0.7912 (0.840 sec/step)\n",
            "I0503 01:50:16.961309 140519389960064 learning.py:507] global step 5167: loss = 0.7912 (0.840 sec/step)\n",
            "INFO:tensorflow:global step 5168: loss = 0.7279 (0.784 sec/step)\n",
            "I0503 01:50:17.746887 140519389960064 learning.py:507] global step 5168: loss = 0.7279 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 5169: loss = 0.6119 (0.876 sec/step)\n",
            "I0503 01:50:18.624648 140519389960064 learning.py:507] global step 5169: loss = 0.6119 (0.876 sec/step)\n",
            "INFO:tensorflow:global step 5170: loss = 0.5264 (0.765 sec/step)\n",
            "I0503 01:50:19.460417 140519389960064 learning.py:507] global step 5170: loss = 0.5264 (0.765 sec/step)\n",
            "INFO:tensorflow:global step 5171: loss = 0.6024 (0.872 sec/step)\n",
            "I0503 01:50:20.336224 140519389960064 learning.py:507] global step 5171: loss = 0.6024 (0.872 sec/step)\n",
            "INFO:tensorflow:global step 5172: loss = 0.6825 (0.932 sec/step)\n",
            "I0503 01:50:21.270187 140519389960064 learning.py:507] global step 5172: loss = 0.6825 (0.932 sec/step)\n",
            "INFO:tensorflow:global step 5173: loss = 0.9522 (0.713 sec/step)\n",
            "I0503 01:50:21.985094 140519389960064 learning.py:507] global step 5173: loss = 0.9522 (0.713 sec/step)\n",
            "INFO:tensorflow:global step 5174: loss = 0.6340 (0.845 sec/step)\n",
            "I0503 01:50:22.831598 140519389960064 learning.py:507] global step 5174: loss = 0.6340 (0.845 sec/step)\n",
            "INFO:tensorflow:global step 5175: loss = 0.7102 (0.804 sec/step)\n",
            "I0503 01:50:23.636683 140519389960064 learning.py:507] global step 5175: loss = 0.7102 (0.804 sec/step)\n",
            "INFO:tensorflow:global step 5176: loss = 0.8759 (0.756 sec/step)\n",
            "I0503 01:50:24.429404 140519389960064 learning.py:507] global step 5176: loss = 0.8759 (0.756 sec/step)\n",
            "INFO:tensorflow:global step 5177: loss = 0.7702 (0.873 sec/step)\n",
            "I0503 01:50:25.307631 140519389960064 learning.py:507] global step 5177: loss = 0.7702 (0.873 sec/step)\n",
            "INFO:tensorflow:global step 5178: loss = 0.9336 (0.953 sec/step)\n",
            "I0503 01:50:26.262372 140519389960064 learning.py:507] global step 5178: loss = 0.9336 (0.953 sec/step)\n",
            "INFO:tensorflow:global step 5179: loss = 0.6272 (0.787 sec/step)\n",
            "I0503 01:50:27.078976 140519389960064 learning.py:507] global step 5179: loss = 0.6272 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 5180: loss = 0.8014 (0.664 sec/step)\n",
            "I0503 01:50:27.798399 140519389960064 learning.py:507] global step 5180: loss = 0.8014 (0.664 sec/step)\n",
            "INFO:tensorflow:global step 5181: loss = 0.8278 (0.851 sec/step)\n",
            "I0503 01:50:28.656242 140519389960064 learning.py:507] global step 5181: loss = 0.8278 (0.851 sec/step)\n",
            "INFO:tensorflow:global step 5182: loss = 0.7631 (0.791 sec/step)\n",
            "I0503 01:50:29.468596 140519389960064 learning.py:507] global step 5182: loss = 0.7631 (0.791 sec/step)\n",
            "INFO:tensorflow:global step 5183: loss = 0.8929 (0.880 sec/step)\n",
            "I0503 01:50:30.350157 140519389960064 learning.py:507] global step 5183: loss = 0.8929 (0.880 sec/step)\n",
            "INFO:tensorflow:global step 5184: loss = 0.6175 (0.946 sec/step)\n",
            "I0503 01:50:31.297860 140519389960064 learning.py:507] global step 5184: loss = 0.6175 (0.946 sec/step)\n",
            "INFO:tensorflow:global step 5185: loss = 0.7630 (0.864 sec/step)\n",
            "I0503 01:50:32.164012 140519389960064 learning.py:507] global step 5185: loss = 0.7630 (0.864 sec/step)\n",
            "INFO:tensorflow:global step 5186: loss = 1.1114 (0.810 sec/step)\n",
            "I0503 01:50:32.976506 140519389960064 learning.py:507] global step 5186: loss = 1.1114 (0.810 sec/step)\n",
            "INFO:tensorflow:global step 5187: loss = 0.6137 (0.896 sec/step)\n",
            "I0503 01:50:33.873757 140519389960064 learning.py:507] global step 5187: loss = 0.6137 (0.896 sec/step)\n",
            "INFO:tensorflow:global step 5188: loss = 0.7864 (0.892 sec/step)\n",
            "I0503 01:50:34.767219 140519389960064 learning.py:507] global step 5188: loss = 0.7864 (0.892 sec/step)\n",
            "INFO:tensorflow:global step 5189: loss = 0.8159 (0.767 sec/step)\n",
            "I0503 01:50:35.536806 140519389960064 learning.py:507] global step 5189: loss = 0.8159 (0.767 sec/step)\n",
            "INFO:tensorflow:global step 5190: loss = 0.5974 (0.816 sec/step)\n",
            "I0503 01:50:36.354212 140519389960064 learning.py:507] global step 5190: loss = 0.5974 (0.816 sec/step)\n",
            "INFO:tensorflow:global step 5191: loss = 0.5869 (0.760 sec/step)\n",
            "I0503 01:50:37.115679 140519389960064 learning.py:507] global step 5191: loss = 0.5869 (0.760 sec/step)\n",
            "INFO:tensorflow:global step 5192: loss = 0.6045 (0.764 sec/step)\n",
            "I0503 01:50:37.881486 140519389960064 learning.py:507] global step 5192: loss = 0.6045 (0.764 sec/step)\n",
            "INFO:tensorflow:global step 5193: loss = 0.6848 (0.803 sec/step)\n",
            "I0503 01:50:38.698506 140519389960064 learning.py:507] global step 5193: loss = 0.6848 (0.803 sec/step)\n",
            "INFO:tensorflow:global step 5194: loss = 0.7334 (0.894 sec/step)\n",
            "I0503 01:50:39.611686 140519389960064 learning.py:507] global step 5194: loss = 0.7334 (0.894 sec/step)\n",
            "INFO:tensorflow:global step 5195: loss = 0.5072 (0.814 sec/step)\n",
            "I0503 01:50:40.427429 140519389960064 learning.py:507] global step 5195: loss = 0.5072 (0.814 sec/step)\n",
            "INFO:tensorflow:global step 5196: loss = 0.6036 (0.881 sec/step)\n",
            "I0503 01:50:41.309727 140519389960064 learning.py:507] global step 5196: loss = 0.6036 (0.881 sec/step)\n",
            "INFO:tensorflow:global step 5197: loss = 0.6214 (0.739 sec/step)\n",
            "I0503 01:50:42.050874 140519389960064 learning.py:507] global step 5197: loss = 0.6214 (0.739 sec/step)\n",
            "INFO:tensorflow:global step 5198: loss = 1.0289 (0.837 sec/step)\n",
            "I0503 01:50:42.889300 140519389960064 learning.py:507] global step 5198: loss = 1.0289 (0.837 sec/step)\n",
            "INFO:tensorflow:global step 5199: loss = 0.5672 (0.889 sec/step)\n",
            "I0503 01:50:43.780942 140519389960064 learning.py:507] global step 5199: loss = 0.5672 (0.889 sec/step)\n",
            "INFO:tensorflow:global step 5200: loss = 0.7906 (0.876 sec/step)\n",
            "I0503 01:50:44.657939 140519389960064 learning.py:507] global step 5200: loss = 0.7906 (0.876 sec/step)\n",
            "INFO:tensorflow:global step 5201: loss = 0.7906 (0.899 sec/step)\n",
            "I0503 01:50:45.557954 140519389960064 learning.py:507] global step 5201: loss = 0.7906 (0.899 sec/step)\n",
            "INFO:tensorflow:global step 5202: loss = 0.6613 (0.833 sec/step)\n",
            "I0503 01:50:46.392755 140519389960064 learning.py:507] global step 5202: loss = 0.6613 (0.833 sec/step)\n",
            "INFO:tensorflow:global step 5203: loss = 0.6725 (0.663 sec/step)\n",
            "I0503 01:50:47.057037 140519389960064 learning.py:507] global step 5203: loss = 0.6725 (0.663 sec/step)\n",
            "INFO:tensorflow:global step 5204: loss = 0.7217 (0.911 sec/step)\n",
            "I0503 01:50:47.969499 140519389960064 learning.py:507] global step 5204: loss = 0.7217 (0.911 sec/step)\n",
            "INFO:tensorflow:global step 5205: loss = 0.6511 (0.896 sec/step)\n",
            "I0503 01:50:48.867475 140519389960064 learning.py:507] global step 5205: loss = 0.6511 (0.896 sec/step)\n",
            "INFO:tensorflow:global step 5206: loss = 0.7819 (0.810 sec/step)\n",
            "I0503 01:50:49.679190 140519389960064 learning.py:507] global step 5206: loss = 0.7819 (0.810 sec/step)\n",
            "INFO:tensorflow:global step 5207: loss = 0.8154 (0.805 sec/step)\n",
            "I0503 01:50:50.509849 140519389960064 learning.py:507] global step 5207: loss = 0.8154 (0.805 sec/step)\n",
            "INFO:tensorflow:global step 5208: loss = 0.7539 (0.779 sec/step)\n",
            "I0503 01:50:51.290927 140519389960064 learning.py:507] global step 5208: loss = 0.7539 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 5209: loss = 0.7022 (0.865 sec/step)\n",
            "I0503 01:50:52.157169 140519389960064 learning.py:507] global step 5209: loss = 0.7022 (0.865 sec/step)\n",
            "INFO:tensorflow:global step 5210: loss = 0.6889 (0.876 sec/step)\n",
            "I0503 01:50:53.034847 140519389960064 learning.py:507] global step 5210: loss = 0.6889 (0.876 sec/step)\n",
            "INFO:tensorflow:global step 5211: loss = 0.6744 (0.864 sec/step)\n",
            "I0503 01:50:53.900432 140519389960064 learning.py:507] global step 5211: loss = 0.6744 (0.864 sec/step)\n",
            "INFO:tensorflow:global step 5212: loss = 0.5690 (0.949 sec/step)\n",
            "I0503 01:50:54.850961 140519389960064 learning.py:507] global step 5212: loss = 0.5690 (0.949 sec/step)\n",
            "INFO:tensorflow:global step 5213: loss = 0.6925 (0.856 sec/step)\n",
            "I0503 01:50:55.708583 140519389960064 learning.py:507] global step 5213: loss = 0.6925 (0.856 sec/step)\n",
            "INFO:tensorflow:global step 5214: loss = 0.6514 (0.819 sec/step)\n",
            "I0503 01:50:56.529021 140519389960064 learning.py:507] global step 5214: loss = 0.6514 (0.819 sec/step)\n",
            "INFO:tensorflow:global step 5215: loss = 0.7251 (0.772 sec/step)\n",
            "I0503 01:50:57.302087 140519389960064 learning.py:507] global step 5215: loss = 0.7251 (0.772 sec/step)\n",
            "INFO:tensorflow:global step 5216: loss = 0.7812 (0.814 sec/step)\n",
            "I0503 01:50:58.117538 140519389960064 learning.py:507] global step 5216: loss = 0.7812 (0.814 sec/step)\n",
            "INFO:tensorflow:global step 5217: loss = 0.7107 (0.780 sec/step)\n",
            "I0503 01:50:58.900625 140519389960064 learning.py:507] global step 5217: loss = 0.7107 (0.780 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 5217.\n",
            "I0503 01:51:00.275099 140515676296960 supervisor.py:1050] Recording summary at step 5217.\n",
            "INFO:tensorflow:global step 5218: loss = 0.8824 (1.697 sec/step)\n",
            "I0503 01:51:00.599069 140519389960064 learning.py:507] global step 5218: loss = 0.8824 (1.697 sec/step)\n",
            "INFO:tensorflow:global step 5219: loss = 0.6594 (0.993 sec/step)\n",
            "I0503 01:51:01.593474 140519389960064 learning.py:507] global step 5219: loss = 0.6594 (0.993 sec/step)\n",
            "INFO:tensorflow:global step 5220: loss = 0.7637 (0.811 sec/step)\n",
            "I0503 01:51:02.406724 140519389960064 learning.py:507] global step 5220: loss = 0.7637 (0.811 sec/step)\n",
            "INFO:tensorflow:global step 5221: loss = 0.7160 (0.867 sec/step)\n",
            "I0503 01:51:03.275851 140519389960064 learning.py:507] global step 5221: loss = 0.7160 (0.867 sec/step)\n",
            "INFO:tensorflow:global step 5222: loss = 0.7113 (0.771 sec/step)\n",
            "I0503 01:51:04.048284 140519389960064 learning.py:507] global step 5222: loss = 0.7113 (0.771 sec/step)\n",
            "INFO:tensorflow:global step 5223: loss = 0.7901 (0.860 sec/step)\n",
            "I0503 01:51:04.909635 140519389960064 learning.py:507] global step 5223: loss = 0.7901 (0.860 sec/step)\n",
            "INFO:tensorflow:global step 5224: loss = 0.6140 (0.812 sec/step)\n",
            "I0503 01:51:05.722995 140519389960064 learning.py:507] global step 5224: loss = 0.6140 (0.812 sec/step)\n",
            "INFO:tensorflow:global step 5225: loss = 0.6597 (0.933 sec/step)\n",
            "I0503 01:51:06.658060 140519389960064 learning.py:507] global step 5225: loss = 0.6597 (0.933 sec/step)\n",
            "INFO:tensorflow:global step 5226: loss = 0.7646 (0.880 sec/step)\n",
            "I0503 01:51:07.540238 140519389960064 learning.py:507] global step 5226: loss = 0.7646 (0.880 sec/step)\n",
            "INFO:tensorflow:global step 5227: loss = 0.9343 (0.802 sec/step)\n",
            "I0503 01:51:08.343957 140519389960064 learning.py:507] global step 5227: loss = 0.9343 (0.802 sec/step)\n",
            "INFO:tensorflow:global step 5228: loss = 0.7662 (0.778 sec/step)\n",
            "I0503 01:51:09.213251 140519389960064 learning.py:507] global step 5228: loss = 0.7662 (0.778 sec/step)\n",
            "INFO:tensorflow:global step 5229: loss = 0.8464 (0.947 sec/step)\n",
            "I0503 01:51:10.187759 140519389960064 learning.py:507] global step 5229: loss = 0.8464 (0.947 sec/step)\n",
            "INFO:tensorflow:global step 5230: loss = 0.5775 (0.809 sec/step)\n",
            "I0503 01:51:10.998655 140519389960064 learning.py:507] global step 5230: loss = 0.5775 (0.809 sec/step)\n",
            "INFO:tensorflow:global step 5231: loss = 0.6776 (0.895 sec/step)\n",
            "I0503 01:51:11.895418 140519389960064 learning.py:507] global step 5231: loss = 0.6776 (0.895 sec/step)\n",
            "INFO:tensorflow:global step 5232: loss = 0.6947 (0.963 sec/step)\n",
            "I0503 01:51:12.860398 140519389960064 learning.py:507] global step 5232: loss = 0.6947 (0.963 sec/step)\n",
            "INFO:tensorflow:global step 5233: loss = 0.8034 (0.899 sec/step)\n",
            "I0503 01:51:13.762937 140519389960064 learning.py:507] global step 5233: loss = 0.8034 (0.899 sec/step)\n",
            "INFO:tensorflow:global step 5234: loss = 0.7595 (0.933 sec/step)\n",
            "I0503 01:51:14.697546 140519389960064 learning.py:507] global step 5234: loss = 0.7595 (0.933 sec/step)\n",
            "INFO:tensorflow:global step 5235: loss = 0.7587 (0.878 sec/step)\n",
            "I0503 01:51:15.577132 140519389960064 learning.py:507] global step 5235: loss = 0.7587 (0.878 sec/step)\n",
            "INFO:tensorflow:global step 5236: loss = 0.5199 (0.775 sec/step)\n",
            "I0503 01:51:16.355121 140519389960064 learning.py:507] global step 5236: loss = 0.5199 (0.775 sec/step)\n",
            "INFO:tensorflow:global step 5237: loss = 0.7828 (0.829 sec/step)\n",
            "I0503 01:51:17.187209 140519389960064 learning.py:507] global step 5237: loss = 0.7828 (0.829 sec/step)\n",
            "INFO:tensorflow:global step 5238: loss = 0.8668 (0.837 sec/step)\n",
            "I0503 01:51:18.026141 140519389960064 learning.py:507] global step 5238: loss = 0.8668 (0.837 sec/step)\n",
            "INFO:tensorflow:global step 5239: loss = 0.7955 (0.941 sec/step)\n",
            "I0503 01:51:18.968806 140519389960064 learning.py:507] global step 5239: loss = 0.7955 (0.941 sec/step)\n",
            "INFO:tensorflow:global step 5240: loss = 0.7455 (0.944 sec/step)\n",
            "I0503 01:51:19.914668 140519389960064 learning.py:507] global step 5240: loss = 0.7455 (0.944 sec/step)\n",
            "INFO:tensorflow:global step 5241: loss = 0.9988 (0.795 sec/step)\n",
            "I0503 01:51:20.711797 140519389960064 learning.py:507] global step 5241: loss = 0.9988 (0.795 sec/step)\n",
            "INFO:tensorflow:global step 5242: loss = 0.5698 (0.884 sec/step)\n",
            "I0503 01:51:21.597835 140519389960064 learning.py:507] global step 5242: loss = 0.5698 (0.884 sec/step)\n",
            "INFO:tensorflow:global step 5243: loss = 0.5755 (0.832 sec/step)\n",
            "I0503 01:51:22.431442 140519389960064 learning.py:507] global step 5243: loss = 0.5755 (0.832 sec/step)\n",
            "INFO:tensorflow:global step 5244: loss = 0.7167 (0.860 sec/step)\n",
            "I0503 01:51:23.293927 140519389960064 learning.py:507] global step 5244: loss = 0.7167 (0.860 sec/step)\n",
            "INFO:tensorflow:global step 5245: loss = 0.9129 (0.881 sec/step)\n",
            "I0503 01:51:24.176753 140519389960064 learning.py:507] global step 5245: loss = 0.9129 (0.881 sec/step)\n",
            "INFO:tensorflow:global step 5246: loss = 0.4744 (0.834 sec/step)\n",
            "I0503 01:51:25.012435 140519389960064 learning.py:507] global step 5246: loss = 0.4744 (0.834 sec/step)\n",
            "INFO:tensorflow:global step 5247: loss = 0.7861 (0.680 sec/step)\n",
            "I0503 01:51:25.715631 140519389960064 learning.py:507] global step 5247: loss = 0.7861 (0.680 sec/step)\n",
            "INFO:tensorflow:global step 5248: loss = 0.8291 (1.431 sec/step)\n",
            "I0503 01:51:27.149033 140519389960064 learning.py:507] global step 5248: loss = 0.8291 (1.431 sec/step)\n",
            "INFO:tensorflow:global step 5249: loss = 0.7881 (0.772 sec/step)\n",
            "I0503 01:51:28.014798 140519389960064 learning.py:507] global step 5249: loss = 0.7881 (0.772 sec/step)\n",
            "INFO:tensorflow:global step 5250: loss = 0.8016 (0.887 sec/step)\n",
            "I0503 01:51:28.926702 140519389960064 learning.py:507] global step 5250: loss = 0.8016 (0.887 sec/step)\n",
            "INFO:tensorflow:global step 5251: loss = 0.6386 (0.811 sec/step)\n",
            "I0503 01:51:29.771622 140519389960064 learning.py:507] global step 5251: loss = 0.6386 (0.811 sec/step)\n",
            "INFO:tensorflow:global step 5252: loss = 0.7225 (0.888 sec/step)\n",
            "I0503 01:51:30.663414 140519389960064 learning.py:507] global step 5252: loss = 0.7225 (0.888 sec/step)\n",
            "INFO:tensorflow:global step 5253: loss = 0.7371 (0.898 sec/step)\n",
            "I0503 01:51:31.562864 140519389960064 learning.py:507] global step 5253: loss = 0.7371 (0.898 sec/step)\n",
            "INFO:tensorflow:global step 5254: loss = 0.6670 (0.711 sec/step)\n",
            "I0503 01:51:32.318305 140519389960064 learning.py:507] global step 5254: loss = 0.6670 (0.711 sec/step)\n",
            "INFO:tensorflow:global step 5255: loss = 0.6734 (0.813 sec/step)\n",
            "I0503 01:51:33.133659 140519389960064 learning.py:507] global step 5255: loss = 0.6734 (0.813 sec/step)\n",
            "INFO:tensorflow:global step 5256: loss = 0.7340 (0.896 sec/step)\n",
            "I0503 01:51:34.030944 140519389960064 learning.py:507] global step 5256: loss = 0.7340 (0.896 sec/step)\n",
            "INFO:tensorflow:global step 5257: loss = 0.6459 (0.819 sec/step)\n",
            "I0503 01:51:34.851464 140519389960064 learning.py:507] global step 5257: loss = 0.6459 (0.819 sec/step)\n",
            "INFO:tensorflow:global step 5258: loss = 0.7210 (0.817 sec/step)\n",
            "I0503 01:51:35.669798 140519389960064 learning.py:507] global step 5258: loss = 0.7210 (0.817 sec/step)\n",
            "INFO:tensorflow:global step 5259: loss = 0.6931 (0.888 sec/step)\n",
            "I0503 01:51:36.559895 140519389960064 learning.py:507] global step 5259: loss = 0.6931 (0.888 sec/step)\n",
            "INFO:tensorflow:global step 5260: loss = 0.7385 (0.957 sec/step)\n",
            "I0503 01:51:37.518289 140519389960064 learning.py:507] global step 5260: loss = 0.7385 (0.957 sec/step)\n",
            "INFO:tensorflow:global step 5261: loss = 0.8683 (0.738 sec/step)\n",
            "I0503 01:51:38.257722 140519389960064 learning.py:507] global step 5261: loss = 0.8683 (0.738 sec/step)\n",
            "INFO:tensorflow:global step 5262: loss = 0.8739 (0.813 sec/step)\n",
            "I0503 01:51:39.072644 140519389960064 learning.py:507] global step 5262: loss = 0.8739 (0.813 sec/step)\n",
            "INFO:tensorflow:global step 5263: loss = 0.8135 (0.740 sec/step)\n",
            "I0503 01:51:39.815553 140519389960064 learning.py:507] global step 5263: loss = 0.8135 (0.740 sec/step)\n",
            "INFO:tensorflow:global step 5264: loss = 0.7963 (0.734 sec/step)\n",
            "I0503 01:51:40.553634 140519389960064 learning.py:507] global step 5264: loss = 0.7963 (0.734 sec/step)\n",
            "INFO:tensorflow:global step 5265: loss = 0.7021 (0.780 sec/step)\n",
            "I0503 01:51:41.334828 140519389960064 learning.py:507] global step 5265: loss = 0.7021 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 5266: loss = 0.8634 (0.906 sec/step)\n",
            "I0503 01:51:42.242379 140519389960064 learning.py:507] global step 5266: loss = 0.8634 (0.906 sec/step)\n",
            "INFO:tensorflow:global step 5267: loss = 0.9610 (0.777 sec/step)\n",
            "I0503 01:51:43.021567 140519389960064 learning.py:507] global step 5267: loss = 0.9610 (0.777 sec/step)\n",
            "INFO:tensorflow:global step 5268: loss = 0.7247 (0.799 sec/step)\n",
            "I0503 01:51:43.822196 140519389960064 learning.py:507] global step 5268: loss = 0.7247 (0.799 sec/step)\n",
            "INFO:tensorflow:global step 5269: loss = 0.8245 (0.704 sec/step)\n",
            "I0503 01:51:44.604636 140519389960064 learning.py:507] global step 5269: loss = 0.8245 (0.704 sec/step)\n",
            "INFO:tensorflow:global step 5270: loss = 1.2830 (0.744 sec/step)\n",
            "I0503 01:51:45.418888 140519389960064 learning.py:507] global step 5270: loss = 1.2830 (0.744 sec/step)\n",
            "INFO:tensorflow:global step 5271: loss = 0.6921 (0.773 sec/step)\n",
            "I0503 01:51:46.193293 140519389960064 learning.py:507] global step 5271: loss = 0.6921 (0.773 sec/step)\n",
            "INFO:tensorflow:global step 5272: loss = 0.5470 (0.847 sec/step)\n",
            "I0503 01:51:47.042187 140519389960064 learning.py:507] global step 5272: loss = 0.5470 (0.847 sec/step)\n",
            "INFO:tensorflow:global step 5273: loss = 1.0142 (0.938 sec/step)\n",
            "I0503 01:51:47.981389 140519389960064 learning.py:507] global step 5273: loss = 1.0142 (0.938 sec/step)\n",
            "INFO:tensorflow:global step 5274: loss = 0.7752 (0.675 sec/step)\n",
            "I0503 01:51:48.658721 140519389960064 learning.py:507] global step 5274: loss = 0.7752 (0.675 sec/step)\n",
            "INFO:tensorflow:global step 5275: loss = 0.7534 (1.074 sec/step)\n",
            "I0503 01:51:49.734295 140519389960064 learning.py:507] global step 5275: loss = 0.7534 (1.074 sec/step)\n",
            "INFO:tensorflow:global step 5276: loss = 0.8865 (0.901 sec/step)\n",
            "I0503 01:51:50.637280 140519389960064 learning.py:507] global step 5276: loss = 0.8865 (0.901 sec/step)\n",
            "INFO:tensorflow:global step 5277: loss = 0.9480 (0.806 sec/step)\n",
            "I0503 01:51:51.447899 140519389960064 learning.py:507] global step 5277: loss = 0.9480 (0.806 sec/step)\n",
            "INFO:tensorflow:global step 5278: loss = 0.8867 (0.913 sec/step)\n",
            "I0503 01:51:52.364248 140519389960064 learning.py:507] global step 5278: loss = 0.8867 (0.913 sec/step)\n",
            "INFO:tensorflow:global step 5279: loss = 0.7576 (0.913 sec/step)\n",
            "I0503 01:51:53.278727 140519389960064 learning.py:507] global step 5279: loss = 0.7576 (0.913 sec/step)\n",
            "INFO:tensorflow:global step 5280: loss = 0.6773 (0.800 sec/step)\n",
            "I0503 01:51:54.090122 140519389960064 learning.py:507] global step 5280: loss = 0.6773 (0.800 sec/step)\n",
            "INFO:tensorflow:global step 5281: loss = 0.6795 (0.703 sec/step)\n",
            "I0503 01:51:54.815622 140519389960064 learning.py:507] global step 5281: loss = 0.6795 (0.703 sec/step)\n",
            "INFO:tensorflow:global step 5282: loss = 0.6045 (0.862 sec/step)\n",
            "I0503 01:51:55.678874 140519389960064 learning.py:507] global step 5282: loss = 0.6045 (0.862 sec/step)\n",
            "INFO:tensorflow:global step 5283: loss = 0.6252 (0.653 sec/step)\n",
            "I0503 01:51:56.333480 140519389960064 learning.py:507] global step 5283: loss = 0.6252 (0.653 sec/step)\n",
            "INFO:tensorflow:global step 5284: loss = 0.8243 (1.164 sec/step)\n",
            "I0503 01:51:57.499681 140519389960064 learning.py:507] global step 5284: loss = 0.8243 (1.164 sec/step)\n",
            "INFO:tensorflow:global step 5285: loss = 0.7001 (0.671 sec/step)\n",
            "I0503 01:51:58.174036 140519389960064 learning.py:507] global step 5285: loss = 0.7001 (0.671 sec/step)\n",
            "INFO:tensorflow:global step 5286: loss = 0.6496 (1.178 sec/step)\n",
            "I0503 01:51:59.353884 140519389960064 learning.py:507] global step 5286: loss = 0.6496 (1.178 sec/step)\n",
            "INFO:tensorflow:global step 5287: loss = 0.8374 (0.851 sec/step)\n",
            "I0503 01:52:00.207231 140519389960064 learning.py:507] global step 5287: loss = 0.8374 (0.851 sec/step)\n",
            "INFO:tensorflow:global step 5288: loss = 0.8112 (0.765 sec/step)\n",
            "I0503 01:52:00.973538 140519389960064 learning.py:507] global step 5288: loss = 0.8112 (0.765 sec/step)\n",
            "INFO:tensorflow:global step 5289: loss = 0.9072 (0.925 sec/step)\n",
            "I0503 01:52:01.900312 140519389960064 learning.py:507] global step 5289: loss = 0.9072 (0.925 sec/step)\n",
            "INFO:tensorflow:global step 5290: loss = 0.5293 (0.831 sec/step)\n",
            "I0503 01:52:02.744883 140519389960064 learning.py:507] global step 5290: loss = 0.5293 (0.831 sec/step)\n",
            "INFO:tensorflow:global step 5291: loss = 0.7877 (0.988 sec/step)\n",
            "I0503 01:52:03.734862 140519389960064 learning.py:507] global step 5291: loss = 0.7877 (0.988 sec/step)\n",
            "INFO:tensorflow:global step 5292: loss = 1.1057 (0.941 sec/step)\n",
            "I0503 01:52:04.678080 140519389960064 learning.py:507] global step 5292: loss = 1.1057 (0.941 sec/step)\n",
            "INFO:tensorflow:global step 5293: loss = 0.6485 (0.937 sec/step)\n",
            "I0503 01:52:05.616747 140519389960064 learning.py:507] global step 5293: loss = 0.6485 (0.937 sec/step)\n",
            "INFO:tensorflow:global step 5294: loss = 0.6673 (0.760 sec/step)\n",
            "I0503 01:52:06.378375 140519389960064 learning.py:507] global step 5294: loss = 0.6673 (0.760 sec/step)\n",
            "INFO:tensorflow:global step 5295: loss = 0.7107 (0.908 sec/step)\n",
            "I0503 01:52:07.288349 140519389960064 learning.py:507] global step 5295: loss = 0.7107 (0.908 sec/step)\n",
            "INFO:tensorflow:global step 5296: loss = 0.6453 (0.869 sec/step)\n",
            "I0503 01:52:08.159398 140519389960064 learning.py:507] global step 5296: loss = 0.6453 (0.869 sec/step)\n",
            "INFO:tensorflow:global step 5297: loss = 0.7989 (0.881 sec/step)\n",
            "I0503 01:52:09.042196 140519389960064 learning.py:507] global step 5297: loss = 0.7989 (0.881 sec/step)\n",
            "INFO:tensorflow:global step 5298: loss = 1.0085 (0.714 sec/step)\n",
            "I0503 01:52:09.757879 140519389960064 learning.py:507] global step 5298: loss = 1.0085 (0.714 sec/step)\n",
            "INFO:tensorflow:global step 5299: loss = 0.6302 (0.826 sec/step)\n",
            "I0503 01:52:10.585267 140519389960064 learning.py:507] global step 5299: loss = 0.6302 (0.826 sec/step)\n",
            "INFO:tensorflow:global step 5300: loss = 0.7613 (0.723 sec/step)\n",
            "I0503 01:52:11.310319 140519389960064 learning.py:507] global step 5300: loss = 0.7613 (0.723 sec/step)\n",
            "INFO:tensorflow:global step 5301: loss = 0.6543 (0.893 sec/step)\n",
            "I0503 01:52:12.205735 140519389960064 learning.py:507] global step 5301: loss = 0.6543 (0.893 sec/step)\n",
            "INFO:tensorflow:global step 5302: loss = 0.6887 (0.824 sec/step)\n",
            "I0503 01:52:13.031494 140519389960064 learning.py:507] global step 5302: loss = 0.6887 (0.824 sec/step)\n",
            "INFO:tensorflow:global step 5303: loss = 0.7863 (0.775 sec/step)\n",
            "I0503 01:52:13.809087 140519389960064 learning.py:507] global step 5303: loss = 0.7863 (0.775 sec/step)\n",
            "INFO:tensorflow:global step 5304: loss = 0.9956 (0.850 sec/step)\n",
            "I0503 01:52:14.660440 140519389960064 learning.py:507] global step 5304: loss = 0.9956 (0.850 sec/step)\n",
            "INFO:tensorflow:global step 5305: loss = 0.9927 (0.642 sec/step)\n",
            "I0503 01:52:15.351278 140519389960064 learning.py:507] global step 5305: loss = 0.9927 (0.642 sec/step)\n",
            "INFO:tensorflow:global step 5306: loss = 0.5883 (0.805 sec/step)\n",
            "I0503 01:52:16.160491 140519389960064 learning.py:507] global step 5306: loss = 0.5883 (0.805 sec/step)\n",
            "INFO:tensorflow:global step 5307: loss = 0.6025 (0.860 sec/step)\n",
            "I0503 01:52:17.023547 140519389960064 learning.py:507] global step 5307: loss = 0.6025 (0.860 sec/step)\n",
            "INFO:tensorflow:global step 5308: loss = 0.7831 (0.678 sec/step)\n",
            "I0503 01:52:17.705950 140519389960064 learning.py:507] global step 5308: loss = 0.7831 (0.678 sec/step)\n",
            "INFO:tensorflow:global step 5309: loss = 0.8374 (0.798 sec/step)\n",
            "I0503 01:52:18.505960 140519389960064 learning.py:507] global step 5309: loss = 0.8374 (0.798 sec/step)\n",
            "INFO:tensorflow:global step 5310: loss = 0.7286 (0.870 sec/step)\n",
            "I0503 01:52:19.378082 140519389960064 learning.py:507] global step 5310: loss = 0.7286 (0.870 sec/step)\n",
            "INFO:tensorflow:global step 5311: loss = 0.6029 (0.729 sec/step)\n",
            "I0503 01:52:20.141247 140519389960064 learning.py:507] global step 5311: loss = 0.6029 (0.729 sec/step)\n",
            "INFO:tensorflow:global step 5312: loss = 0.7002 (0.755 sec/step)\n",
            "I0503 01:52:20.898691 140519389960064 learning.py:507] global step 5312: loss = 0.7002 (0.755 sec/step)\n",
            "INFO:tensorflow:global step 5313: loss = 0.6962 (0.758 sec/step)\n",
            "I0503 01:52:21.678156 140519389960064 learning.py:507] global step 5313: loss = 0.6962 (0.758 sec/step)\n",
            "INFO:tensorflow:global step 5314: loss = 0.7040 (0.836 sec/step)\n",
            "I0503 01:52:22.541642 140519389960064 learning.py:507] global step 5314: loss = 0.7040 (0.836 sec/step)\n",
            "INFO:tensorflow:global step 5315: loss = 0.7668 (0.745 sec/step)\n",
            "I0503 01:52:23.287806 140519389960064 learning.py:507] global step 5315: loss = 0.7668 (0.745 sec/step)\n",
            "INFO:tensorflow:global step 5316: loss = 0.5685 (0.801 sec/step)\n",
            "I0503 01:52:24.090352 140519389960064 learning.py:507] global step 5316: loss = 0.5685 (0.801 sec/step)\n",
            "INFO:tensorflow:global step 5317: loss = 0.4707 (0.897 sec/step)\n",
            "I0503 01:52:24.990429 140519389960064 learning.py:507] global step 5317: loss = 0.4707 (0.897 sec/step)\n",
            "INFO:tensorflow:global step 5318: loss = 0.8748 (0.728 sec/step)\n",
            "I0503 01:52:25.720352 140519389960064 learning.py:507] global step 5318: loss = 0.8748 (0.728 sec/step)\n",
            "INFO:tensorflow:global step 5319: loss = 0.8206 (0.910 sec/step)\n",
            "I0503 01:52:26.632411 140519389960064 learning.py:507] global step 5319: loss = 0.8206 (0.910 sec/step)\n",
            "INFO:tensorflow:global step 5320: loss = 0.9748 (0.709 sec/step)\n",
            "I0503 01:52:27.343041 140519389960064 learning.py:507] global step 5320: loss = 0.9748 (0.709 sec/step)\n",
            "INFO:tensorflow:global step 5321: loss = 0.6981 (0.860 sec/step)\n",
            "I0503 01:52:28.204971 140519389960064 learning.py:507] global step 5321: loss = 0.6981 (0.860 sec/step)\n",
            "INFO:tensorflow:global step 5322: loss = 0.7891 (0.806 sec/step)\n",
            "I0503 01:52:29.012131 140519389960064 learning.py:507] global step 5322: loss = 0.7891 (0.806 sec/step)\n",
            "INFO:tensorflow:global step 5323: loss = 0.6268 (0.847 sec/step)\n",
            "I0503 01:52:29.860450 140519389960064 learning.py:507] global step 5323: loss = 0.6268 (0.847 sec/step)\n",
            "INFO:tensorflow:global step 5324: loss = 0.9675 (0.730 sec/step)\n",
            "I0503 01:52:30.591949 140519389960064 learning.py:507] global step 5324: loss = 0.9675 (0.730 sec/step)\n",
            "INFO:tensorflow:global step 5325: loss = 0.6667 (0.886 sec/step)\n",
            "I0503 01:52:31.480693 140519389960064 learning.py:507] global step 5325: loss = 0.6667 (0.886 sec/step)\n",
            "INFO:tensorflow:global step 5326: loss = 0.7077 (0.817 sec/step)\n",
            "I0503 01:52:32.299761 140519389960064 learning.py:507] global step 5326: loss = 0.7077 (0.817 sec/step)\n",
            "INFO:tensorflow:global step 5327: loss = 0.9076 (0.684 sec/step)\n",
            "I0503 01:52:32.985588 140519389960064 learning.py:507] global step 5327: loss = 0.9076 (0.684 sec/step)\n",
            "INFO:tensorflow:global step 5328: loss = 0.9493 (0.787 sec/step)\n",
            "I0503 01:52:33.773996 140519389960064 learning.py:507] global step 5328: loss = 0.9493 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 5329: loss = 0.7889 (0.703 sec/step)\n",
            "I0503 01:52:34.577953 140519389960064 learning.py:507] global step 5329: loss = 0.7889 (0.703 sec/step)\n",
            "INFO:tensorflow:global step 5330: loss = 0.6643 (0.733 sec/step)\n",
            "I0503 01:52:35.324430 140519389960064 learning.py:507] global step 5330: loss = 0.6643 (0.733 sec/step)\n",
            "INFO:tensorflow:global step 5331: loss = 0.6679 (0.685 sec/step)\n",
            "I0503 01:52:36.055799 140519389960064 learning.py:507] global step 5331: loss = 0.6679 (0.685 sec/step)\n",
            "INFO:tensorflow:global step 5332: loss = 0.6325 (0.868 sec/step)\n",
            "I0503 01:52:36.926090 140519389960064 learning.py:507] global step 5332: loss = 0.6325 (0.868 sec/step)\n",
            "INFO:tensorflow:global step 5333: loss = 0.8414 (0.778 sec/step)\n",
            "I0503 01:52:37.707592 140519389960064 learning.py:507] global step 5333: loss = 0.8414 (0.778 sec/step)\n",
            "INFO:tensorflow:global step 5334: loss = 0.6953 (0.906 sec/step)\n",
            "I0503 01:52:38.614847 140519389960064 learning.py:507] global step 5334: loss = 0.6953 (0.906 sec/step)\n",
            "INFO:tensorflow:global step 5335: loss = 0.6314 (0.888 sec/step)\n",
            "I0503 01:52:39.504344 140519389960064 learning.py:507] global step 5335: loss = 0.6314 (0.888 sec/step)\n",
            "INFO:tensorflow:global step 5336: loss = 1.2656 (0.823 sec/step)\n",
            "I0503 01:52:40.329796 140519389960064 learning.py:507] global step 5336: loss = 1.2656 (0.823 sec/step)\n",
            "INFO:tensorflow:global step 5337: loss = 0.6632 (0.880 sec/step)\n",
            "I0503 01:52:41.211657 140519389960064 learning.py:507] global step 5337: loss = 0.6632 (0.880 sec/step)\n",
            "INFO:tensorflow:global step 5338: loss = 0.7297 (0.868 sec/step)\n",
            "I0503 01:52:42.081678 140519389960064 learning.py:507] global step 5338: loss = 0.7297 (0.868 sec/step)\n",
            "INFO:tensorflow:global step 5339: loss = 0.7901 (0.899 sec/step)\n",
            "I0503 01:52:42.981971 140519389960064 learning.py:507] global step 5339: loss = 0.7901 (0.899 sec/step)\n",
            "INFO:tensorflow:global step 5340: loss = 0.7835 (0.760 sec/step)\n",
            "I0503 01:52:43.746892 140519389960064 learning.py:507] global step 5340: loss = 0.7835 (0.760 sec/step)\n",
            "INFO:tensorflow:global step 5341: loss = 0.7660 (0.829 sec/step)\n",
            "I0503 01:52:44.577929 140519389960064 learning.py:507] global step 5341: loss = 0.7660 (0.829 sec/step)\n",
            "INFO:tensorflow:global step 5342: loss = 0.9588 (0.790 sec/step)\n",
            "I0503 01:52:45.369845 140519389960064 learning.py:507] global step 5342: loss = 0.9588 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 5343: loss = 0.6748 (0.788 sec/step)\n",
            "I0503 01:52:46.179321 140519389960064 learning.py:507] global step 5343: loss = 0.6748 (0.788 sec/step)\n",
            "INFO:tensorflow:global step 5344: loss = 0.7985 (0.624 sec/step)\n",
            "I0503 01:52:46.859441 140519389960064 learning.py:507] global step 5344: loss = 0.7985 (0.624 sec/step)\n",
            "INFO:tensorflow:global step 5345: loss = 0.6902 (0.841 sec/step)\n",
            "I0503 01:52:47.702072 140519389960064 learning.py:507] global step 5345: loss = 0.6902 (0.841 sec/step)\n",
            "INFO:tensorflow:global step 5346: loss = 0.7115 (0.867 sec/step)\n",
            "I0503 01:52:48.570911 140519389960064 learning.py:507] global step 5346: loss = 0.7115 (0.867 sec/step)\n",
            "INFO:tensorflow:global step 5347: loss = 1.1062 (0.830 sec/step)\n",
            "I0503 01:52:49.402979 140519389960064 learning.py:507] global step 5347: loss = 1.1062 (0.830 sec/step)\n",
            "INFO:tensorflow:global step 5348: loss = 0.8281 (0.810 sec/step)\n",
            "I0503 01:52:50.214865 140519389960064 learning.py:507] global step 5348: loss = 0.8281 (0.810 sec/step)\n",
            "INFO:tensorflow:global step 5349: loss = 0.9569 (0.885 sec/step)\n",
            "I0503 01:52:51.101877 140519389960064 learning.py:507] global step 5349: loss = 0.9569 (0.885 sec/step)\n",
            "INFO:tensorflow:global step 5350: loss = 0.7034 (0.749 sec/step)\n",
            "I0503 01:52:51.852689 140519389960064 learning.py:507] global step 5350: loss = 0.7034 (0.749 sec/step)\n",
            "INFO:tensorflow:global step 5351: loss = 0.8217 (0.867 sec/step)\n",
            "I0503 01:52:52.721916 140519389960064 learning.py:507] global step 5351: loss = 0.8217 (0.867 sec/step)\n",
            "INFO:tensorflow:global step 5352: loss = 0.7607 (0.805 sec/step)\n",
            "I0503 01:52:53.528993 140519389960064 learning.py:507] global step 5352: loss = 0.7607 (0.805 sec/step)\n",
            "INFO:tensorflow:global step 5353: loss = 0.7293 (0.925 sec/step)\n",
            "I0503 01:52:54.455497 140519389960064 learning.py:507] global step 5353: loss = 0.7293 (0.925 sec/step)\n",
            "INFO:tensorflow:global step 5354: loss = 0.7736 (0.821 sec/step)\n",
            "I0503 01:52:55.278153 140519389960064 learning.py:507] global step 5354: loss = 0.7736 (0.821 sec/step)\n",
            "INFO:tensorflow:global step 5355: loss = 0.7841 (0.840 sec/step)\n",
            "I0503 01:52:56.120371 140519389960064 learning.py:507] global step 5355: loss = 0.7841 (0.840 sec/step)\n",
            "INFO:tensorflow:global step 5356: loss = 0.7066 (0.798 sec/step)\n",
            "I0503 01:52:56.920290 140519389960064 learning.py:507] global step 5356: loss = 0.7066 (0.798 sec/step)\n",
            "INFO:tensorflow:global step 5357: loss = 0.7075 (0.800 sec/step)\n",
            "I0503 01:52:57.721627 140519389960064 learning.py:507] global step 5357: loss = 0.7075 (0.800 sec/step)\n",
            "INFO:tensorflow:global step 5358: loss = 1.0037 (0.889 sec/step)\n",
            "I0503 01:52:58.611900 140519389960064 learning.py:507] global step 5358: loss = 1.0037 (0.889 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 5359.\n",
            "I0503 01:53:00.180399 140515676296960 supervisor.py:1050] Recording summary at step 5359.\n",
            "Traceback (most recent call last):\n",
            "  File \"research/object_detection/legacy/train.py\", line 185, in <module>\n",
            "    tf.app.run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\", line 324, in new_func\n",
            "    return func(*args, **kwargs)\n",
            "  File \"research/object_detection/legacy/train.py\", line 181, in main\n",
            "    graph_hook_fn=graph_rewriter_fn)\n",
            "  File \"/content/models/research/object_detection/legacy/trainer.py\", line 417, in train\n",
            "    saver=saver)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/slim/python/slim/learning.py\", line 775, in train\n",
            "    train_step_kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/slim/python/slim/learning.py\", line 490, in train_step\n",
            "    run_metadata=run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 956, in run\n",
            "    run_metadata_ptr)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1180, in _run\n",
            "    feed_dict_tensor, options, run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1359, in _do_run\n",
            "    run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1365, in _do_call\n",
            "    return fn(*args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\n",
            "    target_list, run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\n",
            "    run_metadata)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtJiWS-hf1zm",
        "colab_type": "text"
      },
      "source": [
        "test the model with evaluation datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTzctPleOml2",
        "colab_type": "code",
        "outputId": "9fdd7d70-9061-466b-cdff-78709bd58926",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# From the models directory\n",
        "! python research/object_detection/legacy/eval.py \\\n",
        "    --logtostderr \\\n",
        "    --pipeline_config_path=ssd_mobilenet_v2_coco.config \\\n",
        "    --checkpoint_dir=train \\\n",
        "    --eval_dir=eval\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From research/object_detection/legacy/eval.py:57: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "WARNING:tensorflow:From research/object_detection/legacy/eval.py:57: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "WARNING:tensorflow:From research/object_detection/legacy/eval.py:143: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/absl/app.py:250: main (from __main__) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use object_detection/model_main.py.\n",
            "W0428 13:56:19.293940 140223418267520 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/absl/app.py:250: main (from __main__) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use object_detection/model_main.py.\n",
            "WARNING:tensorflow:From research/object_detection/legacy/eval.py:88: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W0428 13:56:19.294136 140223418267520 module_wrapper.py:139] From research/object_detection/legacy/eval.py:88: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/config_util.py:102: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0428 13:56:19.294440 140223418267520 module_wrapper.py:139] From /content/models/research/object_detection/utils/config_util.py:102: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From research/object_detection/legacy/eval.py:92: The name tf.gfile.Copy is deprecated. Please use tf.io.gfile.copy instead.\n",
            "\n",
            "W0428 13:56:19.297656 140223418267520 module_wrapper.py:139] From research/object_detection/legacy/eval.py:92: The name tf.gfile.Copy is deprecated. Please use tf.io.gfile.copy instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "W0428 13:56:19.300895 140223418267520 module_wrapper.py:139] From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:197: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n",
            "\n",
            "W0428 13:56:19.301106 140223418267520 module_wrapper.py:139] From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:197: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:64: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "W0428 13:56:19.312045 140223418267520 module_wrapper.py:139] From /content/models/research/object_detection/builders/dataset_builder.py:64: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"research/object_detection/legacy/eval.py\", line 143, in <module>\n",
            "    tf.app.run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\", line 324, in new_func\n",
            "    return func(*args, **kwargs)\n",
            "  File \"research/object_detection/legacy/eval.py\", line 139, in main\n",
            "    graph_hook_fn=graph_rewriter_fn)\n",
            "  File \"/content/models/research/object_detection/legacy/evaluator.py\", line 206, in evaluate\n",
            "    ignore_groundtruth=eval_config.ignore_groundtruth)\n",
            "  File \"/content/models/research/object_detection/legacy/evaluator.py\", line 81, in _extract_predictions_and_losses\n",
            "    input_dict = create_input_dict_fn()\n",
            "  File \"research/object_detection/legacy/eval.py\", line 117, in get_next\n",
            "    dataset_builder.build(config)).get_next()\n",
            "  File \"/content/models/research/object_detection/builders/dataset_builder.py\", line 141, in build\n",
            "    config.input_path[:], input_reader_config)\n",
            "  File \"/content/models/research/object_detection/builders/dataset_builder.py\", line 67, in read_dataset\n",
            "    '{}'.format(input_files))\n",
            "RuntimeError: Did not find any input files matching the glob pattern ['tf_record/val.record']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ufg1KTtOnOH",
        "colab_type": "code",
        "outputId": "1712f3d8-029f-4bcc-e78f-be346330e892",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# From the models directory\n",
        "! tensorboard --logdir=./ "
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorBoard 1.15.0 at http://0093164bb865:6006/ (Press CTRL+C to quit)\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5TZ8ZoDf9Xe",
        "colab_type": "text"
      },
      "source": [
        "create the model. Go to to the train directory to take the latest checkpoint number to replace the model.ckpt here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2BMd08MOqAl",
        "colab_type": "code",
        "outputId": "6a48ff50-1cde-458b-ce07-d5ea3d0911fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# note teh checkpoint number in /content/models/train sub directory\n",
        "# From the models directory\n",
        "%mkdir fine_tuned_model\n",
        "%cd /content/models\n",
        "\n",
        "!python research/object_detection/export_inference_graph.py  --input_type image_tensor  --pipeline_config_path ssd_mobilenet_v2_coco.config --trained_checkpoint_prefix  train/model.ckpt-4937   --output_directory fine_tuned_model"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘fine_tuned_model’: File exists\n",
            "/content\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From research/object_detection/export_inference_graph.py:162: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From research/object_detection/export_inference_graph.py:145: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0503 01:53:40.750394 139712260958080 module_wrapper.py:139] From research/object_detection/export_inference_graph.py:145: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:402: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W0503 01:53:40.757899 139712260958080 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:402: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:121: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0503 01:53:40.758212 139712260958080 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:121: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/preprocessor.py:2937: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "W0503 01:53:40.793507 139712260958080 module_wrapper.py:139] From /content/models/research/object_detection/core/preprocessor.py:2937: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:589: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "W0503 01:53:40.820943 139712260958080 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:589: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0503 01:53:40.821156 139712260958080 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0503 01:53:40.824790 139712260958080 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "W0503 01:53:42.863121 139712260958080 module_wrapper.py:139] From /content/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W0503 01:53:42.873792 139712260958080 module_wrapper.py:139] From /content/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0503 01:53:42.874010 139712260958080 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0503 01:53:42.910480 139712260958080 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0503 01:53:42.947871 139712260958080 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0503 01:53:42.983137 139712260958080 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0503 01:53:43.019866 139712260958080 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0503 01:53:43.056061 139712260958080 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/post_processing.py:581: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0503 01:53:43.419861 139712260958080 deprecation.py:323] From /content/models/research/object_detection/core/post_processing.py:581: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:278: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "W0503 01:53:43.732220 139712260958080 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:278: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:383: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "W0503 01:53:43.732501 139712260958080 deprecation.py:323] From /content/models/research/object_detection/exporter.py:383: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:415: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0503 01:53:43.735455 139712260958080 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:415: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:539: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "W0503 01:53:43.735652 139712260958080 deprecation.py:323] From /content/models/research/object_detection/exporter.py:539: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "W0503 01:53:43.736616 139712260958080 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "133 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              0\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   name\n",
            "-account_type_regexes       _trainable_variables\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     params\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "param: Number of parameters (in the Variable).\n",
            "\n",
            "Profile:\n",
            "node name | # parameters\n",
            "_TFProfRoot (--/4.57m params)\n",
            "  BoxPredictor_0 (--/10.39k params)\n",
            "    BoxPredictor_0/BoxEncodingPredictor (--/6.92k params)\n",
            "      BoxPredictor_0/BoxEncodingPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_0/BoxEncodingPredictor/weights (1x1x576x12, 6.91k/6.91k params)\n",
            "    BoxPredictor_0/ClassPredictor (--/3.46k params)\n",
            "      BoxPredictor_0/ClassPredictor/biases (6, 6/6 params)\n",
            "      BoxPredictor_0/ClassPredictor/weights (1x1x576x6, 3.46k/3.46k params)\n",
            "  BoxPredictor_1 (--/46.12k params)\n",
            "    BoxPredictor_1/BoxEncodingPredictor (--/30.74k params)\n",
            "      BoxPredictor_1/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_1/BoxEncodingPredictor/weights (1x1x1280x24, 30.72k/30.72k params)\n",
            "    BoxPredictor_1/ClassPredictor (--/15.37k params)\n",
            "      BoxPredictor_1/ClassPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_1/ClassPredictor/weights (1x1x1280x12, 15.36k/15.36k params)\n",
            "  BoxPredictor_2 (--/18.47k params)\n",
            "    BoxPredictor_2/BoxEncodingPredictor (--/12.31k params)\n",
            "      BoxPredictor_2/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_2/BoxEncodingPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n",
            "    BoxPredictor_2/ClassPredictor (--/6.16k params)\n",
            "      BoxPredictor_2/ClassPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_2/ClassPredictor/weights (1x1x512x12, 6.14k/6.14k params)\n",
            "  BoxPredictor_3 (--/9.25k params)\n",
            "    BoxPredictor_3/BoxEncodingPredictor (--/6.17k params)\n",
            "      BoxPredictor_3/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_3/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n",
            "    BoxPredictor_3/ClassPredictor (--/3.08k params)\n",
            "      BoxPredictor_3/ClassPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_3/ClassPredictor/weights (1x1x256x12, 3.07k/3.07k params)\n",
            "  BoxPredictor_4 (--/9.25k params)\n",
            "    BoxPredictor_4/BoxEncodingPredictor (--/6.17k params)\n",
            "      BoxPredictor_4/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_4/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n",
            "    BoxPredictor_4/ClassPredictor (--/3.08k params)\n",
            "      BoxPredictor_4/ClassPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_4/ClassPredictor/weights (1x1x256x12, 3.07k/3.07k params)\n",
            "  BoxPredictor_5 (--/4.64k params)\n",
            "    BoxPredictor_5/BoxEncodingPredictor (--/3.10k params)\n",
            "      BoxPredictor_5/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_5/BoxEncodingPredictor/weights (1x1x128x24, 3.07k/3.07k params)\n",
            "    BoxPredictor_5/ClassPredictor (--/1.55k params)\n",
            "      BoxPredictor_5/ClassPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_5/ClassPredictor/weights (1x1x128x12, 1.54k/1.54k params)\n",
            "  FeatureExtractor (--/4.48m params)\n",
            "    FeatureExtractor/MobilenetV2 (--/4.48m params)\n",
            "      FeatureExtractor/MobilenetV2/Conv (--/864 params)\n",
            "        FeatureExtractor/MobilenetV2/Conv/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/Conv/weights (3x3x3x32, 864/864 params)\n",
            "      FeatureExtractor/MobilenetV2/Conv_1 (--/409.60k params)\n",
            "        FeatureExtractor/MobilenetV2/Conv_1/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/Conv_1/weights (1x1x320x1280, 409.60k/409.60k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv (--/800 params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv/depthwise (--/288 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv/depthwise/depthwise_weights (3x3x32x1, 288/288 params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv/project (--/512 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv/project/weights (1x1x32x16, 512/512 params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_1 (--/4.70k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise (--/864 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/depthwise_weights (3x3x96x1, 864/864 params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_1/expand (--/1.54k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_1/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_1/expand/weights (1x1x16x96, 1.54k/1.54k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_1/project (--/2.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_1/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_1/project/weights (1x1x96x24, 2.30k/2.30k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_10 (--/64.90k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise (--/3.46k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_10/expand (--/24.58k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_10/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_10/expand/weights (1x1x64x384, 24.58k/24.58k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_10/project (--/36.86k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_10/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_10/project/weights (1x1x384x96, 36.86k/36.86k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_11 (--/115.78k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise (--/5.18k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_11/expand (--/55.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_11/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_11/expand/weights (1x1x96x576, 55.30k/55.30k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_11/project (--/55.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_11/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_11/project/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_12 (--/115.78k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise (--/5.18k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_12/expand (--/55.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_12/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_12/expand/weights (1x1x96x576, 55.30k/55.30k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_12/project (--/55.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_12/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_12/project/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_13 (--/152.64k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise (--/5.18k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_13/expand (--/55.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_13/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_13/expand/weights (1x1x96x576, 55.30k/55.30k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_13/project (--/92.16k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_13/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_13/project/weights (1x1x576x160, 92.16k/92.16k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_14 (--/315.84k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise (--/8.64k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_14/expand (--/153.60k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_14/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_14/expand/weights (1x1x160x960, 153.60k/153.60k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_14/project (--/153.60k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_14/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_14/project/weights (1x1x960x160, 153.60k/153.60k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_15 (--/315.84k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise (--/8.64k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_15/expand (--/153.60k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_15/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_15/expand/weights (1x1x160x960, 153.60k/153.60k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_15/project (--/153.60k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_15/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_15/project/weights (1x1x960x160, 153.60k/153.60k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_16 (--/469.44k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise (--/8.64k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_16/expand (--/153.60k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_16/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_16/expand/weights (1x1x160x960, 153.60k/153.60k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_16/project (--/307.20k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_16/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_16/project/weights (1x1x960x320, 307.20k/307.20k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_2 (--/8.21k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise (--/1.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/depthwise_weights (3x3x144x1, 1.30k/1.30k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_2/expand (--/3.46k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_2/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_2/expand/weights (1x1x24x144, 3.46k/3.46k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_2/project (--/3.46k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_2/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_2/project/weights (1x1x144x24, 3.46k/3.46k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_3 (--/9.36k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise (--/1.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/depthwise_weights (3x3x144x1, 1.30k/1.30k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_3/expand (--/3.46k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_3/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_3/expand/weights (1x1x24x144, 3.46k/3.46k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_3/project (--/4.61k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_3/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_3/project/weights (1x1x144x32, 4.61k/4.61k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_4 (--/14.02k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise (--/1.73k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_4/expand (--/6.14k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_4/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_4/expand/weights (1x1x32x192, 6.14k/6.14k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_4/project (--/6.14k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_4/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_4/project/weights (1x1x192x32, 6.14k/6.14k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_5 (--/14.02k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise (--/1.73k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_5/expand (--/6.14k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_5/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_5/expand/weights (1x1x32x192, 6.14k/6.14k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_5/project (--/6.14k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_5/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_5/project/weights (1x1x192x32, 6.14k/6.14k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_6 (--/20.16k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise (--/1.73k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_6/expand (--/6.14k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_6/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_6/expand/weights (1x1x32x192, 6.14k/6.14k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_6/project (--/12.29k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_6/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_6/project/weights (1x1x192x64, 12.29k/12.29k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_7 (--/52.61k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise (--/3.46k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_7/expand (--/24.58k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_7/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_7/expand/weights (1x1x64x384, 24.58k/24.58k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_7/project (--/24.58k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_7/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_7/project/weights (1x1x384x64, 24.58k/24.58k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_8 (--/52.61k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise (--/3.46k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_8/expand (--/24.58k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_8/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_8/expand/weights (1x1x64x384, 24.58k/24.58k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_8/project (--/24.58k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_8/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_8/project/weights (1x1x384x64, 24.58k/24.58k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_9 (--/52.61k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise (--/3.46k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_9/expand (--/24.58k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_9/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_9/expand/weights (1x1x64x384, 24.58k/24.58k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_9/project (--/24.58k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_9/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_9/project/weights (1x1x384x64, 24.58k/24.58k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256 (--/327.68k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/weights (1x1x1280x256, 327.68k/327.68k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128 (--/65.54k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/weights (1x1x512x128, 65.54k/65.54k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128 (--/32.77k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/weights (1x1x256x128, 32.77k/32.77k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64 (--/16.38k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512 (--/1.18m params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/weights (3x3x256x512, 1.18m/1.18m params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256 (--/294.91k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256 (--/294.91k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128 (--/73.73k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/weights (3x3x64x128, 73.73k/73.73k params)\n",
            "\n",
            "======================End of Report==========================\n",
            "133 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              1\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   float_ops\n",
            "-account_type_regexes       .*\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     float_ops\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
            "\n",
            "Profile:\n",
            "node name | # float_ops\n",
            "_TFProfRoot (--/13.71k flops)\n",
            "  MultipleGridAnchorGenerator/sub (2.17k/2.17k flops)\n",
            "  MultipleGridAnchorGenerator/mul_20 (2.17k/2.17k flops)\n",
            "  MultipleGridAnchorGenerator/mul_19 (2.17k/2.17k flops)\n",
            "  MultipleGridAnchorGenerator/mul_27 (1.20k/1.20k flops)\n",
            "  MultipleGridAnchorGenerator/mul_28 (1.20k/1.20k flops)\n",
            "  MultipleGridAnchorGenerator/sub_1 (1.20k/1.20k flops)\n",
            "  MultipleGridAnchorGenerator/mul_21 (1.08k/1.08k flops)\n",
            "  MultipleGridAnchorGenerator/mul_29 (600/600 flops)\n",
            "  MultipleGridAnchorGenerator/mul_36 (300/300 flops)\n",
            "  MultipleGridAnchorGenerator/mul_35 (300/300 flops)\n",
            "  MultipleGridAnchorGenerator/sub_2 (300/300 flops)\n",
            "  MultipleGridAnchorGenerator/mul_37 (150/150 flops)\n",
            "  MultipleGridAnchorGenerator/mul_43 (108/108 flops)\n",
            "  MultipleGridAnchorGenerator/mul_44 (108/108 flops)\n",
            "  MultipleGridAnchorGenerator/sub_3 (108/108 flops)\n",
            "  MultipleGridAnchorGenerator/mul_45 (54/54 flops)\n",
            "  MultipleGridAnchorGenerator/mul_52 (48/48 flops)\n",
            "  MultipleGridAnchorGenerator/mul_51 (48/48 flops)\n",
            "  MultipleGridAnchorGenerator/sub_4 (48/48 flops)\n",
            "  MultipleGridAnchorGenerator/mul_53 (24/24 flops)\n",
            "  MultipleGridAnchorGenerator/mul_18 (19/19 flops)\n",
            "  MultipleGridAnchorGenerator/mul_17 (19/19 flops)\n",
            "  MultipleGridAnchorGenerator/sub_5 (12/12 flops)\n",
            "  MultipleGridAnchorGenerator/mul_60 (12/12 flops)\n",
            "  MultipleGridAnchorGenerator/mul_59 (12/12 flops)\n",
            "  MultipleGridAnchorGenerator/mul_25 (10/10 flops)\n",
            "  MultipleGridAnchorGenerator/mul_26 (10/10 flops)\n",
            "  MultipleGridAnchorGenerator/mul_46 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_40 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_54 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_17 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_16 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_15 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_24 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_47 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_48 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_61 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_39 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_38 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_19 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_55 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_56 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_32 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_31 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_30 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_18 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_22 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_23 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_34 (5/5 flops)\n",
            "  MultipleGridAnchorGenerator/mul_33 (5/5 flops)\n",
            "  MultipleGridAnchorGenerator/mul_42 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_41 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_16 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_15 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_14 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_14 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_50 (2/2 flops)\n",
            "  MultipleGridAnchorGenerator/mul_49 (2/2 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_9 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
            "  Preprocessor/map/while/Less_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/Minimum (1/1 flops)\n",
            "  Preprocessor/map/while/Less (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_19 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_18 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_4 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_1 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_9 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_8 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_7 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_6 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_58 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_57 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_5 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_10 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_3 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_2 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_13 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_12 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_11 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_10 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_1 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/assert_equal_1/Equal (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_7 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_9 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_8 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_6 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_5 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_4 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_3 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_2 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_13 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_12 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_11 (1/1 flops)\n",
            "\n",
            "======================End of Report==========================\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:432: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "W0503 01:53:44.760750 139712260958080 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:432: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:342: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "W0503 01:53:45.516430 139712260958080 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:342: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-05-03 01:53:45.531320: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-05-03 01:53:45.564435: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-03 01:53:45.564846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-05-03 01:53:45.568160: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-05-03 01:53:45.583109: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-05-03 01:53:45.625510: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-05-03 01:53:45.633965: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-05-03 01:53:45.652667: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-05-03 01:53:45.662985: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-05-03 01:53:45.830426: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-05-03 01:53:45.830649: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-03 01:53:45.831233: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-03 01:53:45.831578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-05-03 01:53:45.832148: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
            "2020-05-03 01:53:45.841953: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000160000 Hz\n",
            "2020-05-03 01:53:45.842420: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x246d100 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-05-03 01:53:45.842459: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-05-03 01:53:45.945819: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-03 01:53:45.946341: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x246d2c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-05-03 01:53:45.946375: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P4, Compute Capability 6.1\n",
            "2020-05-03 01:53:45.946609: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-03 01:53:45.946985: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-05-03 01:53:45.947078: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-05-03 01:53:45.947109: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-05-03 01:53:45.947139: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-05-03 01:53:45.947164: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-05-03 01:53:45.947188: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-05-03 01:53:45.947216: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-05-03 01:53:45.947247: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-05-03 01:53:45.947337: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-03 01:53:45.947735: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-03 01:53:45.948069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-05-03 01:53:45.950139: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-05-03 01:53:45.952166: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-05-03 01:53:45.952202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-05-03 01:53:45.952218: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-05-03 01:53:45.952576: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-03 01:53:45.953029: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-03 01:53:45.953399: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-05-03 01:53:45.953447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5165 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "INFO:tensorflow:Restoring parameters from train/model.ckpt-4937\n",
            "I0503 01:53:45.955526 139712260958080 saver.py:1284] Restoring parameters from train/model.ckpt-4937\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "W0503 01:53:55.895263 139712260958080 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "2020-05-03 01:53:56.363271: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-03 01:53:56.363722: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-05-03 01:53:56.363839: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-05-03 01:53:56.363882: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-05-03 01:53:56.363904: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-05-03 01:53:56.363944: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-05-03 01:53:56.363966: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-05-03 01:53:56.363987: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-05-03 01:53:56.364008: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-05-03 01:53:56.364108: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-03 01:53:56.364461: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-03 01:53:56.364757: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-05-03 01:53:56.364812: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-05-03 01:53:56.364827: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-05-03 01:53:56.364840: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-05-03 01:53:56.364934: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-03 01:53:56.365339: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-03 01:53:56.365657: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5165 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "INFO:tensorflow:Restoring parameters from train/model.ckpt-4937\n",
            "I0503 01:53:56.367052 139712260958080 saver.py:1284] Restoring parameters from train/model.ckpt-4937\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W0503 01:53:56.923794 139712260958080 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "W0503 01:53:56.924067 139712260958080 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 324 variables.\n",
            "I0503 01:53:57.266847 139712260958080 graph_util_impl.py:334] Froze 324 variables.\n",
            "INFO:tensorflow:Converted 324 variables to const ops.\n",
            "I0503 01:53:57.346412 139712260958080 graph_util_impl.py:394] Converted 324 variables to const ops.\n",
            "2020-05-03 01:53:57.475953: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-03 01:53:57.476383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-05-03 01:53:57.476482: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-05-03 01:53:57.476521: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-05-03 01:53:57.476545: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-05-03 01:53:57.476571: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-05-03 01:53:57.476595: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-05-03 01:53:57.476619: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-05-03 01:53:57.476644: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-05-03 01:53:57.476762: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-03 01:53:57.477180: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-03 01:53:57.477480: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-05-03 01:53:57.477528: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-05-03 01:53:57.477545: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-05-03 01:53:57.477559: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-05-03 01:53:57.477663: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-03 01:53:57.478037: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-03 01:53:57.478383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5165 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:306: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n",
            "\n",
            "W0503 01:53:57.845944 139712260958080 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:306: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"research/object_detection/export_inference_graph.py\", line 162, in <module>\n",
            "    tf.app.run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"research/object_detection/export_inference_graph.py\", line 158, in main\n",
            "    write_inference_graph=FLAGS.write_inference_graph)\n",
            "  File \"/content/models/research/object_detection/exporter.py\", line 510, in export_inference_graph\n",
            "    write_inference_graph=write_inference_graph)\n",
            "  File \"/content/models/research/object_detection/exporter.py\", line 466, in _export_inference_graph\n",
            "    placeholder_tensor, outputs)\n",
            "  File \"/content/models/research/object_detection/exporter.py\", line 306, in write_saved_model\n",
            "    builder = tf.saved_model.builder.SavedModelBuilder(saved_model_path)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/builder_impl.py\", line 436, in __init__\n",
            "    super(SavedModelBuilder, self).__init__(export_dir=export_dir)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/builder_impl.py\", line 103, in __init__\n",
            "    \"specified directory: %s\" % export_dir)\n",
            "AssertionError: Export directory already exists, and isn't empty. Please choose a different export directory, or delete all the contents of the specified directory: fine_tuned_model/saved_model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bl7Ep7FI4knZ",
        "colab_type": "code",
        "outputId": "432c265f-f22f-421f-f88f-bf01b4a7e62f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "annotations\n",
            "AUTHORS\n",
            "checkpoints\n",
            "CODEOWNERS\n",
            "CONTRIBUTING.md\n",
            "eval\n",
            "images\n",
            "ISSUES.md\n",
            "ISSUE_TEMPLATE.md\n",
            "LICENSE\n",
            "official\n",
            "README.md\n",
            "research\n",
            "ssd_mobilenet_v2_coco.config\n",
            "tf_record\n",
            "train\n",
            "traincheckpoint\n",
            "trainevents.out.tfevents.1587305748.0211dd21a942\n",
            "traingraph.pbtxt\n",
            "trainmodel.ckpt-132.data-00000-of-00001\n",
            "trainmodel.ckpt-132.index\n",
            "trainmodel.ckpt-132.meta\n",
            "trainmodel.ckpt-165.data-00000-of-00001\n",
            "trainmodel.ckpt-165.index\n",
            "trainmodel.ckpt-165.meta\n",
            "trainmodel.ckpt-32.data-00000-of-00001\n",
            "trainmodel.ckpt-32.index\n",
            "trainmodel.ckpt-32.meta\n",
            "trainmodel.ckpt-65.data-00000-of-00001\n",
            "trainmodel.ckpt-65.index\n",
            "trainmodel.ckpt-65.meta\n",
            "trainmodel.ckpt-99.data-00000-of-00001\n",
            "trainmodel.ckpt-99.index\n",
            "trainmodel.ckpt-99.meta\n",
            "trainpipeline.config\n",
            "WORKSPACE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSc6aTIrjOFL",
        "colab_type": "text"
      },
      "source": [
        "testing the model using an image from google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YW_8DB6_3aR",
        "colab_type": "code",
        "outputId": "6d5c204e-a206-4cb8-8bd1-0c143d653fc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Import packages\n",
        "%cd /content/models\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# This is needed since the notebook is stored in the object_detection folder.\n",
        "sys.path.append(\"..\")\n",
        "\n",
        "# Import utilites\n",
        "from utils import label_map_util\n",
        "from utils import visualization_utils as vis_util\n",
        "\n",
        "# Name of the directory containing the object detection module we're using\n",
        "MODEL_NAME = 'fine_tuned_model'\n",
        "IMAGE_NAME = '/content/images.jpg'\n",
        "\n",
        "# Grab path to current working directory\n",
        "CWD_PATH = os.getcwd()\n",
        "\n",
        "# Path to frozen detection graph .pb file, which contains the model that is used\n",
        "# for object detection.\n",
        "PATH_TO_CKPT = os.path.join(CWD_PATH,MODEL_NAME,'frozen_inference_graph.pb')\n",
        "\n",
        "# Path to label map file\n",
        "PATH_TO_LABELS = os.path.join(CWD_PATH,'annotations','label_map.pbtxt')\n",
        "\n",
        "# Path to image\n",
        "PATH_TO_IMAGE = IMAGE_NAME #os.path.join(CWD_PATH,IMAGE_NAME)\n",
        "\n",
        "# Number of classes the object detector can identify\n",
        "NUM_CLASSES = 1\n",
        "\n",
        "# Load the label map.\n",
        "# Label maps map indices to category names, so that when our convolution\n",
        "# network predicts `5`, we know that this corresponds to `king`.\n",
        "# Here we use internal utility functions, but anything that returns a\n",
        "# dictionary mapping integers to appropriate string labels would be fine\n",
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdCNAC4c_4n2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the Tensorflow model into memory.\n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "    od_graph_def = tf.GraphDef()\n",
        "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "        serialized_graph = fid.read()\n",
        "        od_graph_def.ParseFromString(serialized_graph)\n",
        "        tf.import_graph_def(od_graph_def, name='')\n",
        "\n",
        "    sess = tf.Session(graph=detection_graph)\n",
        "\n",
        "# Define input and output tensors (i.e. data) for the object detection classifier\n",
        "\n",
        "# Input tensor is the image\n",
        "image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "# Output tensors are the detection boxes, scores, and classes\n",
        "# Each box represents a part of the image where a particular object was detected\n",
        "detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
        "\n",
        "# Each score represents level of confidence for each of the objects.\n",
        "# The score is shown on the result image, together with the class label.\n",
        "detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
        "detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
        "\n",
        "# Number of objects detected\n",
        "num_detections = detection_graph.get_tensor_by_name('num_detections:0')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NB-3SAv-BnI2",
        "colab_type": "code",
        "outputId": "8bf56486-a0ad-46c9-b4ff-8cf733e8ae7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "source": [
        "\n",
        "# Load image using OpenCV and\n",
        "# expand image dimensions to have shape: [1, None, None, 3]\n",
        "# i.e. a single-column array, where each item in the column has the pixel RGB value\n",
        "image = cv2.imread(PATH_TO_IMAGE)\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "image_expanded = np.expand_dims(image_rgb, axis=0)\n",
        "\n",
        "# Perform the actual detection by running the model with the image as input\n",
        "(boxes, scores, classes, num) = sess.run(\n",
        "    [detection_boxes, detection_scores, detection_classes, num_detections],\n",
        "    feed_dict={image_tensor: image_expanded})\n",
        "\n",
        "# Draw the results of the detection (aka 'visulaize the results')\n",
        "\n",
        "vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "    image,\n",
        "    np.squeeze(boxes),\n",
        "    np.squeeze(classes).astype(np.int32),\n",
        "    np.squeeze(scores),\n",
        "    category_index,\n",
        "    use_normalized_coordinates=True,\n",
        "    line_thickness=8,\n",
        "    min_score_thresh=0.80)\n",
        "\n",
        "# All the results have been drawn on image. Now display the image.\n",
        "cv2_imshow( image)\n",
        "\n",
        "# Press any key to close the image\n",
        "cv2.waitKey(0)\n",
        "\n",
        "# Clean up\n",
        "cv2.destroyAllWindows()\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=480x300 at 0x7F9E446EC630>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsiB6numimdi",
        "colab_type": "text"
      },
      "source": [
        "The following several scripts is to copy the train files and checkpoints to google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ddz6p3LX-9dN",
        "colab_type": "code",
        "outputId": "388032c0-7123-42ef-9498-cb7907bd3cc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/models/train\n",
        "#copy checkpoint train files to google drive for storage\n",
        "for x in os.listdir('/content/models/train'):\n",
        "  copyfile('/content/models/train/'+x, '/content/drive/My Drive/Colab Notebooks/image_retrainssd/checkpoints/'+x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Thz88hLX8qDP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/models/eval\n",
        "#copy checkpoint train files to google drive for storage\n",
        "for x in os.listdir('/content/models/eval'):\n",
        "  copyfile('/content/models/eval/'+x, '/content/drive/My Drive/Colab Notebooks/image_retrainssd/eval_checkpoints/'+x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jioj3Vx79ozI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# copy checkpoint train files from google drive to TRAIN subdirectory\n",
        "for x in os.listdir('/content/drive/My Drive/Colab Notebooks/image_retrainssd/checkpoints'):\n",
        "  copyfile('/content/drive/My Drive/Colab Notebooks/image_retrainssd/checkpoints/'+x, '/content/models/train/'+x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c21E-mqu8aU8",
        "colab_type": "code",
        "outputId": "663ad650-db75-4e9b-a4ef-ac1eac62a5e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "%cd /content/models/fine_tuned_model\n",
        "# copy fine tune model  files togoogle drive to model/fine tunesubdirectory\n",
        "for x in os.listdir('/content/models/fine_tuned_model'):\n",
        "  if os.path.isfile(x) == True :\n",
        "    print(x)\n",
        "    copyfile('/content/models/fine_tuned_model/'+x, '/content/drive/My Drive/Colab Notebooks/image_retrainssd/fine_tune_model/'+x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/fine_tuned_model\n",
            "model.ckpt.meta\n",
            "model.ckpt.data-00000-of-00001\n",
            "frozen_inference_graph.pb\n",
            "model.ckpt.index\n",
            "checkpoint\n",
            "pipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5Xw8h2o818V",
        "colab_type": "code",
        "outputId": "7c29cb3d-df01-4bc3-ffd5-acc835bb9d0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/models/fine_tuned_model/saved_model\n",
        "# copy fine tune model  files togoogle drive to model/fine tunesubdirectory\n",
        "for x in os.listdir('/content/models/fine_tuned_model/saved_model'):\n",
        "  if os.path.isfile(x) == True :\n",
        "    copyfile('/content/models/fine_tuned_model/saved_model/'+x, '/content/drive/My Drive/Colab Notebooks/image_retrainssd/fine_tune_model/saved_model/'+x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/fine_tuned_model/saved_model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqgIwO7oDfX-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from shutil import copyfile\n",
        "%cd /content/models\n",
        "%mkdir fine_tuned_model\n",
        "%cd fine_tuned_model\n",
        "%mkdir saved_model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-YlyDiP49-s",
        "colab_type": "code",
        "outputId": "eecd6c63-02f8-45f5-8b44-ad6e2b2f2365",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "%cd /content/drive/My Drive/Colab Notebooks/image_retrainssd/fine_tune_model\n",
        "# transfering trained model files from google drive to colab\n",
        "for x in os.listdir('/content/drive/My Drive/Colab Notebooks/image_retrainssd/fine_tune_model'):\n",
        "  print(x)\n",
        "  if os.path.isfile(x) == True :\n",
        "    copyfile('/content/drive/My Drive/Colab Notebooks/image_retrainssd/fine_tune_model/'+x, '/content/models/fine_tuned_model/'+x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/image_retrainssd/fine_tune_model\n",
            "saved_model\n",
            "model.ckpt.meta\n",
            "model.ckpt.data-00000-of-00001\n",
            "frozen_inference_graph.pb\n",
            "pipeline.config\n",
            "model.ckpt.index\n",
            "checkpoint\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pc6A2ts6CAYr",
        "colab_type": "code",
        "outputId": "1fb3b752-3c59-452a-bf50-9cc69b067338",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "  copyfile('/content/drive/My Drive/Colab Notebooks/image_retrainssd/fine_tune_model/saved_model/saved_model.pb', '/content/models/fine_tuned_model/saved_model/saved_model.pb')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/models/fine_tuned_model/saved_model/saved_model.pb'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    }
  ]
}